{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e47fcd13",
   "metadata": {},
   "source": [
    "## 모델 저장과 로드  \n",
    "여러분은 클라우드를 사용하면서 세션이 끊어지는 것을 한 번쯤은 경험해보셨을 것입니다.  \n",
    "이때, 만약 학습한 가중치를 저장하지 않는다면 몇 시간을 학습한 것이 날아갈 것입니다.   \n",
    "이번에는 학습 과정에서 모델을 저장하는 방법과, 학습 전에 모델을 불러오는 방법을 배우겠습니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c65df92",
   "metadata": {},
   "source": [
    "## Quiz (Easy)  \n",
    "0) run_cnn2 파일을 만들어서 기존의 코드를 리팩터링 해봅시다.  \n",
    "1) 앞에서 배웠던 argparser를 이용해 config_path, save_path, pre_trained, model_name 인자를 추가하세요  \n",
    "2) 상위 폴더에 weights 폴더를 만드세요.   \n",
    "3) save_path의 default 값은 './weights'이고 config_path의 default는 './configs' 입니다.  \n",
    "4) pre_trained의 type은 bool이고 defaut 값은 False 입니다.  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54c4c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing arg_tutorial3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile arg_tutorial3.py\n",
    "\n",
    "import yaml\n",
    "import os\n",
    "import argparse\n",
    "    \n",
    "parser = argparse.ArgumentParser(description='quiz')\n",
    "parser.add_argument('--config_path', type=str, default='./configs/', help='config_path')\n",
    "parser.add_argument('--save_path', type=str, default='./weights/', help='save_path')\n",
    "parser.add_argument('--pre_trained', type=bool, default=False, help='pre_trained')\n",
    "parser.add_argument('--model_name', type=str, default='cnn.pth', help='model_name')\n",
    "args = parser.parse_args()\n",
    "\n",
    "# 1) args를 출력하세요. \n",
    "print(args)\n",
    "# 2) args들 중 config_path를 통해 yaml 파일을 with open구문을 활용해 불러오고 config 변수에 할당하세요.\n",
    "#    yaml.load()를 활용합니다. \n",
    "with open(args.config_path) as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "# 3) config를 출력하세요. \n",
    "print(config)\n",
    "# 마지막으로 셀을 저장하고 파일을 실행해보세요. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7dab3fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: arg_tutorial3.py [-h] [--config_path CONFIG_PATH]\n",
      "                        [--save_path SAVE_PATH] [--pre_trained PRE_TRAINED]\n",
      "                        [--model_name MODEL_NAME]\n",
      "\n",
      "quiz\n",
      "\n",
      "optional arguments:\n",
      "  -h, --help            show this help message and exit\n",
      "  --config_path CONFIG_PATH\n",
      "                        config_path\n",
      "  --save_path SAVE_PATH\n",
      "                        save_path\n",
      "  --pre_trained PRE_TRAINED\n",
      "                        pre_trained\n",
      "  --model_name MODEL_NAME\n",
      "                        model_name\n"
     ]
    }
   ],
   "source": [
    "!python arg_tutorial3.py --help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "19617e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(config_path='./configs/cnn.yaml', model_name='cnn.pth', pre_trained=False, save_path='./weights/')\n",
      "{'learning_rate': 0.001, 'epochs': 10, 'batch_size': 32, 'kernel_size': 3, 'stride': 2}\n"
     ]
    }
   ],
   "source": [
    "!python arg_tutorial3.py --config_path ./configs/cnn.yaml --model_name cnn.pth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aae8db0",
   "metadata": {},
   "source": [
    "## Quiz (Easy)  \n",
    "모델을 로드하고 저장하는 부분을 구현하기 위해 train, test 코드를 수정해야 합니다.  \n",
    "아래에서 어떤 부분에 추가해야할까요??  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ea94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model, loss_func, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {loss.item():.6f}')\n",
    "            \n",
    "\n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afe36ccd",
   "metadata": {},
   "source": [
    "## Save, Load  \n",
    "모델의 저장과 로드는 torch.load_state_dict(), torch.load(), torch.save()를 활용합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edffdd42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "6\n",
      "2\n",
      "OrderedDict([('conv1.weight', tensor([[[[ 9.5682e-02, -8.6843e-02, -2.8802e-01],\n",
      "          [-1.8895e-01,  1.1838e-01, -2.0885e-02],\n",
      "          [-3.0595e-01,  2.4018e-01, -2.7028e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 3.1410e-01,  7.4856e-02,  1.2415e-01],\n",
      "          [ 2.7332e-01,  2.6599e-01,  9.8109e-02],\n",
      "          [ 3.3008e-01,  1.1670e-01,  8.4203e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3589e-01, -1.6729e-01,  2.5012e-01],\n",
      "          [ 3.6465e-02, -2.1320e-01,  2.6948e-01],\n",
      "          [-9.3775e-02,  2.9670e-01, -3.0916e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.0486e-02,  3.3180e-01, -1.3820e-01],\n",
      "          [ 1.4076e-02, -7.1417e-02, -1.2187e-01],\n",
      "          [ 1.5870e-01,  2.7203e-01, -1.0635e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.2986e-01, -1.6460e-01, -1.2521e-01],\n",
      "          [-1.0145e-01, -4.3318e-02,  3.2621e-01],\n",
      "          [-1.2050e-01, -1.2446e-01, -1.3269e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.6695e-01, -2.6399e-01,  9.6524e-02],\n",
      "          [ 5.7806e-02,  1.9964e-01, -3.4832e-02],\n",
      "          [-1.2158e-01,  2.7812e-02, -4.5214e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.1840e-01,  1.6137e-01, -1.0019e-01],\n",
      "          [ 2.8269e-01,  2.5351e-02, -7.5481e-02],\n",
      "          [ 7.0851e-02,  2.8756e-01,  1.1779e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6052e-01, -1.7047e-02,  3.1036e-02],\n",
      "          [-1.1666e-02,  3.1390e-01,  1.1066e-01],\n",
      "          [ 1.1670e-01,  1.0877e-01, -2.5569e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.0367e-01,  3.1731e-02,  2.5003e-01],\n",
      "          [ 1.7729e-01,  2.4723e-02,  1.8621e-01],\n",
      "          [-8.3622e-02,  1.6802e-01,  1.2418e-01]]],\n",
      "\n",
      "\n",
      "        [[[-2.3252e-01,  1.3687e-01, -1.8321e-01],\n",
      "          [-1.3833e-01, -1.0755e-02,  2.7597e-01],\n",
      "          [-7.1991e-02,  2.4409e-01, -2.2936e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.6642e-01,  3.2369e-01, -5.8129e-02],\n",
      "          [ 9.0143e-02,  1.1997e-01,  2.1487e-01],\n",
      "          [-1.5866e-01,  2.0918e-01,  6.0266e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1556e-01,  2.1994e-01, -2.8124e-01],\n",
      "          [ 1.4139e-01,  3.2084e-01,  1.1097e-02],\n",
      "          [ 1.7620e-01,  3.1228e-01,  2.0839e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.3793e-01,  1.7333e-01,  3.0228e-01],\n",
      "          [ 8.4114e-03,  3.0979e-01,  1.3416e-01],\n",
      "          [-3.8368e-02,  2.2455e-02,  1.2412e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.7782e-01, -1.1653e-01,  2.6128e-01],\n",
      "          [ 3.9495e-02, -2.3159e-01, -5.1509e-02],\n",
      "          [-1.9858e-01, -1.9707e-01, -1.6127e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 2.8585e-01,  2.1522e-01, -7.5847e-02],\n",
      "          [ 2.7475e-01, -1.4087e-01,  7.4782e-02],\n",
      "          [-7.0181e-02, -2.0528e-01,  1.2297e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5004e-01, -2.2610e-01, -1.5123e-01],\n",
      "          [-3.0615e-01, -1.1585e-01,  2.3328e-02],\n",
      "          [-1.2688e-01,  9.2730e-02, -1.6011e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.5525e-01, -1.9376e-01,  2.7593e-01],\n",
      "          [ 1.8460e-01, -6.8813e-02,  2.8838e-01],\n",
      "          [ 1.4150e-01,  5.9211e-02,  1.3016e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.2876e-01, -1.9691e-01,  2.9624e-01],\n",
      "          [-1.9876e-01, -1.2752e-01,  3.0032e-02],\n",
      "          [ 1.0068e-01, -2.2282e-01, -5.8177e-02]]],\n",
      "\n",
      "\n",
      "        [[[-7.2074e-02, -5.1648e-02, -1.5947e-01],\n",
      "          [-1.3138e-02,  9.3452e-02,  1.1702e-01],\n",
      "          [ 2.2948e-04, -1.0588e-01, -2.5477e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5582e-01, -3.3312e-02, -1.5667e-01],\n",
      "          [ 3.0792e-01,  3.1897e-01, -9.2177e-02],\n",
      "          [ 1.2816e-01, -2.3688e-01, -9.2028e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 2.6089e-01, -3.4853e-02,  1.3771e-01],\n",
      "          [-7.3615e-02, -1.3359e-01,  1.1052e-01],\n",
      "          [ 2.1970e-01,  8.1429e-02, -2.4088e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.1775e-01, -2.5435e-01, -8.1564e-02],\n",
      "          [-2.1619e-01,  1.2802e-01,  1.8400e-01],\n",
      "          [-1.8397e-01,  1.7840e-01, -2.9512e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.4960e-01,  1.1384e-02,  8.4928e-02],\n",
      "          [ 2.6835e-01, -2.8585e-01,  1.3240e-01],\n",
      "          [ 1.0046e-01, -5.9362e-03,  1.4097e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.9552e-01, -1.0562e-01,  3.3013e-01],\n",
      "          [-1.8387e-02, -9.9889e-02, -2.9067e-01],\n",
      "          [-5.9364e-02,  1.5360e-02, -9.0414e-02]]],\n",
      "\n",
      "\n",
      "        [[[-2.0360e-02,  4.9113e-02, -1.5531e-01],\n",
      "          [-1.4196e-01, -1.4083e-01, -6.7238e-02],\n",
      "          [-2.9454e-01,  2.4932e-01, -5.7372e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.0429e-01, -4.6308e-02,  2.7992e-01],\n",
      "          [-2.5556e-01, -1.8449e-01, -2.4686e-01],\n",
      "          [-3.2923e-01, -2.8306e-01,  1.6318e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.8541e-01, -3.0914e-01,  2.6378e-01],\n",
      "          [-7.6686e-02, -3.0883e-01, -2.7088e-01],\n",
      "          [ 4.9739e-02,  1.9679e-01, -1.9871e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5152e-01, -2.2860e-01, -2.1349e-01],\n",
      "          [-2.4265e-01,  1.5039e-01,  2.7278e-01],\n",
      "          [-1.4526e-02, -9.4174e-02, -1.5027e-01]]],\n",
      "\n",
      "\n",
      "        [[[-1.3953e-01, -9.3403e-02,  1.2991e-01],\n",
      "          [ 9.6273e-02,  2.3744e-01,  3.2384e-01],\n",
      "          [-2.6184e-01,  1.0397e-01, -1.9315e-01]]],\n",
      "\n",
      "\n",
      "        [[[-8.8001e-02,  3.0772e-01, -1.4652e-01],\n",
      "          [ 1.7949e-01, -2.7309e-01, -1.3448e-01],\n",
      "          [-8.8443e-02, -2.9066e-02,  2.4595e-01]]],\n",
      "\n",
      "\n",
      "        [[[-6.3380e-03,  3.1884e-02,  1.5004e-01],\n",
      "          [ 1.7651e-01,  3.0868e-01,  1.1453e-01],\n",
      "          [ 2.2860e-01, -1.6320e-02, -1.8489e-01]]],\n",
      "\n",
      "\n",
      "        [[[ 1.5228e-01,  5.1165e-02,  2.4027e-01],\n",
      "          [-1.6137e-01,  2.1625e-01,  1.6914e-01],\n",
      "          [ 1.1165e-02, -1.3637e-01, -1.8284e-02]]]])), ('conv1.bias', tensor([-0.0224,  0.0021, -0.1177, -0.0066, -0.1608,  0.1965,  0.2973,  0.0421,\n",
      "         0.1743,  0.2475, -0.1696,  0.0375, -0.1450,  0.2751, -0.2353, -0.0295,\n",
      "        -0.2533,  0.1006, -0.2136, -0.0422, -0.3324, -0.2971,  0.2295, -0.1814,\n",
      "         0.0156, -0.2204, -0.2683, -0.2208,  0.0475, -0.1808, -0.0697, -0.3186])), ('bn1.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn1.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn1.num_batches_tracked', tensor(0)), ('conv2.weight', tensor([[[[-0.0418,  0.0376, -0.0532],\n",
      "          [ 0.0013,  0.0469, -0.0485],\n",
      "          [-0.0415,  0.0576,  0.0310]],\n",
      "\n",
      "         [[ 0.0044, -0.0142,  0.0576],\n",
      "          [-0.0504,  0.0440,  0.0091],\n",
      "          [ 0.0203, -0.0522, -0.0324]],\n",
      "\n",
      "         [[ 0.0254, -0.0586, -0.0329],\n",
      "          [ 0.0128,  0.0263,  0.0507],\n",
      "          [ 0.0415,  0.0056, -0.0417]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0461,  0.0143, -0.0006],\n",
      "          [ 0.0355, -0.0187,  0.0060],\n",
      "          [ 0.0194, -0.0119,  0.0332]],\n",
      "\n",
      "         [[ 0.0102, -0.0357,  0.0362],\n",
      "          [-0.0257, -0.0129, -0.0536],\n",
      "          [-0.0222,  0.0185,  0.0417]],\n",
      "\n",
      "         [[-0.0080, -0.0285,  0.0436],\n",
      "          [ 0.0542,  0.0484,  0.0566],\n",
      "          [ 0.0333,  0.0256,  0.0253]]],\n",
      "\n",
      "\n",
      "        [[[-0.0258, -0.0084, -0.0488],\n",
      "          [-0.0352, -0.0222, -0.0533],\n",
      "          [ 0.0173,  0.0334,  0.0057]],\n",
      "\n",
      "         [[ 0.0207,  0.0028,  0.0268],\n",
      "          [ 0.0254, -0.0111,  0.0559],\n",
      "          [-0.0311, -0.0072, -0.0354]],\n",
      "\n",
      "         [[-0.0360,  0.0125, -0.0111],\n",
      "          [ 0.0438, -0.0347, -0.0454],\n",
      "          [ 0.0535, -0.0092, -0.0253]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0276, -0.0209, -0.0318],\n",
      "          [ 0.0289, -0.0106, -0.0492],\n",
      "          [ 0.0409, -0.0578, -0.0176]],\n",
      "\n",
      "         [[-0.0225, -0.0554, -0.0213],\n",
      "          [ 0.0219,  0.0484,  0.0543],\n",
      "          [ 0.0415, -0.0408, -0.0084]],\n",
      "\n",
      "         [[ 0.0042,  0.0137,  0.0563],\n",
      "          [-0.0563, -0.0567, -0.0448],\n",
      "          [-0.0394,  0.0136, -0.0043]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0525, -0.0137, -0.0191],\n",
      "          [-0.0356, -0.0562, -0.0528],\n",
      "          [ 0.0290, -0.0022, -0.0479]],\n",
      "\n",
      "         [[-0.0493, -0.0493, -0.0418],\n",
      "          [-0.0274, -0.0309, -0.0169],\n",
      "          [ 0.0253,  0.0586, -0.0257]],\n",
      "\n",
      "         [[-0.0261, -0.0380, -0.0151],\n",
      "          [-0.0476, -0.0147,  0.0432],\n",
      "          [-0.0312,  0.0104,  0.0393]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0254, -0.0350, -0.0574],\n",
      "          [-0.0148, -0.0437, -0.0426],\n",
      "          [ 0.0104, -0.0162, -0.0173]],\n",
      "\n",
      "         [[ 0.0586, -0.0265,  0.0183],\n",
      "          [ 0.0232,  0.0511,  0.0350],\n",
      "          [-0.0081, -0.0555,  0.0034]],\n",
      "\n",
      "         [[-0.0265, -0.0199, -0.0410],\n",
      "          [ 0.0396,  0.0449, -0.0301],\n",
      "          [ 0.0575,  0.0396,  0.0307]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-0.0382,  0.0260,  0.0031],\n",
      "          [ 0.0498, -0.0337,  0.0512],\n",
      "          [ 0.0380,  0.0525, -0.0524]],\n",
      "\n",
      "         [[-0.0277, -0.0116, -0.0032],\n",
      "          [-0.0465,  0.0346,  0.0498],\n",
      "          [ 0.0558, -0.0563, -0.0568]],\n",
      "\n",
      "         [[ 0.0415,  0.0097,  0.0068],\n",
      "          [ 0.0538,  0.0462, -0.0574],\n",
      "          [-0.0027, -0.0328, -0.0445]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0046,  0.0127, -0.0317],\n",
      "          [ 0.0584,  0.0226,  0.0412],\n",
      "          [-0.0170,  0.0221, -0.0496]],\n",
      "\n",
      "         [[-0.0365,  0.0464, -0.0529],\n",
      "          [ 0.0432,  0.0378, -0.0265],\n",
      "          [ 0.0012, -0.0344, -0.0328]],\n",
      "\n",
      "         [[ 0.0104, -0.0421,  0.0219],\n",
      "          [-0.0343, -0.0069,  0.0412],\n",
      "          [ 0.0034, -0.0174, -0.0191]]],\n",
      "\n",
      "\n",
      "        [[[-0.0192, -0.0257,  0.0204],\n",
      "          [-0.0026, -0.0548, -0.0108],\n",
      "          [ 0.0212,  0.0411,  0.0181]],\n",
      "\n",
      "         [[-0.0588,  0.0177,  0.0382],\n",
      "          [ 0.0199,  0.0225,  0.0240],\n",
      "          [-0.0476,  0.0224, -0.0118]],\n",
      "\n",
      "         [[-0.0300,  0.0294, -0.0297],\n",
      "          [-0.0079, -0.0089, -0.0023],\n",
      "          [ 0.0264,  0.0501,  0.0501]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-0.0339,  0.0150,  0.0293],\n",
      "          [-0.0269, -0.0426, -0.0353],\n",
      "          [ 0.0516, -0.0113,  0.0180]],\n",
      "\n",
      "         [[ 0.0212,  0.0316,  0.0120],\n",
      "          [ 0.0381,  0.0034, -0.0487],\n",
      "          [-0.0104, -0.0128, -0.0391]],\n",
      "\n",
      "         [[-0.0347,  0.0163, -0.0543],\n",
      "          [-0.0432, -0.0410,  0.0350],\n",
      "          [-0.0094, -0.0324,  0.0082]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0349, -0.0136, -0.0170],\n",
      "          [ 0.0379,  0.0069, -0.0207],\n",
      "          [-0.0230,  0.0269,  0.0381]],\n",
      "\n",
      "         [[-0.0431, -0.0324,  0.0041],\n",
      "          [ 0.0507, -0.0569,  0.0132],\n",
      "          [ 0.0485,  0.0127, -0.0047]],\n",
      "\n",
      "         [[ 0.0479,  0.0484, -0.0495],\n",
      "          [-0.0228, -0.0545, -0.0582],\n",
      "          [ 0.0489,  0.0318,  0.0180]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 0.0352,  0.0447,  0.0394],\n",
      "          [ 0.0188,  0.0010, -0.0558],\n",
      "          [ 0.0381, -0.0587, -0.0041]],\n",
      "\n",
      "         [[ 0.0031,  0.0328, -0.0183],\n",
      "          [ 0.0069,  0.0387,  0.0257],\n",
      "          [-0.0402,  0.0464,  0.0324]],\n",
      "\n",
      "         [[-0.0280, -0.0470, -0.0544],\n",
      "          [ 0.0157, -0.0342,  0.0321],\n",
      "          [ 0.0212, -0.0143,  0.0175]]]])), ('conv2.bias', tensor([-0.0535,  0.0211, -0.0189, -0.0203, -0.0022,  0.0192, -0.0473, -0.0024,\n",
      "        -0.0335, -0.0271, -0.0492, -0.0140,  0.0516, -0.0524, -0.0428, -0.0310,\n",
      "         0.0403,  0.0391,  0.0573,  0.0177,  0.0523,  0.0245, -0.0482,  0.0270,\n",
      "         0.0198, -0.0351, -0.0434, -0.0558, -0.0301, -0.0195, -0.0040,  0.0317,\n",
      "        -0.0311, -0.0559, -0.0066, -0.0352, -0.0532,  0.0078, -0.0199, -0.0221,\n",
      "        -0.0382,  0.0009, -0.0349,  0.0011,  0.0005,  0.0074,  0.0284, -0.0536,\n",
      "         0.0439, -0.0499,  0.0063,  0.0117, -0.0523,  0.0312, -0.0201,  0.0310,\n",
      "         0.0173,  0.0560,  0.0478, -0.0454,  0.0192,  0.0310,  0.0004,  0.0041])), ('bn2.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])), ('bn2.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1.])), ('bn2.num_batches_tracked', tensor(0)), ('conv3.weight', tensor([[[[-8.1724e-03,  3.5896e-02, -6.8376e-03],\n",
      "          [ 7.1504e-03,  3.3549e-02, -2.1675e-02],\n",
      "          [-1.2336e-02, -3.8228e-02,  3.6543e-02]],\n",
      "\n",
      "         [[-1.3175e-02,  3.6096e-02, -2.9421e-02],\n",
      "          [-3.9410e-02, -6.9650e-03,  2.1156e-02],\n",
      "          [ 2.3562e-02,  1.6736e-03,  1.8204e-02]],\n",
      "\n",
      "         [[-5.7757e-03, -2.1695e-02, -3.6288e-02],\n",
      "          [-1.4472e-02,  1.6487e-02,  3.9488e-02],\n",
      "          [ 4.1417e-02, -1.1755e-02,  2.5679e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4671e-02,  2.3442e-02,  2.3566e-02],\n",
      "          [ 3.1458e-02,  1.7689e-02,  2.8391e-02],\n",
      "          [ 2.2562e-02, -1.5403e-02, -2.2681e-02]],\n",
      "\n",
      "         [[ 2.9300e-02,  2.6635e-02, -1.6075e-02],\n",
      "          [-2.2297e-02,  4.4308e-03, -3.6924e-02],\n",
      "          [ 6.3555e-03,  1.9691e-02, -3.7325e-02]],\n",
      "\n",
      "         [[ 3.9072e-02, -4.0848e-02,  2.7139e-02],\n",
      "          [ 2.5113e-02, -4.1530e-02,  2.1479e-02],\n",
      "          [ 4.0616e-02, -1.0960e-02, -3.6870e-02]]],\n",
      "\n",
      "\n",
      "        [[[-1.1375e-02, -3.1277e-02,  2.8000e-02],\n",
      "          [-8.9186e-03, -2.2200e-02, -2.6651e-02],\n",
      "          [-1.7899e-02,  1.7844e-02, -1.6860e-02]],\n",
      "\n",
      "         [[-2.1281e-02, -1.3649e-03, -1.3198e-02],\n",
      "          [ 1.7390e-02, -6.1786e-03,  5.6632e-03],\n",
      "          [ 5.3892e-03,  2.1167e-02,  2.6890e-02]],\n",
      "\n",
      "         [[-2.5608e-02, -4.1518e-02,  3.0878e-03],\n",
      "          [ 1.2742e-02,  3.1801e-02, -4.4767e-03],\n",
      "          [-3.7546e-02,  1.3420e-02, -2.3263e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3303e-02,  1.3302e-02,  8.5577e-05],\n",
      "          [ 2.9494e-02,  8.6447e-03, -2.7911e-02],\n",
      "          [ 2.8252e-02, -3.3744e-02,  1.8433e-02]],\n",
      "\n",
      "         [[ 1.5539e-02,  1.9983e-02,  4.1265e-02],\n",
      "          [-2.9729e-02,  3.3193e-02, -1.6108e-03],\n",
      "          [ 2.9856e-02,  1.5806e-02,  1.2955e-02]],\n",
      "\n",
      "         [[-3.2883e-02,  4.8290e-03,  3.5647e-02],\n",
      "          [-3.0445e-02,  3.3125e-03, -3.8972e-02],\n",
      "          [-2.6716e-02,  4.0433e-02,  2.1545e-03]]],\n",
      "\n",
      "\n",
      "        [[[-2.7197e-02,  2.6938e-02, -3.3094e-02],\n",
      "          [-2.1820e-02, -1.6243e-02, -3.3750e-02],\n",
      "          [-1.6117e-02, -3.4398e-02,  1.1128e-02]],\n",
      "\n",
      "         [[ 3.0078e-02,  2.7625e-02, -1.4615e-02],\n",
      "          [ 1.6972e-02, -3.1149e-03,  2.1140e-02],\n",
      "          [ 3.2085e-02,  1.9555e-02,  9.8698e-03]],\n",
      "\n",
      "         [[ 9.4626e-03, -1.6389e-02, -3.7681e-03],\n",
      "          [-4.0273e-02,  1.8584e-02,  1.0230e-03],\n",
      "          [ 3.5284e-02, -3.2473e-02, -1.9762e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.7010e-03,  8.7518e-03, -2.0809e-02],\n",
      "          [ 2.3916e-02,  2.1798e-02, -3.4311e-02],\n",
      "          [ 1.9600e-03, -4.1218e-02,  9.3217e-03]],\n",
      "\n",
      "         [[-2.8305e-02, -3.6328e-04, -1.8803e-02],\n",
      "          [ 1.8327e-02, -3.7187e-02, -2.7964e-02],\n",
      "          [-1.6008e-04, -6.9066e-03,  3.6583e-03]],\n",
      "\n",
      "         [[-7.6420e-03,  2.6094e-02,  1.3562e-02],\n",
      "          [ 2.8106e-02,  2.1600e-03, -3.2692e-02],\n",
      "          [-3.3047e-02, -5.8394e-04, -2.2843e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 3.6683e-02,  2.9332e-03, -2.5724e-02],\n",
      "          [-1.8587e-02,  3.6081e-02, -3.2110e-02],\n",
      "          [ 7.7544e-03, -3.1591e-02,  2.9719e-02]],\n",
      "\n",
      "         [[ 2.4339e-02,  3.1763e-02, -3.8598e-02],\n",
      "          [-9.6520e-03,  3.4348e-02, -3.0350e-03],\n",
      "          [ 1.6055e-02, -1.9202e-02,  1.5901e-02]],\n",
      "\n",
      "         [[ 2.7302e-02,  3.6693e-02,  8.9873e-03],\n",
      "          [ 3.3268e-02,  1.6650e-02, -1.7665e-02],\n",
      "          [ 3.6547e-02, -2.6745e-02,  7.3188e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.8903e-02,  3.9766e-02, -1.9615e-02],\n",
      "          [ 3.7634e-02, -2.9162e-02,  1.6772e-03],\n",
      "          [-2.5484e-02, -2.3806e-02,  2.9762e-02]],\n",
      "\n",
      "         [[ 2.5204e-02,  4.7409e-03,  3.2341e-04],\n",
      "          [-1.3325e-02, -5.3123e-03,  1.5182e-02],\n",
      "          [ 7.2650e-03,  1.6989e-02,  2.3625e-02]],\n",
      "\n",
      "         [[-2.0591e-02, -3.6096e-02,  4.1169e-02],\n",
      "          [-3.8813e-02, -4.0252e-02,  2.6619e-02],\n",
      "          [-3.7883e-02,  2.4005e-02, -1.6768e-02]]],\n",
      "\n",
      "\n",
      "        [[[-8.1663e-03,  2.5442e-02,  8.0275e-03],\n",
      "          [-2.0188e-02, -2.9161e-02,  3.5361e-03],\n",
      "          [ 3.0702e-02, -7.8353e-03,  1.5576e-02]],\n",
      "\n",
      "         [[ 5.7063e-03, -2.4055e-02,  2.4723e-03],\n",
      "          [-3.2593e-02,  1.9169e-02, -1.4893e-02],\n",
      "          [ 3.9948e-02,  2.9582e-02, -3.4651e-02]],\n",
      "\n",
      "         [[ 3.9075e-02, -9.4263e-03, -3.3499e-02],\n",
      "          [ 3.1447e-02,  3.2860e-02, -1.4110e-02],\n",
      "          [-2.8958e-02, -3.9671e-02, -2.9346e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.7501e-02, -1.6673e-02,  2.8170e-02],\n",
      "          [ 2.6742e-02, -1.9838e-02, -5.3362e-03],\n",
      "          [-1.1922e-02, -4.9455e-03, -8.8475e-03]],\n",
      "\n",
      "         [[-4.0741e-02,  2.2957e-02, -1.2342e-02],\n",
      "          [-3.3159e-02,  9.0751e-03,  3.0106e-02],\n",
      "          [-2.2225e-02, -2.1919e-02,  3.3099e-02]],\n",
      "\n",
      "         [[ 3.1893e-02,  1.9779e-02, -1.0593e-02],\n",
      "          [ 3.8843e-02, -3.8915e-02,  4.0017e-02],\n",
      "          [-2.2701e-02, -3.4050e-02,  7.9290e-03]]],\n",
      "\n",
      "\n",
      "        [[[ 4.0715e-02, -2.0482e-02, -1.3336e-02],\n",
      "          [ 1.5828e-04,  3.1844e-04, -3.2898e-02],\n",
      "          [ 6.2938e-03,  7.3584e-03,  1.8109e-02]],\n",
      "\n",
      "         [[ 2.0589e-02, -7.0794e-03,  2.7260e-02],\n",
      "          [-2.1424e-02, -2.0453e-02,  4.1062e-02],\n",
      "          [ 2.1837e-02, -3.9331e-03,  3.3881e-02]],\n",
      "\n",
      "         [[ 2.6422e-02,  3.2572e-03, -2.2717e-02],\n",
      "          [-1.8759e-02, -1.5595e-02, -2.0790e-02],\n",
      "          [ 3.4444e-02,  4.0409e-02,  7.8059e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.0182e-03,  2.4406e-03, -1.4871e-02],\n",
      "          [-1.9615e-02, -2.6180e-02, -2.5691e-02],\n",
      "          [-2.2290e-02, -1.4358e-04,  3.0545e-02]],\n",
      "\n",
      "         [[-1.4987e-02,  5.5849e-03,  1.8117e-02],\n",
      "          [ 3.1363e-02,  1.6697e-02, -2.3566e-02],\n",
      "          [-2.1101e-02,  6.9856e-04,  2.5992e-02]],\n",
      "\n",
      "         [[-1.8228e-02,  3.4309e-02,  3.0066e-02],\n",
      "          [ 1.1029e-02, -7.5643e-04,  1.4038e-02],\n",
      "          [ 1.1620e-02, -2.4994e-02,  8.1820e-03]]]])), ('conv3.bias', tensor([-0.0141,  0.0352,  0.0297,  0.0362, -0.0166, -0.0413,  0.0183, -0.0372,\n",
      "         0.0382,  0.0185,  0.0010,  0.0057, -0.0304,  0.0410,  0.0111,  0.0198,\n",
      "        -0.0279, -0.0064,  0.0250, -0.0189,  0.0336, -0.0109,  0.0203, -0.0290,\n",
      "         0.0376, -0.0352,  0.0367,  0.0289, -0.0198,  0.0158,  0.0358, -0.0200,\n",
      "        -0.0368,  0.0165,  0.0013, -0.0296, -0.0134,  0.0121, -0.0015,  0.0017,\n",
      "         0.0133, -0.0026, -0.0250,  0.0237, -0.0399,  0.0041, -0.0050,  0.0211,\n",
      "         0.0365, -0.0327, -0.0048, -0.0352, -0.0036, -0.0237,  0.0326,  0.0277,\n",
      "         0.0050, -0.0203,  0.0258, -0.0258,  0.0247, -0.0202, -0.0126,  0.0232,\n",
      "         0.0153, -0.0049,  0.0355,  0.0154,  0.0217,  0.0193, -0.0131, -0.0330,\n",
      "         0.0299,  0.0190,  0.0002,  0.0121, -0.0304,  0.0230,  0.0373, -0.0085,\n",
      "         0.0100, -0.0358, -0.0301, -0.0006, -0.0128,  0.0282, -0.0224,  0.0290,\n",
      "         0.0153, -0.0417,  0.0386, -0.0339,  0.0114,  0.0346, -0.0124, -0.0200,\n",
      "         0.0340,  0.0354,  0.0019, -0.0220,  0.0400,  0.0383,  0.0080, -0.0020,\n",
      "         0.0165, -0.0222, -0.0097, -0.0399, -0.0342, -0.0213, -0.0416, -0.0384,\n",
      "         0.0063, -0.0058, -0.0045,  0.0162, -0.0030, -0.0340, -0.0340, -0.0370,\n",
      "         0.0024,  0.0167, -0.0242, -0.0137,  0.0193,  0.0274,  0.0181, -0.0079])), ('bn3.weight', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn3.bias', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_mean', tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.])), ('bn3.running_var', tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
      "        1., 1.])), ('bn3.num_batches_tracked', tensor(0)), ('fc.weight', tensor([[-3.9469e-02, -2.4272e-02, -1.9951e-02,  ..., -6.7282e-03,\n",
      "          8.3994e-03,  6.0228e-03],\n",
      "        [ 3.1871e-02,  8.6598e-03,  3.8924e-02,  ..., -1.8825e-02,\n",
      "          3.1978e-02, -2.6340e-02],\n",
      "        [ 1.0898e-02, -2.9521e-02,  2.6862e-02,  ...,  4.3398e-02,\n",
      "          2.7427e-03, -3.3983e-02],\n",
      "        ...,\n",
      "        [-3.3291e-02, -1.2065e-02,  1.4250e-04,  ..., -2.6702e-02,\n",
      "         -4.3174e-02,  3.1374e-05],\n",
      "        [-3.6014e-02, -1.0786e-02, -2.5208e-02,  ..., -2.6999e-02,\n",
      "          2.6725e-02, -3.3645e-02],\n",
      "        [ 3.1048e-02,  3.5861e-02,  1.6902e-02,  ...,  3.1220e-02,\n",
      "          1.8361e-02,  1.4330e-02]])), ('fc.bias', tensor([-0.0288, -0.0145, -0.0282,  0.0165,  0.0278, -0.0263,  0.0187,  0.0360,\n",
      "        -0.0397,  0.0362]))])\n"
     ]
    }
   ],
   "source": [
    "from models.CNN import CNN\n",
    "cnn = CNN(C=1, W=28, H=28, K=3, S=2) \n",
    "\n",
    "# state_dict() : 모델의 상태 딕셔너리를 반환한다. \n",
    "print(cnn.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e61e1e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if pre_trained:\n",
    "#     model_dict = torch.load(save_path+model_name)\n",
    "#     model.load_state_dict(model_dict)\n",
    "\n",
    "def train(epoch, model, loss_func, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {loss.item():.6f}')\n",
    "            \n",
    "            \n",
    "    #torch.save(모델 파라미터 정보, 경로+이름)\n",
    "    torch.save(model.state_dict(), save_path + model_name)\n",
    "            \n",
    "\n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b26aae72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python run_cnn3.py --config_path ./configs/cnn.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17f85aef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ce_loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_39512/1679895195.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcnn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'ce_loss' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(epoch, cnn, ce_loss, train_loader, valid_loader, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e9e10e",
   "metadata": {},
   "source": [
    "# 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bfcabfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러오기\n",
    "# torch.load()\n",
    "import torch\n",
    "import os\n",
    "save_path = os.curdir + '/weights/'\n",
    "model_name = 'cnn.pth'\n",
    "state_dict = torch.load(save_path+model_name)\n",
    "#print(state_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "431262d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 토치 모델의 load_state_dict()를 활용\n",
    "cnn.load_state_dict(state_dict)\n",
    "\n",
    "# load는 언제 활용할까?\n",
    "# 1) 학습된 모델을 평가하기 위해 불러올 때\n",
    "# 2) 학습을 하다가 끊어졌을 때 다시 불러옴.\n",
    "# 3) 전이학습 (학습된 가중치를 불러와서 특정 영역의 레이어만을 학습)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafbb6f",
   "metadata": {},
   "source": [
    "## Tensorboard  \n",
    "tensorboard는 모델학습 과정의 loss나 기타 지표를 확인해서 학습이 잘되고 있는지, 모델 테스트 성능이  \n",
    "어떻게 나오는지를 시각화해줍니다.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bb122ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (1.0.0)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (1.41.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (2.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (2.26.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (3.3.4)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (3.19.1)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (0.37.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (1.21.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (2.3.3)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from tensorboard) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from absl-py>=0.4->tensorboard) (1.16.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard) (4.7.2)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.10.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "10598347",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ee5d0",
   "metadata": {},
   "source": [
    "먼저 runs 폴더를 만들고 그 안에 cnn 폴더를 만들어주세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e85ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writer를 정의합시다. \n",
    "writer = SummaryWriter('runs/cnn/')\n",
    "\n",
    "# writer.add_scalar를 통해서 손실함수 값, 또는 정확도를 기록할 수 있습니다.\n",
    "writer.add_scalar(\"그룹/변수명\", 변수, iter)\n",
    "# ex : 그룹 = train or valid 변수명 : loss or acc\n",
    "writer.add_scalar(\"train/loss\", train_loss, bactch_iter)\n",
    "\n",
    "# 여러 개의 값을 dictionary 활용\n",
    "writer.add_scalar(\"그룹/변수명\", 변수 dictionary, iter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "258b6dc9",
   "metadata": {},
   "source": [
    "## Quiz (Normal)  \n",
    "add_scalar는 train, test함수에서 어느 줄에 삽입해야 할까요?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37dfac4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if pre_trained:\n",
    "    model_dict = torch.load(save_path+model_name)\n",
    "    model.load_state_dict(model_dict)\n",
    "\n",
    "# 후보 1)\n",
    "writer = SummaryWriter('runs/cnn/')\n",
    "\n",
    "def train(epoch, model, loss_func, train_loader, valid_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        # 후보 2)\n",
    "        train_loss = loss_func(y_pred, y)\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        # 후보 3)\n",
    "        # wandb.log({\"train_loss\": train_loss})\n",
    "        writer.add_scalar(\"train/loss\", train_loss, epoch*batch_size + batch_index)\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {train_loss.item():.6f}')\n",
    "    torch.save(model.state_dict(), save_path + model_name)\n",
    "\n",
    "    for batch_index, (x, y) in enumerate(valid_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        val_loss = loss_func(y_pred, y)\n",
    "        \n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b58637bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "kernel_size = 3\n",
    "stride = 2\n",
    "pre_trained = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0737b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = './configs/'\n",
    "save_path = './weights/'\n",
    "model_name = 'cnn.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ac1e24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "6\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cnn = CNN(C=1, W=28, H=28, K=3, S=2) \n",
    "cnn = cnn.to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=0.001)\n",
    "writer = SummaryWriter('runs/cnn/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86cf57e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ye200\\anaconda3\\envs\\env\\lib\\site-packages\\ipykernel_launcher.py:28: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 | Batch Status: 0/60000             (0% | Loss: 2.293186\n",
      "Train Epoch: 1 | Batch Status: 3200/60000             (5% | Loss: 1.113714\n",
      "Train Epoch: 1 | Batch Status: 6400/60000             (11% | Loss: 1.064491\n",
      "Train Epoch: 1 | Batch Status: 9600/60000             (16% | Loss: 0.686955\n",
      "Train Epoch: 1 | Batch Status: 12800/60000             (21% | Loss: 0.965053\n",
      "Train Epoch: 1 | Batch Status: 16000/60000             (27% | Loss: 0.459951\n",
      "Train Epoch: 1 | Batch Status: 19200/60000             (32% | Loss: 0.819730\n",
      "Train Epoch: 1 | Batch Status: 22400/60000             (37% | Loss: 0.690969\n",
      "Train Epoch: 1 | Batch Status: 25600/60000             (43% | Loss: 0.686268\n",
      "Train Epoch: 1 | Batch Status: 28800/60000             (48% | Loss: 0.903146\n",
      "Train Epoch: 1 | Batch Status: 32000/60000             (53% | Loss: 0.559102\n",
      "Train Epoch: 1 | Batch Status: 35200/60000             (59% | Loss: 0.894578\n",
      "Train Epoch: 1 | Batch Status: 38400/60000             (64% | Loss: 0.765228\n",
      "Train Epoch: 1 | Batch Status: 41600/60000             (69% | Loss: 1.308519\n",
      "Train Epoch: 1 | Batch Status: 44800/60000             (75% | Loss: 1.100264\n",
      "Train Epoch: 1 | Batch Status: 48000/60000             (80% | Loss: 0.465319\n",
      "Train Epoch: 1 | Batch Status: 51200/60000             (85% | Loss: 0.805286\n",
      "Train Epoch: 1 | Batch Status: 54400/60000             (91% | Loss: 0.646653\n",
      "Train Epoch: 1 | Batch Status: 57600/60000             (96% | Loss: 0.581447\n",
      "Train Epoch: 2 | Batch Status: 0/60000             (0% | Loss: 0.566322\n",
      "Train Epoch: 2 | Batch Status: 3200/60000             (5% | Loss: 0.724684\n",
      "Train Epoch: 2 | Batch Status: 6400/60000             (11% | Loss: 0.772006\n",
      "Train Epoch: 2 | Batch Status: 9600/60000             (16% | Loss: 0.596862\n",
      "Train Epoch: 2 | Batch Status: 12800/60000             (21% | Loss: 0.640563\n",
      "Train Epoch: 2 | Batch Status: 16000/60000             (27% | Loss: 0.721540\n",
      "Train Epoch: 2 | Batch Status: 19200/60000             (32% | Loss: 0.953970\n",
      "Train Epoch: 2 | Batch Status: 22400/60000             (37% | Loss: 0.995232\n",
      "Train Epoch: 2 | Batch Status: 25600/60000             (43% | Loss: 0.865449\n",
      "Train Epoch: 2 | Batch Status: 28800/60000             (48% | Loss: 0.761107\n",
      "Train Epoch: 2 | Batch Status: 32000/60000             (53% | Loss: 0.938200\n",
      "Train Epoch: 2 | Batch Status: 35200/60000             (59% | Loss: 0.826681\n",
      "Train Epoch: 2 | Batch Status: 38400/60000             (64% | Loss: 0.670595\n",
      "Train Epoch: 2 | Batch Status: 41600/60000             (69% | Loss: 0.520668\n",
      "Train Epoch: 2 | Batch Status: 44800/60000             (75% | Loss: 0.938990\n",
      "Train Epoch: 2 | Batch Status: 48000/60000             (80% | Loss: 1.179451\n",
      "Train Epoch: 2 | Batch Status: 51200/60000             (85% | Loss: 0.806625\n",
      "Train Epoch: 2 | Batch Status: 54400/60000             (91% | Loss: 0.577565\n",
      "Train Epoch: 2 | Batch Status: 57600/60000             (96% | Loss: 0.745916\n",
      "Train Epoch: 3 | Batch Status: 0/60000             (0% | Loss: 0.970593\n",
      "Train Epoch: 3 | Batch Status: 3200/60000             (5% | Loss: 0.440729\n",
      "Train Epoch: 3 | Batch Status: 6400/60000             (11% | Loss: 0.654588\n",
      "Train Epoch: 3 | Batch Status: 9600/60000             (16% | Loss: 0.940330\n",
      "Train Epoch: 3 | Batch Status: 12800/60000             (21% | Loss: 0.720394\n",
      "Train Epoch: 3 | Batch Status: 16000/60000             (27% | Loss: 0.511379\n",
      "Train Epoch: 3 | Batch Status: 19200/60000             (32% | Loss: 0.370843\n",
      "Train Epoch: 3 | Batch Status: 22400/60000             (37% | Loss: 0.589331\n",
      "Train Epoch: 3 | Batch Status: 25600/60000             (43% | Loss: 0.791945\n",
      "Train Epoch: 3 | Batch Status: 28800/60000             (48% | Loss: 0.870673\n",
      "Train Epoch: 3 | Batch Status: 32000/60000             (53% | Loss: 0.801235\n",
      "Train Epoch: 3 | Batch Status: 35200/60000             (59% | Loss: 1.007694\n",
      "Train Epoch: 3 | Batch Status: 38400/60000             (64% | Loss: 0.648749\n",
      "Train Epoch: 3 | Batch Status: 41600/60000             (69% | Loss: 0.938329\n",
      "Train Epoch: 3 | Batch Status: 44800/60000             (75% | Loss: 0.882594\n",
      "Train Epoch: 3 | Batch Status: 48000/60000             (80% | Loss: 0.821543\n",
      "Train Epoch: 3 | Batch Status: 51200/60000             (85% | Loss: 0.737517\n",
      "Train Epoch: 3 | Batch Status: 54400/60000             (91% | Loss: 1.030945\n",
      "Train Epoch: 3 | Batch Status: 57600/60000             (96% | Loss: 1.131153\n",
      "Train Epoch: 4 | Batch Status: 0/60000             (0% | Loss: 0.588403\n",
      "Train Epoch: 4 | Batch Status: 3200/60000             (5% | Loss: 0.864343\n",
      "Train Epoch: 4 | Batch Status: 6400/60000             (11% | Loss: 0.794986\n",
      "Train Epoch: 4 | Batch Status: 9600/60000             (16% | Loss: 0.576946\n",
      "Train Epoch: 4 | Batch Status: 12800/60000             (21% | Loss: 0.651601\n",
      "Train Epoch: 4 | Batch Status: 16000/60000             (27% | Loss: 0.525115\n",
      "Train Epoch: 4 | Batch Status: 19200/60000             (32% | Loss: 0.647872\n",
      "Train Epoch: 4 | Batch Status: 22400/60000             (37% | Loss: 0.647996\n",
      "Train Epoch: 4 | Batch Status: 25600/60000             (43% | Loss: 0.865161\n",
      "Train Epoch: 4 | Batch Status: 28800/60000             (48% | Loss: 0.648929\n",
      "Train Epoch: 4 | Batch Status: 32000/60000             (53% | Loss: 0.505733\n",
      "Train Epoch: 4 | Batch Status: 35200/60000             (59% | Loss: 0.503849\n",
      "Train Epoch: 4 | Batch Status: 38400/60000             (64% | Loss: 0.720740\n",
      "Train Epoch: 4 | Batch Status: 41600/60000             (69% | Loss: 0.440938\n",
      "Train Epoch: 4 | Batch Status: 44800/60000             (75% | Loss: 0.884927\n",
      "Train Epoch: 4 | Batch Status: 48000/60000             (80% | Loss: 0.512128\n",
      "Train Epoch: 4 | Batch Status: 51200/60000             (85% | Loss: 0.865080\n",
      "Train Epoch: 4 | Batch Status: 54400/60000             (91% | Loss: 0.509608\n",
      "Train Epoch: 4 | Batch Status: 57600/60000             (96% | Loss: 0.339244\n",
      "Train Epoch: 5 | Batch Status: 0/60000             (0% | Loss: 0.814364\n",
      "Train Epoch: 5 | Batch Status: 3200/60000             (5% | Loss: 0.484468\n",
      "Train Epoch: 5 | Batch Status: 6400/60000             (11% | Loss: 0.795920\n",
      "Train Epoch: 5 | Batch Status: 9600/60000             (16% | Loss: 0.711460\n",
      "Train Epoch: 5 | Batch Status: 12800/60000             (21% | Loss: 0.729221\n",
      "Train Epoch: 5 | Batch Status: 16000/60000             (27% | Loss: 0.433483\n",
      "Train Epoch: 5 | Batch Status: 19200/60000             (32% | Loss: 1.112434\n",
      "Train Epoch: 5 | Batch Status: 22400/60000             (37% | Loss: 0.504451\n",
      "Train Epoch: 5 | Batch Status: 25600/60000             (43% | Loss: 0.720274\n",
      "Train Epoch: 5 | Batch Status: 28800/60000             (48% | Loss: 0.659710\n",
      "Train Epoch: 5 | Batch Status: 32000/60000             (53% | Loss: 1.086849\n",
      "Train Epoch: 5 | Batch Status: 35200/60000             (59% | Loss: 0.792040\n",
      "Train Epoch: 5 | Batch Status: 38400/60000             (64% | Loss: 0.733509\n",
      "Train Epoch: 5 | Batch Status: 41600/60000             (69% | Loss: 0.805832\n",
      "Train Epoch: 5 | Batch Status: 44800/60000             (75% | Loss: 0.604959\n",
      "Train Epoch: 5 | Batch Status: 48000/60000             (80% | Loss: 1.020508\n",
      "Train Epoch: 5 | Batch Status: 51200/60000             (85% | Loss: 0.434305\n",
      "Train Epoch: 5 | Batch Status: 54400/60000             (91% | Loss: 0.938151\n",
      "Train Epoch: 5 | Batch Status: 57600/60000             (96% | Loss: 0.506526\n",
      "=======================\n",
      " Test set: Average loss: 0.0229, Accuracy: 0.692\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    train(epoch, cnn, ce_loss, train_loader, valid_loader, optimizer)\n",
    "test(cnn, ce_loss, test_loader)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318e1b19",
   "metadata": {},
   "source": [
    "## 텐서보드의 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83689c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir \"경로\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
