{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28cd5fc8",
   "metadata": {},
   "source": [
    "# 딥러닝 프레임워크에서 구현 흐름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24d39f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5109d3f",
   "metadata": {},
   "source": [
    "1. 데이터 전처리, ** 중요 딥러닝 모델의 입력 shape와 출력 shape를 확인\n",
    "2. 데이터셋 클래스 작성\n",
    "3. 데이터셋 인스턴스를 활용해서 데이터 로더 할당\n",
    "4. 딥러닝 모델 작성\n",
    "5. 순전파 함수를 정의\n",
    "6. 손실함수 정의\n",
    "7. 최적화 기법 설정\n",
    "8. 하이퍼 파라미터를 설정\n",
    "9. 학습, 검증 시행\n",
    "10. 테스트 데이터로 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42319d11",
   "metadata": {},
   "source": [
    "## 3.1 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cba31f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # nn 모듈에는 뉴럴 네트워크를 구성하기 위해 필요한 모든 요소가 구현되어 있다. ex) Linear, Conv, RNN, 활성화함수 등\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23ad6daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396a3a5",
   "metadata": {},
   "source": [
    "## 옵티마이저 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34aa3e04",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23940/3011148206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparamters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# optimizer를 설정하기 위해서는 모델의 파라미터와, 러닝레이트가 필요하다!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.paramters(), lr=learning_rate)\n",
    "# optimizer를 설정하기 위해서는 모델의 파라미터와, 러닝레이트가 필요하다!!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d4c21",
   "metadata": {},
   "source": [
    "## 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "776bf97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실함수를 정의\n",
    "bce_loss = nn.BCELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "mse_loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd86bf24",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0600)\n"
     ]
    }
   ],
   "source": [
    "# 모델이 있고 예측값이 나왔다고 가정.\n",
    "y_hat = torch.tensor([1.1, 2.4, 3.1])\n",
    "y_target = torch.tensor([1, 2, 3])\n",
    "# 간단한게 로스 함수의 입력에 타깃 데이터와 예측 값을 넣으면 로스가 계산된다.\n",
    "loss1 = mse_loss(y_hat, y_target)\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ca9c93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.4982)\n"
     ]
    }
   ],
   "source": [
    "# cross entropy\n",
    "torch.manual_seed(1)\n",
    "output = torch.rand([4, 10]) # 2x10 행렬을 생성합니다. 2는 데이터의 수, 10은 클래스의 수\n",
    "target = torch.LongTensor([1, 9, 2, 3]) # 1과 9는 실제 정답\n",
    "loss2 = ce_loss(output, target)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7c32152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6614, 0.2669, 0.0617])\n",
      "tensor([0.6596, 0.5663, 0.5154])\n",
      "tensor([1., 0., 0.])\n",
      "tensor(0.6587)\n"
     ]
    }
   ],
   "source": [
    "# binary cross entropy\n",
    "torch.manual_seed(1)\n",
    "sigmoid = nn.Sigmoid()\n",
    "input_ = torch.randn(3)\n",
    "y_pred = sigmoid(input_)\n",
    "target = torch.empty(3).random_(2)\n",
    "\n",
    "loss1 = bce_loss(y_pred, target)\n",
    "print(input_)\n",
    "print(y_pred)\n",
    "print(target)\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d087ba",
   "metadata": {},
   "source": [
    "## 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e3578718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn 모듈에는 딥러닝 모델을 구축하기 위해 필요한 모든 요소가 구현되어 있다.\n",
    "# 우리는 이것들을 잘 갖다쓰기만 하면 된다.\n",
    "\n",
    "# y = wx + b\n",
    "linear_model = nn.Linear(1, 1) # 첫번째 인자 : 입력의 차원, 두번째 인자 : 출력의 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "74552bed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0469e-38, 1.0653e-38],\n",
      "        [1.0194e-38, 2.9389e-39],\n",
      "        [1.0194e-38, 9.9184e-39],\n",
      "        [2.9389e-39, 1.0194e-38],\n",
      "        [2.9389e-39, 9.2755e-39],\n",
      "        [9.0918e-39, 1.0010e-38],\n",
      "        [9.9184e-39, 1.0653e-38],\n",
      "        [9.1837e-39, 9.6428e-39],\n",
      "        [1.0010e-38, 9.1837e-39],\n",
      "        [8.9082e-39, 9.2755e-39]])\n",
      "tensor([1, 2, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "# 선형회귀 데이터 생성\n",
    "num_data = 1000\n",
    "a = torch.Tensor(10, 2) # 대문자 텐서는 모양을 입력받음\n",
    "print(a)\n",
    "a = torch.tensor([1, 2, 3, 4])\n",
    "print(a)\n",
    "# torch.init\n",
    "# init 모듈은 가중치나 텐서 데이터들의 분포를 초기화할 때 사용합니다.\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10) # 첫번째 인자 : 텐서 shape, 두번째, 세번째 : 범위\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1) \n",
    "y = 2*x + 3 # 실제 모델.\n",
    "y_noise = y + noise\n",
    "\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "17c1030f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3054]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.4991], requires_grad=True)\n",
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(linear_model.weight)\n",
    "print(linear_model.bias)\n",
    "print(linear_model.weight.grad)\n",
    "print(linear_model.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6fc313",
   "metadata": {},
   "source": [
    "## 지도학습 모델의 학습 순서  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9238691",
   "metadata": {},
   "source": [
    "1) 옵티마이저의 그래디언트를 0으로 만든다.   \n",
    "2) 데이터를 모델에 넣어서 값을 예측한다.  \n",
    "3) 정답 데이터와 예측값을 통해 손실함수를 계산한다.  \n",
    "4) 자동미분함수인 .backward()를 이용해 그래디언트를 계산한다.  \n",
    "5) 옵티마이저의 step() 함수를 호출한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a7115f4f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(192.5185)\n",
      "tensor(1.2783e+17)\n",
      "tensor(9.1067e+31)\n",
      "tensor(inf)\n",
      "tensor(inf)\n",
      "tensor(inf)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n",
      "tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1000\n",
    "target = y_noise\n",
    "for i in range(num_epochs):\n",
    "    optimizer.zero_grad() # 1\n",
    "    y_pred = linear_model(x) # 2\n",
    "    loss = mse_loss(y_pred, target) # 3\n",
    "    loss.backward() # 4\n",
    "    optimizer.step() # 5\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95ac7369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.0024]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([2.5626], requires_grad=True)\n",
      "tensor([[-0.0028]])\n",
      "tensor([-1.0385])\n",
      "tensor([[0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(linear_model.weight)\n",
    "print(linear_model.bias)\n",
    "print(linear_model.weight.grad)\n",
    "print(linear_model.bias.grad)\n",
    "optimizer.zero_grad()\n",
    "print(linear_model.weight.grad)\n",
    "print(linear_model.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff43d3",
   "metadata": {},
   "source": [
    "## 3.2 다중선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5a171a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y shape : torch.Size([1000, 1])\n"
     ]
    }
   ],
   "source": [
    "# 선형회귀 데이터 생성\n",
    "num_data = 1000\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 3), -10, 10) # 첫번째 인자 : 텐서 shape, 두번째, 세번째 : 범위\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1) \n",
    "weights = torch.tensor([2., 3., 1.])\n",
    "y = x.matmul(weights) + -1\n",
    "y = y.unsqueeze(1)\n",
    "y_noise = y + noise\n",
    "print(f\"y shape : {y_noise.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30716fae",
   "metadata": {},
   "source": [
    "$${y = w_1 x_1 + w_2 x_2 + w_3 x_3 + b}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4c3e25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중선형회귀 모델 : y = w_1*x_1 + w_2*x_2 + w_3*x_3 + b\n",
    "multi_model = nn.Linear(3, 1)\n",
    "optimizer = optim.SGD(multi_model.parameters(), lr=0.01)\n",
    "loss_func = nn.MSELoss()\n",
    "target = y_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b772d725",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(418.2192)\n",
      "tensor(1.3588)\n",
      "tensor(1.2272)\n",
      "tensor(1.1394)\n",
      "tensor(1.0807)\n",
      "tensor(1.0415)\n",
      "tensor(1.0153)\n",
      "tensor(0.9978)\n",
      "tensor(0.9862)\n",
      "tensor(0.9784)\n",
      "tensor(0.9731)\n",
      "tensor(0.9697)\n",
      "tensor(0.9673)\n",
      "tensor(0.9658)\n",
      "tensor(0.9647)\n",
      "tensor(0.9641)\n",
      "tensor(0.9636)\n",
      "tensor(0.9633)\n",
      "tensor(0.9631)\n",
      "tensor(0.9629)\n",
      "tensor(0.9628)\n",
      "tensor(0.9628)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n",
      "tensor(0.9627)\n"
     ]
    }
   ],
   "source": [
    "for i in range(num_epochs):\n",
    "    optimizer.zero_grad() # 1\n",
    "    y_pred = multi_model(x) # 2\n",
    "    loss = mse_loss(y_pred, target) # 3\n",
    "    loss.backward() # 4\n",
    "    optimizer.step() # 5\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a7f71328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.0000, 3.0048, 1.0018]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.9799], requires_grad=True)\n",
      "tensor([[ 8.9372e-06,  6.0501e-06, -1.7341e-06]])\n",
      "tensor([2.7530e-06])\n",
      "tensor([[0., 0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(multi_model.weight)\n",
    "print(multi_model.bias)\n",
    "print(multi_model.weight.grad)\n",
    "print(multi_model.bias.grad)\n",
    "optimizer.zero_grad()\n",
    "print(multi_model.weight.grad)\n",
    "print(multi_model.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a88c3f",
   "metadata": {},
   "source": [
    "# 퀴즈 (Easy)  \n",
    "1) 하이퍼파라미터를 조정해서 모델의 가중치와 편향이 정답에 가깝도록 학습시켜보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb7cc9",
   "metadata": {},
   "source": [
    "## 3.3 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ecbaa1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = [[0, 2], [1, 2], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f4d6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(2, 1)\n",
    "sigmoid = nn.Sigmoid()\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97900692",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9818)\n",
      "tensor(0.9669)\n",
      "tensor(0.9522)\n",
      "tensor(0.9380)\n",
      "tensor(0.9242)\n",
      "tensor(0.9109)\n",
      "tensor(0.8980)\n",
      "tensor(0.8857)\n",
      "tensor(0.8738)\n",
      "tensor(0.8625)\n",
      "tensor(0.8518)\n",
      "tensor(0.8416)\n",
      "tensor(0.8319)\n",
      "tensor(0.8228)\n",
      "tensor(0.8142)\n",
      "tensor(0.8061)\n",
      "tensor(0.7984)\n",
      "tensor(0.7913)\n",
      "tensor(0.7846)\n",
      "tensor(0.7782)\n",
      "tensor(0.7723)\n",
      "tensor(0.7666)\n",
      "tensor(0.7613)\n",
      "tensor(0.7562)\n",
      "tensor(0.7513)\n",
      "tensor(0.7466)\n",
      "tensor(0.7421)\n",
      "tensor(0.7377)\n",
      "tensor(0.7334)\n",
      "tensor(0.7292)\n",
      "tensor(0.7250)\n",
      "tensor(0.7209)\n",
      "tensor(0.7169)\n",
      "tensor(0.7129)\n",
      "tensor(0.7090)\n",
      "tensor(0.7050)\n",
      "tensor(0.7011)\n",
      "tensor(0.6973)\n",
      "tensor(0.6934)\n",
      "tensor(0.6896)\n",
      "tensor(0.6858)\n",
      "tensor(0.6820)\n",
      "tensor(0.6782)\n",
      "tensor(0.6745)\n",
      "tensor(0.6708)\n",
      "tensor(0.6671)\n",
      "tensor(0.6635)\n",
      "tensor(0.6598)\n",
      "tensor(0.6563)\n",
      "tensor(0.6527)\n",
      "tensor(0.6492)\n",
      "tensor(0.6456)\n",
      "tensor(0.6422)\n",
      "tensor(0.6387)\n",
      "tensor(0.6353)\n",
      "tensor(0.6319)\n",
      "tensor(0.6286)\n",
      "tensor(0.6253)\n",
      "tensor(0.6220)\n",
      "tensor(0.6188)\n",
      "tensor(0.6156)\n",
      "tensor(0.6124)\n",
      "tensor(0.6092)\n",
      "tensor(0.6061)\n",
      "tensor(0.6031)\n",
      "tensor(0.6000)\n",
      "tensor(0.5970)\n",
      "tensor(0.5941)\n",
      "tensor(0.5911)\n",
      "tensor(0.5882)\n",
      "tensor(0.5854)\n",
      "tensor(0.5825)\n",
      "tensor(0.5798)\n",
      "tensor(0.5770)\n",
      "tensor(0.5743)\n",
      "tensor(0.5716)\n",
      "tensor(0.5689)\n",
      "tensor(0.5663)\n",
      "tensor(0.5637)\n",
      "tensor(0.5612)\n",
      "tensor(0.5587)\n",
      "tensor(0.5562)\n",
      "tensor(0.5537)\n",
      "tensor(0.5513)\n",
      "tensor(0.5489)\n",
      "tensor(0.5466)\n",
      "tensor(0.5442)\n",
      "tensor(0.5419)\n",
      "tensor(0.5397)\n",
      "tensor(0.5375)\n",
      "tensor(0.5353)\n",
      "tensor(0.5331)\n",
      "tensor(0.5309)\n",
      "tensor(0.5288)\n",
      "tensor(0.5268)\n",
      "tensor(0.5247)\n",
      "tensor(0.5227)\n",
      "tensor(0.5207)\n",
      "tensor(0.5187)\n",
      "tensor(0.5168)\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "num_epochs = 1000\n",
    "for i in range(num_epochs):\n",
    "    optimizer.zero_grad() # 1\n",
    "    y_pred = sigmoid(linear_model(x_train)) # 2\n",
    "    loss = bce_loss(y_pred, y_train) # 3\n",
    "    loss.backward() # 4\n",
    "    optimizer.step() # 5\n",
    "    \n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14190f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[0.2931, 0.0539]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.3991], requires_grad=True)\n",
      "tensor([[-0.1656,  0.0978]])\n",
      "tensor([0.1438])\n",
      "tensor([[0., 0.]])\n",
      "tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(linear_model.weight)\n",
    "print(linear_model.bias)\n",
    "print(linear_model.weight.grad)\n",
    "print(linear_model.bias.grad)\n",
    "optimizer.zero_grad()\n",
    "print(linear_model.weight.grad)\n",
    "print(linear_model.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af233f82",
   "metadata": {},
   "source": [
    "## 3.4 클래스를 통한 회귀 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879c3d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 부모클래스인 nn.Module의 생성자를 먼저 호출한다.\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear_layer = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 순전파 함수 : 입력값 x를 생성자에 정의된 레이어에 넣어서 값을 예측한다.\n",
    "        return self.linear_layer(x)\n",
    "    \n",
    "\n",
    "class MultiRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiRegression, self).__init__()\n",
    "        self.multi_layer = nn.Linear(3, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.multi_layer(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc331f",
   "metadata": {},
   "source": [
    "## 퀴즈 (Normal)  \n",
    "위 세 가지 모델을 구현했으면 또 반복문을 통해 학습시켜야 합니다.  \n",
    "이는 귀찮은 과정이니 함수 형태로 만들어서 코드의 반복을 줄여봅시다.  \n",
    "텐서플로우에서 사용했던 fit 함수를 직접 만들어봅시다.  \n",
    "fit() 함수는 model, optimizer, loss_func, x_train, y_train, epochs를 입력으로 받습니다.  \n",
    "위에서 수행한 반복문을 함수형태로 만들어서 세 가지 회귀모델에 적용할 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0f487",
   "metadata": {},
   "source": [
    "## Softmax 회귀  \n",
    "https://wikidocs.net/60575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fa206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
