{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fcd353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset \n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "epochs = 5\n",
    "kernel_size = 3\n",
    "stride = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d93bf",
   "metadata": {},
   "source": [
    "## 모듈화  \n",
    "코드의 가독성을 좋게 하고 보수 및 관리를 쉽게 합니다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc57d444",
   "metadata": {},
   "source": [
    "```\n",
    "+-- configs/\n",
    "|   +-- cnn.yaml\n",
    "+-- dataset/\n",
    "|   +-- mnist_data/...\n",
    "|   +-- MNIST_LOADER.py\n",
    "+-- models/\n",
    "|   +-- cnn.py\n",
    "|   +-- res_net.py\n",
    "+-- runs/\n",
    "|   +-- cnn/...\n",
    "|   +-- experiments/...\n",
    "+-- wetights/\n",
    "|   +-- cnn.pth\n",
    "+-- argparse_tutorial.py\n",
    "+-- README.md\n",
    "+-- run_cnn.py\n",
    "+-- run_cnn2.py\n",
    "+-- requirements.txt\n",
    "+-- utils.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafed4c5",
   "metadata": {},
   "source": [
    "## Quiz (Easy)  \n",
    "위 구조와 같이 모듈화를 진행하겠습니다.  \n",
    "1) dataset 폴더를 만들고 mnist_data 폴더를 옮겨주세요. 그리고 MNIST_LOADER.py를 dataset에 만듭니다.   \n",
    "2) models 폴더를 만들고 cnn.py, res_net.py를 만들고 내용을 채워주세요   \n",
    "3) runs 폴더를 만들어주세요.   \n",
    "4) weights 폴더를 만들어주세요.   \n",
    "5) requirements.txt 파일을 만들어주세요.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25004f82",
   "metadata": {},
   "source": [
    "## Quiz (Hard)\n",
    "\n",
    "학습에 필요한 각 모듈들을 불러와서 학습 및 테스트를 수행하세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8af7ceba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting run_cnn3.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile run_cnn3.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import argparse\n",
    "import yaml\n",
    "from models.CNN import CNN\n",
    "from dataset.MNIST_LOADER import make_loader\n",
    "\n",
    "def train(epoch, model, loss_func, train_loader, optimizer):\n",
    "    model.train()\n",
    "    for batch_index, (x, y) in enumerate(train_loader):\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(x)\n",
    "        loss = loss_func(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_index % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch+1} | Batch Status: {batch_index*len(x)}/{len(train_loader.dataset)} \\\n",
    "            ({100. * batch_index * batch_size / len(train_loader.dataset):.0f}% | Loss: {loss.item():.6f}')\n",
    "\n",
    "def test(model, loss_func, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct_count = 0\n",
    "    for x, y in test_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x)\n",
    "        test_loss += loss_func(y_pred, y).item()\n",
    "        pred = y_pred.data.max(1, keepdim=True)[1]\n",
    "        # torch.eq : Computes element-wise equality. return counts value\n",
    "        correct_count += pred.eq(y.data.view_as(pred)).cpu().sum()\n",
    "    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'=======================\\n Test set: Average loss: {test_loss:.4f}, Accuracy: {correct_count/len(test_loader.dataset):.3}')\n",
    "\n",
    "parser = argparse.ArgumentParser(description='run_cnn3')\n",
    "parser.add_argument('--config_path', type=str, default='./configs/cnn.yaml', help='config file path')\n",
    "args = parser.parse_args()\n",
    "config_path = args.config_path\n",
    "\n",
    "with open(config_path ,'r') as f:\n",
    "    config = yaml.load(f, Loader=yaml.FullLoader)\n",
    "    print(type(config))\n",
    "    \n",
    "batch_size = config['batch_size']\n",
    "lr = config['learning_rate']\n",
    "epochs = config['epochs']\n",
    "kernel_size = config['kernel_size']\n",
    "stride = config['stride']\n",
    "\n",
    "train_loader, valid_loader, test_loader, shape = make_loader(batch_size)\n",
    "C = shape[0]\n",
    "W = shape[1]\n",
    "H = shape[2]\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "cnn = CNN(C=C, W=W, H=H, K=3, S=2) \n",
    "cnn = cnn.to(device)\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(cnn.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train(epoch, cnn, ce_loss, train_loader, optimizer)\n",
    "\n",
    "test(cnn, ce_loss, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61461ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_cnn3.py --config_path ./configs/cnn.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf6820",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
