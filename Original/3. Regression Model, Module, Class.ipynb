{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57602ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d893bb09",
   "metadata": {},
   "source": [
    "#  파이토치를 활용한 딥러닝 구현 흐름  \n",
    "1. 데이터 전처리, 딥러닝 모델의 입력과 출력 확인  \n",
    "2. 데이터셋 클래스 작성  \n",
    "3. 데이터 로더 활용  \n",
    "4. 딥러닝 모델 작성  \n",
    "5. 순전파 정의  \n",
    "6. 손실함수 정의  \n",
    "7. 최적화 기법 설정\n",
    "8. 하이퍼파라미터 설정\n",
    "9. 학습/검증 시행  \n",
    "10. 테스트 데이터로 추론  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42319d11",
   "metadata": {},
   "source": [
    "## 3.1 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "cba31f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn # nn 모듈에는 뉴럴 네트워크를 구성하기 위해 필요한 모든 요소가 구현되어 있다. ex) Linear, Conv, RNN, 활성화함수 등\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "23ad6daf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f396a3a5",
   "metadata": {},
   "source": [
    "## 옵티마이저 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "020417b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr=0.001)\n",
    "#optimizer = optim.RMSprop(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056d4c21",
   "metadata": {},
   "source": [
    "## 손실함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f3336b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 퀴즈 MSELoss와 크로스엔트로피 로스는 각각 어떤 문제에 사용할까요?\n",
    "mse_loss = nn.MSELoss()\n",
    "ce_loss = nn.CrossEntropyLoss()\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ed2a0846",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0600)\n"
     ]
    }
   ],
   "source": [
    "# 손실함수를 사용해서 직접 계산해봅시다.\n",
    "y_hat = torch.tensor([1.1, 2.4, 3.1])\n",
    "y = torch.tensor([1, 2, 3])\n",
    "loss1 = mse_loss(y_hat, y)\n",
    "print(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "d354e2ee",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7576, 0.2793, 0.4031, 0.7347, 0.0293, 0.7999, 0.3971, 0.7544, 0.5695,\n",
      "         0.4388],\n",
      "        [0.6387, 0.5247, 0.6826, 0.3051, 0.4635, 0.4550, 0.5725, 0.4980, 0.9371,\n",
      "         0.6556]])\n",
      "torch.Size([2, 10])\n",
      "torch.Size([2])\n",
      "tensor(2.4004)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "output = torch.rand([2, 10])\n",
    "target = torch.LongTensor([1, 9])\n",
    "\n",
    "print(output)\n",
    "print(output.shape)\n",
    "print(target.shape)\n",
    "print(ce_loss(output, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "da7efb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6614, 0.2669, 0.0617], requires_grad=True)\n",
      "torch.Size([3])\n",
      "tensor([1., 0., 0.])\n",
      "torch.Size([3])\n",
      "tensor(0.6587, grad_fn=<BinaryCrossEntropyBackward0>)\n",
      "tensor(0.0001)\n",
      "tensor(9.2001)\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1)\n",
    "sigmoid = nn.Sigmoid()\n",
    "loss = nn.BCELoss()\n",
    "input_ = torch.randn(3, requires_grad=True)\n",
    "print(input_)\n",
    "print(input_.shape)\n",
    "\n",
    "target = torch.empty(3).random_(2)\n",
    "print(target)\n",
    "print(target.shape)\n",
    "output = loss(sigmoid(input_), target)\n",
    "output2 = loss(sigmoid(torch.tensor(9.2)), torch.tensor(1.0))\n",
    "output3 = loss(sigmoid(torch.tensor(-9.2)), torch.tensor(1.0))\n",
    "print(output)\n",
    "print(output2)\n",
    "print(output3)\n",
    "# 3개의 독립적인 이진 분류 문제로 접근, \n",
    "# Binary Cross Entropy 함수를 여러 개의 클래스를 가지는 문제의loss 계산에 활용할 수 있음.\n",
    "# 참고 : https://kh-kim.gitbook.io/natural-language-processing-with-pytorch/00-cover-7/06-multi_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "3a97a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4973)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor([0.35, -2.1, -0.28])\n",
    "y_hat = sigmoid(y)\n",
    "target = torch.tensor([1.0, 0.0, 1.0])\n",
    "loss2 = bce_loss(y_hat, target)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d087ba",
   "metadata": {},
   "source": [
    "## 선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd37ed90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 간단한 선형 회귀 모델  y_pred = wx + b\n",
    "linear_model = nn.Linear(1, 1)\n",
    "label = y_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5034d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 노이즈가 추가된 데이터 생성\n",
    "num_data = 1000\n",
    "num_epoch = 100\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)\n",
    "y = 2*x + 3\n",
    "y_noise = y + noise\n",
    "\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "17db75a2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[2.0012]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([2.5398], requires_grad=True)\n",
      "tensor([[0.0007]])\n",
      "tensor([-0.9456])\n"
     ]
    }
   ],
   "source": [
    "## print(linear_model.weight)\n",
    "print(linear_model.weight)\n",
    "print(linear_model.bias)\n",
    "print(linear_model.weight.grad)\n",
    "print(linear_model.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6fc313",
   "metadata": {},
   "source": [
    "## 지도학습 모델의 학습 순서  \n",
    "1) 옵티마이저의 그래디언트를 0으로 만든다.  \n",
    "2) 데이터를 모델에 넣어서 값을 예측한다.  \n",
    "3) 정답 데이터와 예측 값을 통해 손실함수를 계산한다.  \n",
    "4) 자동미분 함수인 .backward()를 통해 그래디언트를 계산한다.  \n",
    "5) 옵티마이저의 step()함수를 호출한다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "8572365e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "275.2430725097656\n",
      "tensor(275.2431)\n",
      "150.18048095703125\n",
      "136.97288513183594\n",
      "135.57144165039062\n",
      "135.41636657714844\n",
      "135.39312744140625\n",
      "135.38406372070312\n",
      "135.37680053710938\n",
      "135.36990356445312\n",
      "135.36334228515625\n",
      "135.35702514648438\n",
      "tensor(135.3570)\n",
      "135.35096740722656\n",
      "135.34515380859375\n",
      "135.33956909179688\n",
      "135.33416748046875\n",
      "135.32901000976562\n",
      "135.32406616210938\n",
      "135.31930541992188\n",
      "135.31472778320312\n",
      "135.3103485107422\n",
      "135.30612182617188\n",
      "tensor(135.3061)\n",
      "135.3020782470703\n",
      "135.2981719970703\n",
      "135.29443359375\n",
      "135.2908477783203\n",
      "135.2873992919922\n",
      "135.28408813476562\n",
      "135.28089904785156\n",
      "135.27784729003906\n",
      "135.27491760253906\n",
      "135.27207946777344\n",
      "tensor(135.2721)\n",
      "135.26939392089844\n",
      "135.26678466796875\n",
      "135.2642822265625\n",
      "135.2618865966797\n",
      "135.25958251953125\n",
      "135.25735473632812\n",
      "135.25521850585938\n",
      "135.25320434570312\n",
      "135.25123596191406\n",
      "135.2493438720703\n",
      "tensor(135.2493)\n",
      "135.24752807617188\n",
      "135.2458038330078\n",
      "135.24412536621094\n",
      "135.24253845214844\n",
      "135.24098205566406\n",
      "135.239501953125\n",
      "135.2380828857422\n",
      "135.23672485351562\n",
      "135.23541259765625\n",
      "135.23414611816406\n",
      "tensor(135.2341)\n",
      "135.23292541503906\n",
      "135.23178100585938\n",
      "135.23065185546875\n",
      "135.22958374023438\n",
      "135.22854614257812\n",
      "135.22756958007812\n",
      "135.22659301757812\n",
      "135.2257080078125\n",
      "135.2248077392578\n",
      "135.22398376464844\n",
      "tensor(135.2240)\n",
      "135.22315979003906\n",
      "135.22239685058594\n",
      "135.22164916992188\n",
      "135.22093200683594\n",
      "135.22023010253906\n",
      "135.21958923339844\n",
      "135.2189483642578\n",
      "135.21832275390625\n",
      "135.21774291992188\n",
      "135.21719360351562\n",
      "tensor(135.2172)\n",
      "135.21664428710938\n",
      "135.21612548828125\n",
      "135.2156219482422\n",
      "135.2151336669922\n",
      "135.21469116210938\n",
      "135.21424865722656\n",
      "135.21380615234375\n",
      "135.21340942382812\n",
      "135.2130126953125\n",
      "135.212646484375\n",
      "tensor(135.2126)\n",
      "135.2122802734375\n",
      "135.21194458007812\n",
      "135.21160888671875\n",
      "135.21127319335938\n",
      "135.21096801757812\n",
      "135.21067810058594\n",
      "135.21038818359375\n",
      "135.2101287841797\n",
      "135.20985412597656\n",
      "135.20960998535156\n",
      "tensor(135.2096)\n",
      "135.20936584472656\n",
      "135.20912170410156\n",
      "135.2089080810547\n",
      "135.2086944580078\n",
      "135.20848083496094\n",
      "135.2082977294922\n",
      "135.20809936523438\n",
      "135.20790100097656\n",
      "135.20774841308594\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad() # 옵티마이저의 그래디언트를 0으로 초기화\n",
    "    output = linear_model(x) # 모델을 통해 값을 예측\n",
    "    loss = mse_loss(output, label) # 정답 데이터와 예측 값과의 차이를 통해 손실함수 계산\n",
    "    print(loss.item())\n",
    "    loss.backward() # 자동미분을 통해 가중치에 대한 그래디언트 계산 calculate gradient\n",
    "    optimizer.step() # 계산한 그래디언트를 통해 가중치 업데이트 w = w - alpha * gradient\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "07216742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0297]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([2.9756], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(linear_model.weight)\n",
    "print(linear_model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e80d7a",
   "metadata": {},
   "source": [
    "# 퀴즈 (Easy)  \n",
    "위 모델은 y = 2x + 3 으로 학습되지 않았습니다.  \n",
    "이를 개선하기 위해서는 하이퍼 파라미터를 조정해야 합니다.  \n",
    "1) 위 선형회귀모델에서 하이퍼파라미터의 종류는 뭐가 있을까요?  \n",
    "2) 하이퍼파라미터를 조정해서 모델의 가중치와 편향이 정답에 가깝도록 학습시켜보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ff43d3",
   "metadata": {},
   "source": [
    "## 3.2 다중선형회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "72a96044",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "y.shape torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "num_data = 1000\n",
    "num_epoch = 2000\n",
    "\n",
    "x = init.uniform_(torch.Tensor(10, 3), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(10, 1), std=1)\n",
    "weights = torch.tensor([2., 3., 1.])\n",
    "print(x.matmul(weights).shape)\n",
    "y = x.matmul(weights) + -1\n",
    "y = y.unsqueeze(1)\n",
    "print(f\"y.shape {y.shape}\")\n",
    "y_noise = y + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "43db4930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중회귀 모델 구현\n",
    "multi_model = nn.Linear(3, 1)\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저\n",
    "optimizer = optim.SGD(multi_model.parameters(), lr=0.001)\n",
    "label = y_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "33e20d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "481.73858642578125\n",
      "tensor(481.7386)\n",
      "399.367431640625\n",
      "332.70709228515625\n",
      "278.6700134277344\n",
      "234.78012084960938\n",
      "199.0516357421875\n",
      "169.89163208007812\n",
      "146.02218627929688\n",
      "126.41786193847656\n",
      "110.2555160522461\n",
      "96.87440490722656\n",
      "85.7437515258789\n",
      "76.43717956542969\n",
      "68.61190032958984\n",
      "61.99226760864258\n",
      "56.3564453125\n",
      "51.525718688964844\n",
      "47.3560791015625\n",
      "43.731285095214844\n",
      "40.55742645263672\n",
      "37.75852966308594\n",
      "35.273006439208984\n",
      "33.050865173339844\n",
      "31.05143165588379\n",
      "29.241497039794922\n",
      "27.593917846679688\n",
      "26.08638572692871\n",
      "24.700531005859375\n",
      "23.421165466308594\n",
      "22.235654830932617\n",
      "21.13344383239746\n",
      "20.105655670166016\n",
      "19.144817352294922\n",
      "18.244544982910156\n",
      "17.399370193481445\n",
      "16.604595184326172\n",
      "15.85614013671875\n",
      "15.150433540344238\n",
      "14.4843111038208\n",
      "13.854985237121582\n",
      "13.259961128234863\n",
      "12.697000503540039\n",
      "12.16407585144043\n",
      "11.659339904785156\n",
      "11.181109428405762\n",
      "10.72783088684082\n",
      "10.29808235168457\n",
      "9.890525817871094\n",
      "9.503948211669922\n",
      "9.137191772460938\n",
      "8.789196014404297\n",
      "8.458942413330078\n",
      "8.145503044128418\n",
      "7.847989559173584\n",
      "7.565570831298828\n",
      "7.297450065612793\n",
      "7.042900085449219\n",
      "6.801217555999756\n",
      "6.571732521057129\n",
      "6.353824138641357\n",
      "6.14690637588501\n",
      "5.950408935546875\n",
      "5.763805866241455\n",
      "5.586594581604004\n",
      "5.418292999267578\n",
      "5.258451461791992\n",
      "5.106640338897705\n",
      "4.962451457977295\n",
      "4.825497627258301\n",
      "4.695417881011963\n",
      "4.571859359741211\n",
      "4.454490661621094\n",
      "4.343003273010254\n",
      "4.237093925476074\n",
      "4.13648796081543\n",
      "4.040912628173828\n",
      "3.9501144886016846\n",
      "3.8638546466827393\n",
      "3.7818996906280518\n",
      "3.7040374279022217\n",
      "3.6300559043884277\n",
      "3.5597596168518066\n",
      "3.4929676055908203\n",
      "3.429495334625244\n",
      "3.3691840171813965\n",
      "3.3118672370910645\n",
      "3.2573955059051514\n",
      "3.205625534057617\n",
      "3.1564221382141113\n",
      "3.109656572341919\n",
      "3.0652031898498535\n",
      "3.0229485034942627\n",
      "2.9827778339385986\n",
      "2.9445855617523193\n",
      "2.9082775115966797\n",
      "2.8737547397613525\n",
      "2.840928316116333\n",
      "2.809713363647461\n",
      "2.7800235748291016\n",
      "2.7517871856689453\n",
      "2.7249321937561035\n",
      "tensor(2.7249)\n",
      "2.699383497238159\n",
      "2.6750810146331787\n",
      "2.6519601345062256\n",
      "2.6299569606781006\n",
      "2.6090192794799805\n",
      "2.5890941619873047\n",
      "2.570127487182617\n",
      "2.5520753860473633\n",
      "2.5348877906799316\n",
      "2.518522262573242\n",
      "2.502939462661743\n",
      "2.4880964756011963\n",
      "2.4739580154418945\n",
      "2.46049165725708\n",
      "2.4476561546325684\n",
      "2.435427665710449\n",
      "2.4237706661224365\n",
      "2.412658214569092\n",
      "2.40206241607666\n",
      "2.3919577598571777\n",
      "2.3823189735412598\n",
      "2.3731234073638916\n",
      "2.364348888397217\n",
      "2.355976104736328\n",
      "2.34798002243042\n",
      "2.3403449058532715\n",
      "2.3330516815185547\n",
      "2.3260843753814697\n",
      "2.319427251815796\n",
      "2.3130640983581543\n",
      "2.306978702545166\n",
      "2.301157236099243\n",
      "2.2955873012542725\n",
      "2.2902586460113525\n",
      "2.285155773162842\n",
      "2.2802681922912598\n",
      "2.275588274002075\n",
      "2.271101474761963\n",
      "2.2667996883392334\n",
      "2.2626750469207764\n",
      "2.258716106414795\n",
      "2.2549171447753906\n",
      "2.2512669563293457\n",
      "2.2477645874023438\n",
      "2.2443950176239014\n",
      "2.2411584854125977\n",
      "2.2380423545837402\n",
      "2.2350449562072754\n",
      "2.2321572303771973\n",
      "2.229377269744873\n",
      "2.2266948223114014\n",
      "2.2241108417510986\n",
      "2.2216176986694336\n",
      "2.2192094326019287\n",
      "2.2168850898742676\n",
      "2.2146377563476562\n",
      "2.2124669551849365\n",
      "2.210365056991577\n",
      "2.2083301544189453\n",
      "2.206364393234253\n",
      "2.2044544219970703\n",
      "2.202603340148926\n",
      "2.2008087635040283\n",
      "2.1990654468536377\n",
      "2.197373151779175\n",
      "2.195727825164795\n",
      "2.194126605987549\n",
      "2.1925699710845947\n",
      "2.1910548210144043\n",
      "2.1895782947540283\n",
      "2.188138961791992\n",
      "2.1867356300354004\n",
      "2.185368299484253\n",
      "2.1840291023254395\n",
      "2.182723045349121\n",
      "2.1814465522766113\n",
      "2.1801955699920654\n",
      "2.1789772510528564\n",
      "2.1777772903442383\n",
      "2.1766037940979004\n",
      "2.175457715988159\n",
      "2.1743292808532715\n",
      "2.173222780227661\n",
      "2.172137498855591\n",
      "2.1710712909698486\n",
      "2.17002272605896\n",
      "2.1689932346343994\n",
      "2.167978286743164\n",
      "2.1669816970825195\n",
      "2.165998697280884\n",
      "2.165031909942627\n",
      "2.164079189300537\n",
      "2.163137912750244\n",
      "2.1622142791748047\n",
      "2.161299228668213\n",
      "2.1603970527648926\n",
      "2.1595065593719482\n",
      "2.1586265563964844\n",
      "2.1577563285827637\n",
      "2.1568973064422607\n",
      "tensor(2.1569)\n",
      "2.1560475826263428\n",
      "2.1552040576934814\n",
      "2.1543753147125244\n",
      "2.1535520553588867\n",
      "2.152737617492676\n",
      "2.151930332183838\n",
      "2.151132106781006\n",
      "2.1503424644470215\n",
      "2.1495566368103027\n",
      "2.14877986907959\n",
      "2.1480095386505127\n",
      "2.147244930267334\n",
      "2.1464879512786865\n",
      "2.1457362174987793\n",
      "2.1449880599975586\n",
      "2.144247531890869\n",
      "2.1435132026672363\n",
      "2.1427838802337646\n",
      "2.142057180404663\n",
      "2.1413378715515137\n",
      "2.140622615814209\n",
      "2.1399123668670654\n",
      "2.1392054557800293\n",
      "2.1385045051574707\n",
      "2.137807607650757\n",
      "2.1371166706085205\n",
      "2.1364269256591797\n",
      "2.1357405185699463\n",
      "2.1350598335266113\n",
      "2.1343843936920166\n",
      "2.1337087154388428\n",
      "2.1330392360687256\n",
      "2.132371664047241\n",
      "2.131709098815918\n",
      "2.1310501098632812\n",
      "2.1303935050964355\n",
      "2.1297383308410645\n",
      "2.129089593887329\n",
      "2.1284427642822266\n",
      "2.127798318862915\n",
      "2.1271584033966064\n",
      "2.126518964767456\n",
      "2.1258866786956787\n",
      "2.1252524852752686\n",
      "2.124621868133545\n",
      "2.123994827270508\n",
      "2.1233739852905273\n",
      "2.1227495670318604\n",
      "2.122131586074829\n",
      "2.121516466140747\n",
      "2.120901584625244\n",
      "2.1202938556671143\n",
      "2.1196818351745605\n",
      "2.119076728820801\n",
      "2.1184751987457275\n",
      "2.1178717613220215\n",
      "2.1172728538513184\n",
      "2.116676092147827\n",
      "2.1160831451416016\n",
      "2.1154911518096924\n",
      "2.1148993968963623\n",
      "2.1143133640289307\n",
      "2.1137287616729736\n",
      "2.1131443977355957\n",
      "2.1125617027282715\n",
      "2.1119842529296875\n",
      "2.1114084720611572\n",
      "2.110833168029785\n",
      "2.110260486602783\n",
      "2.1096901893615723\n",
      "2.109123706817627\n",
      "2.1085567474365234\n",
      "2.1079916954040527\n",
      "2.1074278354644775\n",
      "2.1068685054779053\n",
      "2.106309413909912\n",
      "2.1057546138763428\n",
      "2.1052002906799316\n",
      "2.1046462059020996\n",
      "2.104097366333008\n",
      "2.1035478115081787\n",
      "2.103001594543457\n",
      "2.102457046508789\n",
      "2.1019136905670166\n",
      "2.1013729572296143\n",
      "2.1008353233337402\n",
      "2.10029673576355\n",
      "2.0997612476348877\n",
      "2.099226951599121\n",
      "2.0986971855163574\n",
      "2.0981667041778564\n",
      "2.0976383686065674\n",
      "2.0971126556396484\n",
      "2.096588373184204\n",
      "2.096065044403076\n",
      "2.0955452919006348\n",
      "2.095025062561035\n",
      "2.0945088863372803\n",
      "2.0939929485321045\n",
      "2.093478202819824\n",
      "tensor(2.0935)\n",
      "2.0929665565490723\n",
      "2.092456340789795\n",
      "2.0919463634490967\n",
      "2.091437816619873\n",
      "2.090935230255127\n",
      "2.0904312133789062\n",
      "2.0899291038513184\n",
      "2.0894289016723633\n",
      "2.088931083679199\n",
      "2.0884344577789307\n",
      "2.0879387855529785\n",
      "2.0874438285827637\n",
      "2.086953639984131\n",
      "2.086460828781128\n",
      "2.0859737396240234\n",
      "2.0854861736297607\n",
      "2.0849995613098145\n",
      "2.084517240524292\n",
      "2.084035873413086\n",
      "2.0835561752319336\n",
      "2.0830764770507812\n",
      "2.082598924636841\n",
      "2.082122325897217\n",
      "2.0816473960876465\n",
      "2.081176996231079\n",
      "2.0807039737701416\n",
      "2.080235004425049\n",
      "2.0797667503356934\n",
      "2.07930064201355\n",
      "2.0788354873657227\n",
      "2.0783724784851074\n",
      "2.077910900115967\n",
      "2.0774521827697754\n",
      "2.0769925117492676\n",
      "2.076535224914551\n",
      "2.076077938079834\n",
      "2.075624704360962\n",
      "2.075171947479248\n",
      "2.0747203826904297\n",
      "2.0742714405059814\n",
      "2.073824405670166\n",
      "2.073378086090088\n",
      "2.072932720184326\n",
      "2.0724899768829346\n",
      "2.0720462799072266\n",
      "2.071603536605835\n",
      "2.0711655616760254\n",
      "2.0707287788391113\n",
      "2.070293664932251\n",
      "2.069854736328125\n",
      "2.0694212913513184\n",
      "2.068991184234619\n",
      "2.0685596466064453\n",
      "2.0681304931640625\n",
      "2.0677032470703125\n",
      "2.067275285720825\n",
      "2.066850423812866\n",
      "2.066427707672119\n",
      "2.0660042762756348\n",
      "2.0655837059020996\n",
      "2.0651638507843018\n",
      "2.064746618270874\n",
      "2.0643303394317627\n",
      "2.063915729522705\n",
      "2.0634992122650146\n",
      "2.063089609146118\n",
      "2.0626771450042725\n",
      "2.062267780303955\n",
      "2.061858892440796\n",
      "2.061450242996216\n",
      "2.061044931411743\n",
      "2.0606417655944824\n",
      "2.060237169265747\n",
      "2.0598363876342773\n",
      "2.059434413909912\n",
      "2.0590367317199707\n",
      "2.0586369037628174\n",
      "2.058241605758667\n",
      "2.057844877243042\n",
      "2.0574522018432617\n",
      "2.057060718536377\n",
      "2.0566678047180176\n",
      "2.056277275085449\n",
      "2.055889129638672\n",
      "2.0555031299591064\n",
      "2.055116653442383\n",
      "2.0547308921813965\n",
      "2.054347515106201\n",
      "2.053964853286743\n",
      "2.0535855293273926\n",
      "2.0532045364379883\n",
      "2.0528249740600586\n",
      "2.05244779586792\n",
      "2.0520730018615723\n",
      "2.05169677734375\n",
      "2.0513243675231934\n",
      "2.0509512424468994\n",
      "2.050581216812134\n",
      "2.0502114295959473\n",
      "2.0498411655426025\n",
      "tensor(2.0498)\n",
      "2.0494725704193115\n",
      "2.049107074737549\n",
      "2.0487425327301025\n",
      "2.0483784675598145\n",
      "2.048016309738159\n",
      "2.047654867172241\n",
      "2.0472941398620605\n",
      "2.046936273574829\n",
      "2.046576738357544\n",
      "2.046220064163208\n",
      "2.045863628387451\n",
      "2.0455102920532227\n",
      "2.045156955718994\n",
      "2.044807195663452\n",
      "2.044455051422119\n",
      "2.0441055297851562\n",
      "2.0437536239624023\n",
      "2.043408155441284\n",
      "2.043060302734375\n",
      "2.0427186489105225\n",
      "2.0423741340637207\n",
      "2.042029619216919\n",
      "2.0416884422302246\n",
      "2.0413472652435303\n",
      "2.041008472442627\n",
      "2.0406689643859863\n",
      "2.040332317352295\n",
      "2.0399959087371826\n",
      "2.039660930633545\n",
      "2.0393285751342773\n",
      "2.0389950275421143\n",
      "2.0386641025543213\n",
      "2.0383338928222656\n",
      "2.0380046367645264\n",
      "2.037675142288208\n",
      "2.037346363067627\n",
      "2.037020444869995\n",
      "2.036694049835205\n",
      "2.0363690853118896\n",
      "2.036046266555786\n",
      "2.0357260704040527\n",
      "2.035404920578003\n",
      "2.0350847244262695\n",
      "2.0347657203674316\n",
      "2.0344488620758057\n",
      "2.034132480621338\n",
      "2.033815622329712\n",
      "2.0335018634796143\n",
      "2.0331878662109375\n",
      "2.03287672996521\n",
      "2.032564640045166\n",
      "2.0322537422180176\n",
      "2.0319433212280273\n",
      "2.0316357612609863\n",
      "2.0313284397125244\n",
      "2.031022548675537\n",
      "2.030714273452759\n",
      "2.030411720275879\n",
      "2.030107021331787\n",
      "2.0298044681549072\n",
      "2.0295040607452393\n",
      "2.029205083847046\n",
      "2.0289041996002197\n",
      "2.0286054611206055\n",
      "2.028306722640991\n",
      "2.028010606765747\n",
      "2.0277159214019775\n",
      "2.0274229049682617\n",
      "2.0271267890930176\n",
      "2.0268352031707764\n",
      "2.026543617248535\n",
      "2.0262537002563477\n",
      "2.0259623527526855\n",
      "2.0256757736206055\n",
      "2.0253870487213135\n",
      "2.025099277496338\n",
      "2.024815082550049\n",
      "2.024528980255127\n",
      "2.0242459774017334\n",
      "2.023963451385498\n",
      "2.0236802101135254\n",
      "2.0233991146087646\n",
      "2.0231170654296875\n",
      "2.0228381156921387\n",
      "2.022559642791748\n",
      "2.022282123565674\n",
      "2.022005558013916\n",
      "2.0217318534851074\n",
      "2.021456241607666\n",
      "2.0211808681488037\n",
      "2.020908832550049\n",
      "2.0206387042999268\n",
      "2.0203661918640137\n",
      "2.0200953483581543\n",
      "2.0198254585266113\n",
      "2.0195579528808594\n",
      "2.0192885398864746\n",
      "2.0190224647521973\n",
      "2.0187582969665527\n",
      "2.0184924602508545\n",
      "tensor(2.0185)\n",
      "2.0182292461395264\n",
      "2.01796555519104\n",
      "2.0177016258239746\n",
      "2.0174412727355957\n",
      "2.017181396484375\n",
      "2.016921281814575\n",
      "2.0166635513305664\n",
      "2.016404390335083\n",
      "2.016146659851074\n",
      "2.015888214111328\n",
      "2.0156350135803223\n",
      "2.0153794288635254\n",
      "2.0151267051696777\n",
      "2.014871835708618\n",
      "2.014620780944824\n",
      "2.0143706798553467\n",
      "2.014118194580078\n",
      "2.0138704776763916\n",
      "2.013620615005493\n",
      "2.013373613357544\n",
      "2.0131239891052246\n",
      "2.012877941131592\n",
      "2.0126330852508545\n",
      "2.0123894214630127\n",
      "2.012143611907959\n",
      "2.0119025707244873\n",
      "2.011660575866699\n",
      "2.011417865753174\n",
      "2.0111782550811768\n",
      "2.0109362602233887\n",
      "2.0106961727142334\n",
      "2.0104575157165527\n",
      "2.010221004486084\n",
      "2.009983539581299\n",
      "2.009748697280884\n",
      "2.0095131397247314\n",
      "2.009279489517212\n",
      "2.0090463161468506\n",
      "2.0088117122650146\n",
      "2.0085811614990234\n",
      "2.008347988128662\n",
      "2.0081188678741455\n",
      "2.0078864097595215\n",
      "2.0076587200164795\n",
      "2.0074305534362793\n",
      "2.007201910018921\n",
      "2.0069756507873535\n",
      "2.0067496299743652\n",
      "2.006524085998535\n",
      "2.0062994956970215\n",
      "2.0060770511627197\n",
      "2.0058505535125732\n",
      "2.005629539489746\n",
      "2.0054073333740234\n",
      "2.0051867961883545\n",
      "2.0049667358398438\n",
      "2.0047459602355957\n",
      "2.004528522491455\n",
      "2.004312038421631\n",
      "2.004094362258911\n",
      "2.0038771629333496\n",
      "2.003661632537842\n",
      "2.003446340560913\n",
      "2.0032317638397217\n",
      "2.0030171871185303\n",
      "2.0028038024902344\n",
      "2.002591609954834\n",
      "2.0023818016052246\n",
      "2.002169132232666\n",
      "2.0019583702087402\n",
      "2.00174880027771\n",
      "2.0015389919281006\n",
      "2.0013327598571777\n",
      "2.0011255741119385\n",
      "2.000919818878174\n",
      "2.000711679458618\n",
      "2.00050687789917\n",
      "2.000302791595459\n",
      "2.0000977516174316\n",
      "1.9998934268951416\n",
      "1.9996906518936157\n",
      "1.9994895458221436\n",
      "1.9992883205413818\n",
      "1.9990885257720947\n",
      "1.9988876581192017\n",
      "1.9986884593963623\n",
      "1.9984899759292603\n",
      "1.9982900619506836\n",
      "1.998093605041504\n",
      "1.9978967905044556\n",
      "1.997699499130249\n",
      "1.9975054264068604\n",
      "1.9973100423812866\n",
      "1.9971144199371338\n",
      "1.9969208240509033\n",
      "1.9967291355133057\n",
      "1.9965366125106812\n",
      "1.996346116065979\n",
      "1.9961551427841187\n",
      "1.9959644079208374\n",
      "tensor(1.9960)\n",
      "1.9957730770111084\n",
      "1.9955832958221436\n",
      "1.995396375656128\n",
      "1.9952081441879272\n",
      "1.9950201511383057\n",
      "1.9948335886001587\n",
      "1.9946458339691162\n",
      "1.994462013244629\n",
      "1.9942773580551147\n",
      "1.9940932989120483\n",
      "1.9939086437225342\n",
      "1.993727445602417\n",
      "1.9935438632965088\n",
      "1.9933626651763916\n",
      "1.993178367614746\n",
      "1.9930016994476318\n",
      "1.9928194284439087\n",
      "1.992640495300293\n",
      "1.9924602508544922\n",
      "1.9922857284545898\n",
      "1.9921045303344727\n",
      "1.9919296503067017\n",
      "1.9917528629302979\n",
      "1.9915764331817627\n",
      "1.9913994073867798\n",
      "1.9912269115447998\n",
      "1.9910529851913452\n",
      "1.990877389907837\n",
      "1.9907052516937256\n",
      "1.990533471107483\n",
      "1.9903624057769775\n",
      "1.9901918172836304\n",
      "1.9900178909301758\n",
      "1.989849328994751\n",
      "1.9896793365478516\n",
      "1.9895086288452148\n",
      "1.9893407821655273\n",
      "1.9891735315322876\n",
      "1.9890058040618896\n",
      "1.98883855342865\n",
      "1.988673210144043\n",
      "1.988507628440857\n",
      "1.9883391857147217\n",
      "1.9881782531738281\n",
      "1.988012671470642\n",
      "1.9878489971160889\n",
      "1.987687349319458\n",
      "1.9875246286392212\n",
      "1.987361192703247\n",
      "1.987200140953064\n",
      "1.9870386123657227\n",
      "1.9868781566619873\n",
      "1.986720323562622\n",
      "1.9865604639053345\n",
      "1.9864006042480469\n",
      "1.9862438440322876\n",
      "1.9860851764678955\n",
      "1.9859278202056885\n",
      "1.985771894454956\n",
      "1.9856154918670654\n",
      "1.9854590892791748\n",
      "1.9853041172027588\n",
      "1.9851478338241577\n",
      "1.9849965572357178\n",
      "1.9848417043685913\n",
      "1.984688401222229\n",
      "1.9845359325408936\n",
      "1.9843822717666626\n",
      "1.9842302799224854\n",
      "1.9840824604034424\n",
      "1.9839303493499756\n",
      "1.9837806224822998\n",
      "1.9836307764053345\n",
      "1.9834825992584229\n",
      "1.983332872390747\n",
      "1.9831844568252563\n",
      "1.9830385446548462\n",
      "1.9828910827636719\n",
      "1.9827439785003662\n",
      "1.982598066329956\n",
      "1.9824520349502563\n",
      "1.9823055267333984\n",
      "1.9821617603302002\n",
      "1.982017159461975\n",
      "1.9818741083145142\n",
      "1.9817311763763428\n",
      "1.9815864562988281\n",
      "1.9814443588256836\n",
      "1.9813028573989868\n",
      "1.9811601638793945\n",
      "1.9810212850570679\n",
      "1.9808801412582397\n",
      "1.9807380437850952\n",
      "1.980600357055664\n",
      "1.980463981628418\n",
      "1.980322241783142\n",
      "1.9801841974258423\n",
      "1.9800465106964111\n",
      "1.9799083471298218\n",
      "1.9797732830047607\n",
      "tensor(1.9798)\n",
      "1.9796359539031982\n",
      "1.9794995784759521\n",
      "1.979365348815918\n",
      "1.9792295694351196\n",
      "1.9790964126586914\n",
      "1.978960633277893\n",
      "1.9788272380828857\n",
      "1.978693962097168\n",
      "1.9785606861114502\n",
      "1.9784263372421265\n",
      "1.9782956838607788\n",
      "1.9781659841537476\n",
      "1.9780337810516357\n",
      "1.977903962135315\n",
      "1.9777723550796509\n",
      "1.9776426553726196\n",
      "1.9775127172470093\n",
      "1.9773849248886108\n",
      "1.977254867553711\n",
      "1.977128028869629\n",
      "1.9770005941390991\n",
      "1.9768733978271484\n",
      "1.9767475128173828\n",
      "1.9766194820404053\n",
      "1.9764935970306396\n",
      "1.976367712020874\n",
      "1.9762437343597412\n",
      "1.9761180877685547\n",
      "1.9759941101074219\n",
      "1.9758703708648682\n",
      "1.975746750831604\n",
      "1.9756237268447876\n",
      "1.9755016565322876\n",
      "1.9753773212432861\n",
      "1.9752569198608398\n",
      "1.9751358032226562\n",
      "1.9750127792358398\n",
      "1.9748942852020264\n",
      "1.9747722148895264\n",
      "1.9746509790420532\n",
      "1.9745352268218994\n",
      "1.974413514137268\n",
      "1.9742956161499023\n",
      "1.974177360534668\n",
      "1.9740585088729858\n",
      "1.9739423990249634\n",
      "1.9738247394561768\n",
      "1.9737064838409424\n",
      "1.9735915660858154\n",
      "1.9734748601913452\n",
      "1.9733597040176392\n",
      "1.9732468128204346\n",
      "1.973128080368042\n",
      "1.9730151891708374\n",
      "1.9729013442993164\n",
      "1.9727863073349\n",
      "1.9726721048355103\n",
      "1.9725618362426758\n",
      "1.972447395324707\n",
      "1.9723354578018188\n",
      "1.9722232818603516\n",
      "1.9721109867095947\n",
      "1.9720007181167603\n",
      "1.9718906879425049\n",
      "1.9717791080474854\n",
      "1.971670150756836\n",
      "1.9715598821640015\n",
      "1.9714504480361938\n",
      "1.971343755722046\n",
      "1.9712330102920532\n",
      "1.9711261987686157\n",
      "1.9710168838500977\n",
      "1.9709088802337646\n",
      "1.970802664756775\n",
      "1.9706958532333374\n",
      "1.9705889225006104\n",
      "1.9704822301864624\n",
      "1.9703776836395264\n",
      "1.9702717065811157\n",
      "1.9701662063598633\n",
      "1.9700613021850586\n",
      "1.9699573516845703\n",
      "1.9698528051376343\n",
      "1.9697496891021729\n",
      "1.9696462154388428\n",
      "1.9695441722869873\n",
      "1.969440221786499\n",
      "1.9693410396575928\n",
      "1.969236135482788\n",
      "1.9691349267959595\n",
      "1.9690335988998413\n",
      "1.968932867050171\n",
      "1.9688326120376587\n",
      "1.9687318801879883\n",
      "1.968632698059082\n",
      "1.968530297279358\n",
      "1.9684330224990845\n",
      "1.9683328866958618\n",
      "1.968235731124878\n",
      "1.9681360721588135\n",
      "tensor(1.9681)\n",
      "1.968038558959961\n",
      "1.967942476272583\n",
      "1.96784245967865\n",
      "1.9677473306655884\n",
      "1.967651605606079\n",
      "1.9675527811050415\n",
      "1.9674568176269531\n",
      "1.9673629999160767\n",
      "1.9672666788101196\n",
      "1.9671704769134521\n",
      "1.9670757055282593\n",
      "1.9669841527938843\n",
      "1.966888427734375\n",
      "1.966792345046997\n",
      "1.9667001962661743\n",
      "1.9666080474853516\n",
      "1.9665136337280273\n",
      "1.9664217233657837\n",
      "1.9663293361663818\n",
      "1.9662363529205322\n",
      "1.9661433696746826\n",
      "1.9660526514053345\n",
      "1.9659616947174072\n",
      "1.9658701419830322\n",
      "1.9657825231552124\n",
      "1.965692162513733\n",
      "1.965598464012146\n",
      "1.9655109643936157\n",
      "1.9654232263565063\n",
      "1.965333342552185\n",
      "1.9652421474456787\n",
      "1.9651546478271484\n",
      "1.9650672674179077\n",
      "1.9649765491485596\n",
      "1.9648911952972412\n",
      "1.9648042917251587\n",
      "1.9647190570831299\n",
      "1.9646291732788086\n",
      "1.9645439386367798\n",
      "1.9644562005996704\n",
      "1.964371919631958\n",
      "1.9642858505249023\n",
      "1.9642006158828735\n",
      "1.9641153812408447\n",
      "1.9640324115753174\n",
      "1.9639463424682617\n",
      "1.9638608694076538\n",
      "1.9637806415557861\n",
      "1.9636951684951782\n",
      "1.963610053062439\n",
      "1.9635273218154907\n",
      "1.9634454250335693\n",
      "1.963362693786621\n",
      "1.9632806777954102\n",
      "1.9631977081298828\n",
      "1.9631175994873047\n",
      "1.963035225868225\n",
      "1.962952971458435\n",
      "1.9628727436065674\n",
      "1.9627920389175415\n",
      "1.962712049484253\n",
      "1.9626338481903076\n",
      "1.9625532627105713\n",
      "1.9624723196029663\n",
      "1.962392807006836\n",
      "1.9623152017593384\n",
      "1.9622364044189453\n",
      "1.9621551036834717\n",
      "1.9620780944824219\n",
      "1.962001085281372\n",
      "1.961920142173767\n",
      "1.9618428945541382\n",
      "1.9617668390274048\n",
      "1.9616906642913818\n",
      "1.961614966392517\n",
      "1.9615379571914673\n",
      "1.961461067199707\n",
      "1.9613850116729736\n",
      "1.961308479309082\n",
      "1.9612343311309814\n",
      "1.9611589908599854\n",
      "1.9610856771469116\n",
      "1.9610106945037842\n",
      "1.9609339237213135\n",
      "1.960860013961792\n",
      "1.960784673690796\n",
      "1.960712194442749\n",
      "1.9606374502182007\n",
      "1.9605642557144165\n",
      "1.9604921340942383\n",
      "1.9604198932647705\n",
      "1.960345983505249\n",
      "1.9602749347686768\n",
      "1.9602031707763672\n",
      "1.960129976272583\n",
      "1.9600579738616943\n",
      "1.9599883556365967\n",
      "1.9599167108535767\n",
      "1.9598467350006104\n",
      "1.9597752094268799\n",
      "tensor(1.9598)\n",
      "1.9597043991088867\n",
      "1.9596353769302368\n",
      "1.9595632553100586\n",
      "1.9594930410385132\n",
      "1.9594262838363647\n",
      "1.9593559503555298\n",
      "1.9592869281768799\n",
      "1.9592164754867554\n",
      "1.9591484069824219\n",
      "1.9590791463851929\n",
      "1.959012746810913\n",
      "1.958944320678711\n",
      "1.9588756561279297\n",
      "1.9588098526000977\n",
      "1.9587424993515015\n",
      "1.9586760997772217\n",
      "1.9586082696914673\n",
      "1.958540916442871\n",
      "1.9584770202636719\n",
      "1.9584099054336548\n",
      "1.9583429098129272\n",
      "1.9582792520523071\n",
      "1.9582128524780273\n",
      "1.9581445455551147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9580812454223633\n",
      "1.9580169916152954\n",
      "1.9579532146453857\n",
      "1.9578883647918701\n",
      "1.9578230381011963\n",
      "1.9577586650848389\n",
      "1.9576942920684814\n",
      "1.9576303958892822\n",
      "1.9575679302215576\n",
      "1.9575035572052002\n",
      "1.9574426412582397\n",
      "1.9573795795440674\n",
      "1.9573160409927368\n",
      "1.9572551250457764\n",
      "1.9571924209594727\n",
      "1.957131028175354\n",
      "1.957067847251892\n",
      "1.9570081233978271\n",
      "1.9569451808929443\n",
      "1.9568850994110107\n",
      "1.9568243026733398\n",
      "1.956762671470642\n",
      "1.9567010402679443\n",
      "1.9566423892974854\n",
      "1.9565823078155518\n",
      "1.9565197229385376\n",
      "1.956463098526001\n",
      "1.956403374671936\n",
      "1.9563424587249756\n",
      "1.956284523010254\n",
      "1.9562263488769531\n",
      "1.9561659097671509\n",
      "1.9561083316802979\n",
      "1.956051230430603\n",
      "1.9559917449951172\n",
      "1.9559348821640015\n",
      "1.955875039100647\n",
      "1.9558184146881104\n",
      "1.9557621479034424\n",
      "1.9557034969329834\n",
      "1.9556477069854736\n",
      "1.9555914402008057\n",
      "1.9555336236953735\n",
      "1.955476999282837\n",
      "1.9554214477539062\n",
      "1.9553651809692383\n",
      "1.9553098678588867\n",
      "1.9552549123764038\n",
      "1.9551969766616821\n",
      "1.9551414251327515\n",
      "1.9550882577896118\n",
      "1.9550330638885498\n",
      "1.95497727394104\n",
      "1.9549211263656616\n",
      "1.9548685550689697\n",
      "1.9548139572143555\n",
      "1.9547605514526367\n",
      "1.954703688621521\n",
      "1.9546527862548828\n",
      "1.954599142074585\n",
      "1.954545021057129\n",
      "1.9544916152954102\n",
      "1.9544384479522705\n",
      "1.9543874263763428\n",
      "1.954332709312439\n",
      "1.954281210899353\n",
      "1.9542293548583984\n",
      "1.9541774988174438\n",
      "1.954122543334961\n",
      "1.954073190689087\n",
      "1.954019546508789\n",
      "1.9539674520492554\n",
      "1.953917145729065\n",
      "1.9538676738739014\n",
      "1.9538167715072632\n",
      "1.9537655115127563\n",
      "tensor(1.9538)\n",
      "1.9537149667739868\n",
      "1.9536653757095337\n",
      "1.9536149501800537\n",
      "1.9535648822784424\n",
      "1.9535129070281982\n",
      "1.9534642696380615\n",
      "1.9534155130386353\n",
      "1.9533660411834717\n",
      "1.9533170461654663\n",
      "1.9532649517059326\n",
      "1.9532171487808228\n",
      "1.9531704187393188\n",
      "1.9531186819076538\n",
      "1.9530723094940186\n",
      "1.9530236721038818\n",
      "1.9529740810394287\n",
      "1.9529263973236084\n",
      "1.9528805017471313\n",
      "1.9528318643569946\n",
      "1.9527835845947266\n",
      "1.9527356624603271\n",
      "1.9526891708374023\n",
      "1.9526420831680298\n",
      "1.9525949954986572\n",
      "1.9525474309921265\n",
      "1.9525024890899658\n",
      "1.9524558782577515\n",
      "1.9524099826812744\n",
      "1.95236337184906\n",
      "1.952317237854004\n",
      "1.952271819114685\n",
      "1.9522254467010498\n",
      "1.9521801471710205\n",
      "1.952135443687439\n",
      "1.952087163925171\n",
      "1.9520429372787476\n",
      "1.9519987106323242\n",
      "1.951952576637268\n",
      "1.9519097805023193\n",
      "1.9518661499023438\n",
      "1.951820969581604\n",
      "1.951777458190918\n",
      "1.9517313241958618\n",
      "1.9516894817352295\n",
      "1.9516452550888062\n",
      "1.9516023397445679\n",
      "1.9515584707260132\n",
      "1.9515138864517212\n",
      "1.9514715671539307\n",
      "1.9514272212982178\n",
      "1.951383352279663\n",
      "1.9513413906097412\n",
      "1.9512983560562134\n",
      "1.9512579441070557\n",
      "1.9512147903442383\n",
      "1.9511743783950806\n",
      "1.9511324167251587\n",
      "1.9510900974273682\n",
      "1.9510465860366821\n",
      "1.9510066509246826\n",
      "1.950964331626892\n",
      "1.950923204421997\n",
      "1.9508802890777588\n",
      "1.950839638710022\n",
      "1.950798749923706\n",
      "1.950757622718811\n",
      "1.9507179260253906\n",
      "1.9506771564483643\n",
      "1.9506391286849976\n",
      "1.9505945444107056\n",
      "1.9505573511123657\n",
      "1.9505159854888916\n",
      "1.9504764080047607\n",
      "1.9504369497299194\n",
      "1.9503977298736572\n",
      "1.95035719871521\n",
      "1.9503179788589478\n",
      "1.9502779245376587\n",
      "1.9502408504486084\n",
      "1.9501994848251343\n",
      "1.950162649154663\n",
      "1.9501216411590576\n",
      "1.9500831365585327\n",
      "1.950046181678772\n",
      "1.9500080347061157\n",
      "1.949970006942749\n",
      "1.9499317407608032\n",
      "1.9498927593231201\n",
      "1.9498541355133057\n",
      "1.9498202800750732\n",
      "1.949779748916626\n",
      "1.9497438669204712\n",
      "1.9497045278549194\n",
      "1.9496667385101318\n",
      "1.9496310949325562\n",
      "1.949593186378479\n",
      "1.9495550394058228\n",
      "1.9495201110839844\n",
      "1.9494835138320923\n",
      "1.9494470357894897\n",
      "tensor(1.9494)\n",
      "1.9494107961654663\n",
      "1.9493744373321533\n",
      "1.9493376016616821\n",
      "1.949302077293396\n",
      "1.9492664337158203\n",
      "1.9492299556732178\n",
      "1.9491965770721436\n",
      "1.9491584300994873\n",
      "1.9491221904754639\n",
      "1.949087381362915\n",
      "1.9490516185760498\n",
      "1.9490196704864502\n",
      "1.948982834815979\n",
      "1.948947548866272\n",
      "1.948914885520935\n",
      "1.948879599571228\n",
      "1.9488441944122314\n",
      "1.948809027671814\n",
      "1.9487762451171875\n",
      "1.9487428665161133\n",
      "1.9487056732177734\n",
      "1.9486719369888306\n",
      "1.9486398696899414\n",
      "1.9486055374145508\n",
      "1.948574423789978\n",
      "1.9485397338867188\n",
      "1.9485057592391968\n",
      "1.9484710693359375\n",
      "1.9484374523162842\n",
      "1.9484050273895264\n",
      "1.9483730792999268\n",
      "1.9483388662338257\n",
      "1.9483095407485962\n",
      "1.9482768774032593\n",
      "1.9482421875\n",
      "1.9482100009918213\n",
      "1.9481769800186157\n",
      "1.9481432437896729\n",
      "1.9481117725372314\n",
      "1.9480812549591064\n",
      "1.9480483531951904\n",
      "1.9480164051055908\n",
      "1.9479854106903076\n",
      "1.947954535484314\n",
      "1.9479217529296875\n",
      "1.9478918313980103\n",
      "1.9478620290756226\n",
      "1.9478294849395752\n",
      "1.9477990865707397\n",
      "1.9477676153182983\n",
      "1.947735071182251\n",
      "1.947705864906311\n",
      "1.947675108909607\n",
      "1.947643518447876\n",
      "1.9476146697998047\n",
      "1.9475831985473633\n",
      "1.9475520849227905\n",
      "1.9475219249725342\n",
      "1.9474942684173584\n",
      "1.9474632740020752\n",
      "1.9474318027496338\n",
      "1.9474035501480103\n",
      "1.9473745822906494\n",
      "1.9473438262939453\n",
      "1.947314977645874\n",
      "1.947286605834961\n",
      "1.9472572803497314\n",
      "1.9472272396087646\n",
      "1.9472004175186157\n",
      "1.9471685886383057\n",
      "1.9471399784088135\n",
      "1.9471123218536377\n",
      "1.9470819234848022\n",
      "1.9470539093017578\n",
      "1.9470252990722656\n",
      "1.9469974040985107\n",
      "1.9469674825668335\n",
      "1.9469406604766846\n",
      "1.9469125270843506\n",
      "1.946882963180542\n",
      "1.9468557834625244\n",
      "1.9468295574188232\n",
      "1.9468004703521729\n",
      "1.9467709064483643\n",
      "1.9467456340789795\n",
      "1.9467178583145142\n",
      "1.9466902017593384\n",
      "1.9466619491577148\n",
      "1.9466378688812256\n",
      "1.9466075897216797\n",
      "1.9465827941894531\n",
      "1.9465547800064087\n",
      "1.9465291500091553\n",
      "1.9465030431747437\n",
      "1.9464759826660156\n",
      "1.946448564529419\n",
      "1.9464218616485596\n",
      "1.946394920349121\n",
      "1.9463682174682617\n",
      "1.9463441371917725\n",
      "tensor(1.9463)\n",
      "1.9463167190551758\n",
      "1.9462921619415283\n",
      "1.946265459060669\n",
      "1.9462387561798096\n",
      "1.9462127685546875\n",
      "1.9461864233016968\n",
      "1.9461628198623657\n",
      "1.9461361169815063\n",
      "1.946110725402832\n",
      "1.9460842609405518\n",
      "1.946059226989746\n",
      "1.946035385131836\n",
      "1.9460117816925049\n",
      "1.9459842443466187\n",
      "1.9459607601165771\n",
      "1.945935845375061\n",
      "1.9459104537963867\n",
      "1.9458858966827393\n",
      "1.9458614587783813\n",
      "1.9458376169204712\n",
      "1.9458118677139282\n",
      "1.9457868337631226\n",
      "1.945765495300293\n",
      "1.9457381963729858\n",
      "1.9457120895385742\n",
      "1.9456901550292969\n",
      "1.9456684589385986\n",
      "1.9456422328948975\n",
      "1.9456201791763306\n",
      "1.9455959796905518\n",
      "1.9455715417861938\n",
      "1.9455482959747314\n",
      "1.9455244541168213\n",
      "1.9455010890960693\n",
      "1.9454782009124756\n",
      "1.9454543590545654\n",
      "1.9454290866851807\n",
      "1.9454066753387451\n",
      "1.9453843832015991\n",
      "1.9453637599945068\n",
      "1.9453403949737549\n",
      "1.9453169107437134\n",
      "1.945294737815857\n",
      "1.9452712535858154\n",
      "1.9452486038208008\n",
      "1.9452251195907593\n",
      "1.945203185081482\n",
      "1.9451814889907837\n",
      "1.9451589584350586\n",
      "1.9451338052749634\n",
      "1.9451141357421875\n",
      "1.9450922012329102\n",
      "1.945069670677185\n",
      "1.945045828819275\n",
      "1.9450260400772095\n",
      "1.945005178451538\n",
      "1.9449809789657593\n",
      "1.9449613094329834\n",
      "1.9449392557144165\n",
      "1.9449176788330078\n",
      "1.9448978900909424\n",
      "1.9448738098144531\n",
      "1.94485342502594\n",
      "1.9448318481445312\n",
      "1.9448111057281494\n",
      "1.944788932800293\n",
      "1.9447689056396484\n",
      "1.9447482824325562\n",
      "1.9447276592254639\n",
      "1.9447046518325806\n",
      "1.944685935974121\n",
      "1.9446645975112915\n",
      "1.9446439743041992\n",
      "1.9446239471435547\n",
      "1.9446027278900146\n",
      "1.9445823431015015\n",
      "1.9445629119873047\n",
      "1.9445432424545288\n",
      "1.9445232152938843\n",
      "1.9445011615753174\n",
      "1.9444831609725952\n",
      "1.9444620609283447\n",
      "1.9444408416748047\n",
      "1.9444233179092407\n",
      "1.9444001913070679\n",
      "1.9443832635879517\n",
      "1.9443626403808594\n",
      "1.9443423748016357\n",
      "1.9443238973617554\n",
      "1.9443044662475586\n",
      "1.9442834854125977\n",
      "1.944265604019165\n",
      "1.944244146347046\n",
      "1.9442259073257446\n",
      "1.9442075490951538\n",
      "1.944188117980957\n",
      "1.944166898727417\n",
      "1.9441497325897217\n",
      "1.9441311359405518\n",
      "1.9441118240356445\n",
      "tensor(1.9441)\n",
      "1.944093108177185\n",
      "1.9440730810165405\n",
      "1.9440562725067139\n",
      "1.9440391063690186\n",
      "1.9440193176269531\n",
      "1.944000482559204\n",
      "1.9439821243286133\n",
      "1.9439634084701538\n",
      "1.9439475536346436\n",
      "1.9439283609390259\n",
      "1.943910002708435\n",
      "1.9438921213150024\n",
      "1.9438724517822266\n",
      "1.943853735923767\n",
      "1.9438365697860718\n",
      "1.9438180923461914\n",
      "1.9438022375106812\n",
      "1.9437841176986694\n",
      "1.9437675476074219\n",
      "1.9437490701675415\n",
      "1.9437299966812134\n",
      "1.943711519241333\n",
      "1.943695306777954\n",
      "1.9436790943145752\n",
      "1.9436594247817993\n",
      "1.9436452388763428\n",
      "1.9436267614364624\n",
      "1.9436101913452148\n",
      "1.9435908794403076\n",
      "1.9435758590698242\n",
      "1.9435573816299438\n",
      "1.9435398578643799\n",
      "1.9435243606567383\n",
      "1.9435069561004639\n",
      "1.943489670753479\n",
      "1.9434738159179688\n",
      "1.9434564113616943\n",
      "1.9434394836425781\n",
      "1.943424940109253\n",
      "1.943407416343689\n",
      "1.9433915615081787\n",
      "1.9433743953704834\n",
      "1.9433578252792358\n",
      "1.943341851234436\n",
      "1.9433250427246094\n",
      "1.943307638168335\n",
      "1.943292260169983\n",
      "1.9432767629623413\n",
      "1.9432601928710938\n",
      "1.943245530128479\n",
      "1.9432306289672852\n",
      "1.9432138204574585\n",
      "1.9431968927383423\n",
      "1.943182349205017\n",
      "1.9431679248809814\n",
      "1.9431512355804443\n",
      "1.9431356191635132\n",
      "1.943120002746582\n",
      "1.9431031942367554\n",
      "1.943086862564087\n",
      "1.9430725574493408\n",
      "1.9430574178695679\n",
      "1.943042516708374\n",
      "1.9430277347564697\n",
      "1.9430122375488281\n",
      "1.9429954290390015\n",
      "1.9429798126220703\n",
      "1.9429658651351929\n",
      "1.9429515600204468\n",
      "1.9429359436035156\n",
      "1.9429233074188232\n",
      "1.9429069757461548\n",
      "1.9428913593292236\n",
      "1.9428762197494507\n",
      "1.942862868309021\n",
      "1.9428470134735107\n",
      "1.9428341388702393\n",
      "1.9428189992904663\n",
      "1.9428037405014038\n",
      "1.9427893161773682\n",
      "1.9427745342254639\n",
      "1.9427608251571655\n",
      "1.9427467584609985\n",
      "1.9427295923233032\n",
      "1.9427177906036377\n",
      "1.9427025318145752\n",
      "1.94268798828125\n",
      "1.9426767826080322\n",
      "1.9426615238189697\n",
      "1.942645788192749\n",
      "1.942631721496582\n",
      "1.9426212310791016\n",
      "1.9426071643829346\n",
      "1.9425904750823975\n",
      "1.9425795078277588\n",
      "1.9425618648529053\n",
      "1.9425504207611084\n",
      "1.9425361156463623\n",
      "1.9425243139266968\n",
      "1.9425086975097656\n",
      "tensor(1.9425)\n",
      "1.9424943923950195\n",
      "1.9424846172332764\n",
      "1.9424705505371094\n",
      "1.9424560070037842\n",
      "1.9424422979354858\n",
      "1.9424304962158203\n",
      "1.942416787147522\n",
      "1.9424009323120117\n",
      "1.942388892173767\n",
      "1.9423754215240479\n",
      "1.942363977432251\n",
      "1.9423513412475586\n",
      "1.9423372745513916\n",
      "1.942323923110962\n",
      "1.9423110485076904\n",
      "1.9422988891601562\n",
      "1.9422870874404907\n",
      "1.9422721862792969\n",
      "1.942260503768921\n",
      "1.9422481060028076\n",
      "1.9422355890274048\n",
      "1.9422218799591064\n",
      "1.9422109127044678\n",
      "1.9421952962875366\n",
      "1.9421848058700562\n",
      "1.9421716928482056\n",
      "1.9421592950820923\n",
      "1.9421478509902954\n",
      "1.9421346187591553\n",
      "1.9421221017837524\n",
      "1.9421098232269287\n",
      "1.942098617553711\n",
      "1.9420884847640991\n",
      "1.942073106765747\n",
      "1.9420621395111084\n",
      "1.9420499801635742\n",
      "1.9420369863510132\n",
      "1.9420263767242432\n",
      "1.9420143365859985\n",
      "1.9420020580291748\n",
      "1.9419898986816406\n",
      "1.9419796466827393\n",
      "1.9419656991958618\n",
      "1.941957712173462\n",
      "1.9419424533843994\n",
      "1.9419294595718384\n",
      "1.9419214725494385\n",
      "1.9419071674346924\n",
      "1.9418976306915283\n",
      "1.941882848739624\n",
      "1.941872000694275\n",
      "1.9418621063232422\n",
      "1.9418532848358154\n",
      "1.9418394565582275\n",
      "1.9418302774429321\n",
      "1.9418179988861084\n",
      "1.9418079853057861\n",
      "1.9417946338653564\n",
      "1.941784143447876\n",
      "1.9417740106582642\n",
      "1.9417635202407837\n",
      "1.9417508840560913\n",
      "1.941741943359375\n",
      "1.9417299032211304\n",
      "1.9417188167572021\n",
      "1.941707968711853\n",
      "1.9416977167129517\n",
      "1.9416860342025757\n",
      "1.941676378250122\n",
      "1.9416637420654297\n",
      "1.9416539669036865\n",
      "1.9416429996490479\n",
      "1.941632866859436\n",
      "1.9416202306747437\n",
      "1.9416135549545288\n",
      "1.9416017532348633\n",
      "1.94158935546875\n",
      "1.9415795803070068\n",
      "1.9415686130523682\n",
      "1.9415581226348877\n",
      "1.9415496587753296\n",
      "1.9415361881256104\n",
      "1.9415289163589478\n",
      "1.9415156841278076\n",
      "1.9415067434310913\n",
      "1.9414983987808228\n",
      "1.941486120223999\n",
      "1.9414761066436768\n",
      "1.9414653778076172\n",
      "1.9414560794830322\n",
      "1.9414465427398682\n",
      "1.9414355754852295\n",
      "1.9414284229278564\n",
      "1.9414167404174805\n",
      "1.9414068460464478\n",
      "1.941396713256836\n",
      "1.9413868188858032\n",
      "1.9413783550262451\n",
      "1.9413673877716064\n",
      "1.9413566589355469\n",
      "tensor(1.9414)\n",
      "1.9413490295410156\n",
      "1.94133722782135\n",
      "1.9413286447525024\n",
      "1.9413185119628906\n",
      "1.9413102865219116\n",
      "1.941300392150879\n",
      "1.9412891864776611\n",
      "1.9412813186645508\n",
      "1.9412702322006226\n",
      "1.9412612915039062\n",
      "1.9412533044815063\n",
      "1.9412431716918945\n",
      "1.9412342309951782\n",
      "1.9412238597869873\n",
      "1.94121515750885\n",
      "1.9412059783935547\n",
      "1.9411952495574951\n",
      "1.9411876201629639\n",
      "1.9411777257919312\n",
      "1.9411684274673462\n",
      "1.9411602020263672\n",
      "1.9411509037017822\n",
      "1.94114089012146\n",
      "1.9411344528198242\n",
      "1.9411249160766602\n",
      "1.9411165714263916\n",
      "1.9411077499389648\n",
      "1.941098928451538\n",
      "1.9410877227783203\n",
      "1.9410804510116577\n",
      "1.9410711526870728\n",
      "1.9410619735717773\n",
      "1.9410526752471924\n",
      "1.9410451650619507\n",
      "1.9410369396209717\n",
      "1.9410260915756226\n",
      "1.9410183429718018\n",
      "1.9410107135772705\n",
      "1.9410018920898438\n",
      "1.9409929513931274\n",
      "1.9409847259521484\n",
      "1.9409784078598022\n",
      "1.9409687519073486\n",
      "1.9409615993499756\n",
      "1.9409496784210205\n",
      "1.9409433603286743\n",
      "1.9409334659576416\n",
      "1.9409263134002686\n",
      "1.940918207168579\n",
      "1.9409105777740479\n",
      "1.940900444984436\n",
      "1.9408934116363525\n",
      "1.9408836364746094\n",
      "1.9408773183822632\n",
      "1.9408690929412842\n",
      "1.9408607482910156\n",
      "1.940850853919983\n",
      "1.9408445358276367\n",
      "1.9408353567123413\n",
      "1.9408283233642578\n",
      "1.9408210515975952\n",
      "1.9408133029937744\n",
      "1.9408038854599\n",
      "1.9407964944839478\n",
      "1.9407901763916016\n",
      "1.9407809972763062\n",
      "1.9407752752304077\n",
      "1.9407660961151123\n",
      "1.9407587051391602\n",
      "1.940748929977417\n",
      "1.9407411813735962\n",
      "1.9407333135604858\n",
      "1.94072687625885\n",
      "1.9407202005386353\n",
      "1.940711259841919\n",
      "1.9407049417495728\n",
      "1.9406957626342773\n",
      "1.9406888484954834\n",
      "1.9406824111938477\n",
      "1.9406750202178955\n",
      "1.940664291381836\n",
      "1.9406601190567017\n",
      "1.9406511783599854\n",
      "1.94064462184906\n",
      "1.940636396408081\n",
      "1.9406287670135498\n",
      "1.9406225681304932\n",
      "1.940617561340332\n",
      "1.9406089782714844\n",
      "1.9406001567840576\n",
      "1.9405953884124756\n",
      "1.940586805343628\n",
      "1.9405784606933594\n",
      "1.9405710697174072\n",
      "1.9405651092529297\n",
      "1.9405581951141357\n",
      "1.940551996231079\n",
      "1.9405441284179688\n",
      "1.940537691116333\n",
      "1.9405282735824585\n",
      "tensor(1.9405)\n",
      "1.9405244588851929\n",
      "1.940516710281372\n",
      "1.9405075311660767\n",
      "1.9405019283294678\n",
      "1.9404948949813843\n",
      "1.940485954284668\n",
      "1.940481185913086\n",
      "1.9404741525650024\n",
      "1.9404665231704712\n",
      "1.9404613971710205\n",
      "1.9404535293579102\n",
      "1.9404478073120117\n",
      "1.9404407739639282\n",
      "1.9404346942901611\n",
      "1.9404265880584717\n",
      "1.9404194355010986\n",
      "1.9404150247573853\n",
      "1.9404067993164062\n",
      "1.94040048122406\n",
      "1.9403932094573975\n",
      "1.940387487411499\n",
      "1.9403817653656006\n",
      "1.9403740167617798\n",
      "1.9403679370880127\n",
      "1.9403622150421143\n",
      "1.940355896949768\n",
      "1.9403505325317383\n",
      "1.9403431415557861\n",
      "1.9403365850448608\n",
      "1.9403295516967773\n",
      "1.9403225183486938\n",
      "1.9403184652328491\n",
      "1.940312385559082\n",
      "1.940306305885315\n",
      "1.9402990341186523\n",
      "1.9402916431427002\n",
      "1.9402859210968018\n",
      "1.9402806758880615\n",
      "1.9402754306793213\n",
      "1.9402681589126587\n",
      "1.9402618408203125\n",
      "1.940254807472229\n",
      "1.9402498006820679\n",
      "1.9402443170547485\n",
      "1.9402368068695068\n",
      "1.9402307271957397\n",
      "1.9402252435684204\n",
      "1.940219521522522\n",
      "1.9402129650115967\n",
      "1.9402081966400146\n",
      "1.9402014017105103\n",
      "1.9401963949203491\n",
      "1.9401915073394775\n",
      "1.9401851892471313\n",
      "1.9401781558990479\n",
      "1.940172791481018\n",
      "1.9401664733886719\n",
      "1.9401603937149048\n",
      "1.9401557445526123\n",
      "1.940148949623108\n",
      "1.9401443004608154\n",
      "1.9401381015777588\n",
      "1.94013249874115\n",
      "1.9401264190673828\n",
      "1.9401195049285889\n",
      "1.9401156902313232\n",
      "1.9401096105575562\n",
      "1.9401051998138428\n",
      "1.940098524093628\n",
      "1.9400936365127563\n",
      "1.9400882720947266\n",
      "1.9400831460952759\n",
      "1.940079927444458\n",
      "1.9400708675384521\n",
      "1.9400659799575806\n",
      "1.9400590658187866\n",
      "1.9400554895401\n",
      "1.9400489330291748\n",
      "1.9400447607040405\n",
      "1.9400392770767212\n",
      "1.94003427028656\n",
      "1.9400272369384766\n",
      "1.940023422241211\n",
      "1.9400161504745483\n",
      "1.9400125741958618\n",
      "1.9400056600570679\n",
      "1.9400005340576172\n",
      "1.9399954080581665\n",
      "1.9399912357330322\n",
      "1.9399856328964233\n",
      "1.9399808645248413\n",
      "1.9399747848510742\n",
      "1.93997061252594\n",
      "1.9399659633636475\n",
      "1.9399583339691162\n",
      "1.9399559497833252\n",
      "1.939950942993164\n",
      "1.9399442672729492\n",
      "1.9399394989013672\n",
      "1.9399330615997314\n",
      "tensor(1.9399)\n",
      "1.9399309158325195\n",
      "1.939923644065857\n",
      "1.9399200677871704\n",
      "1.9399150609970093\n",
      "1.9399099349975586\n",
      "1.9399054050445557\n",
      "1.9399007558822632\n",
      "1.939894437789917\n",
      "1.939889907836914\n",
      "1.9398858547210693\n",
      "1.9398796558380127\n",
      "1.939875602722168\n",
      "1.9398696422576904\n",
      "1.939866304397583\n",
      "1.9398599863052368\n",
      "1.9398558139801025\n",
      "1.9398514032363892\n",
      "1.9398475885391235\n",
      "1.9398400783538818\n",
      "1.9398367404937744\n",
      "1.939833641052246\n",
      "1.9398276805877686\n",
      "1.939822793006897\n",
      "1.939819574356079\n",
      "1.9398142099380493\n",
      "1.9398101568222046\n",
      "1.9398044347763062\n",
      "1.9398012161254883\n",
      "1.9397962093353271\n",
      "1.939790964126587\n",
      "1.9397876262664795\n",
      "1.9397802352905273\n",
      "1.9397770166397095\n",
      "1.9397739171981812\n",
      "1.9397691488265991\n",
      "1.9397618770599365\n",
      "1.9397594928741455\n",
      "1.9397554397583008\n",
      "1.9397525787353516\n",
      "1.9397459030151367\n",
      "1.9397414922714233\n",
      "1.9397379159927368\n",
      "1.939732551574707\n",
      "1.9397318363189697\n",
      "1.9397242069244385\n",
      "1.939719557762146\n",
      "1.9397151470184326\n",
      "1.9397112131118774\n",
      "1.9397070407867432\n",
      "1.9397026300430298\n",
      "1.939699411392212\n",
      "1.9396936893463135\n",
      "1.9396893978118896\n",
      "1.9396867752075195\n",
      "1.9396814107894897\n",
      "1.9396778345108032\n",
      "1.939673662185669\n",
      "1.939670205116272\n",
      "1.9396655559539795\n",
      "1.9396623373031616\n",
      "1.9396581649780273\n",
      "1.9396533966064453\n",
      "1.9396499395370483\n",
      "1.9396460056304932\n",
      "1.939640998840332\n",
      "1.9396358728408813\n",
      "1.9396326541900635\n",
      "1.9396278858184814\n",
      "1.9396240711212158\n",
      "1.9396188259124756\n",
      "1.939615249633789\n",
      "1.9396127462387085\n",
      "1.939609169960022\n",
      "1.9396040439605713\n",
      "1.9395990371704102\n",
      "1.9395959377288818\n",
      "1.9395923614501953\n",
      "1.9395889043807983\n",
      "1.939588189125061\n",
      "1.9395816326141357\n",
      "1.9395809173583984\n",
      "1.9395748376846313\n",
      "1.9395716190338135\n",
      "1.9395687580108643\n",
      "1.9395627975463867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9395592212677002\n",
      "1.9395548105239868\n",
      "1.939550757408142\n",
      "1.9395473003387451\n",
      "1.9395431280136108\n",
      "1.939538598060608\n",
      "1.9395360946655273\n",
      "1.939531683921814\n",
      "1.9395296573638916\n",
      "1.9395265579223633\n",
      "1.9395214319229126\n",
      "1.9395160675048828\n",
      "1.93951416015625\n",
      "1.9395115375518799\n",
      "1.9395078420639038\n",
      "tensor(1.9395)\n",
      "1.939504861831665\n",
      "1.9395023584365845\n",
      "1.9394960403442383\n",
      "1.9394943714141846\n",
      "1.9394893646240234\n",
      "1.9394862651824951\n",
      "1.93948233127594\n",
      "1.9394794702529907\n",
      "1.9394747018814087\n",
      "1.9394710063934326\n",
      "1.9394677877426147\n",
      "1.939467430114746\n",
      "1.9394614696502686\n",
      "1.9394569396972656\n",
      "1.9394559860229492\n",
      "1.9394519329071045\n",
      "1.9394464492797852\n",
      "1.9394433498382568\n",
      "1.939440131187439\n",
      "1.9394385814666748\n",
      "1.9394363164901733\n",
      "1.9394296407699585\n",
      "1.9394289255142212\n",
      "1.9394232034683228\n",
      "1.9394185543060303\n",
      "1.939415693283081\n",
      "1.9394134283065796\n",
      "1.939410924911499\n",
      "1.9394071102142334\n",
      "1.9394031763076782\n",
      "1.939400315284729\n",
      "1.9393999576568604\n",
      "1.9393962621688843\n",
      "1.9393926858901978\n",
      "1.9393885135650635\n",
      "1.9393848180770874\n",
      "1.9393808841705322\n",
      "1.9393800497055054\n",
      "1.9393736124038696\n",
      "1.9393707513809204\n",
      "1.9393692016601562\n",
      "1.9393647909164429\n",
      "1.939363718032837\n",
      "1.9393603801727295\n",
      "1.9393571615219116\n",
      "1.9393526315689087\n",
      "1.939349889755249\n",
      "1.9393470287322998\n",
      "1.9393455982208252\n",
      "1.939340353012085\n",
      "1.939337968826294\n",
      "1.9393329620361328\n",
      "1.9393317699432373\n",
      "1.9393278360366821\n",
      "1.9393250942230225\n",
      "1.9393224716186523\n",
      "1.9393209218978882\n",
      "1.9393173456192017\n",
      "1.9393141269683838\n",
      "1.939308524131775\n",
      "1.9393078088760376\n",
      "1.9393055438995361\n",
      "1.9393020868301392\n",
      "1.9392973184585571\n",
      "1.9392961263656616\n",
      "1.9392915964126587\n",
      "1.9392904043197632\n",
      "1.9392865896224976\n",
      "1.9392852783203125\n",
      "1.9392805099487305\n",
      "1.9392783641815186\n",
      "1.939274787902832\n",
      "1.9392735958099365\n",
      "1.9392709732055664\n",
      "1.9392662048339844\n",
      "1.939263939857483\n",
      "1.9392627477645874\n",
      "1.9392598867416382\n",
      "1.9392573833465576\n",
      "1.9392528533935547\n",
      "1.939251184463501\n",
      "1.9392458200454712\n",
      "1.9392446279525757\n",
      "1.9392417669296265\n",
      "1.939239263534546\n",
      "1.9392362833023071\n",
      "1.939234733581543\n",
      "1.9392324686050415\n",
      "1.9392290115356445\n",
      "1.9392263889312744\n",
      "1.9392240047454834\n",
      "1.9392204284667969\n",
      "1.939217209815979\n",
      "1.9392166137695312\n",
      "1.939211130142212\n",
      "1.939211130142212\n",
      "1.9392095804214478\n",
      "1.939204454421997\n",
      "1.9392039775848389\n",
      "1.9392023086547852\n",
      "tensor(1.9392)\n",
      "1.9391965866088867\n",
      "1.9391950368881226\n",
      "1.9391937255859375\n",
      "1.9391902685165405\n",
      "1.9391883611679077\n",
      "1.939182996749878\n",
      "1.9391825199127197\n",
      "1.9391794204711914\n",
      "1.939176321029663\n",
      "1.939173936843872\n",
      "1.939170479774475\n",
      "1.93916916847229\n",
      "1.9391670227050781\n",
      "1.9391647577285767\n",
      "1.9391613006591797\n",
      "1.9391605854034424\n",
      "1.9391565322875977\n",
      "1.9391553401947021\n",
      "1.9391515254974365\n",
      "1.9391502141952515\n",
      "1.9391467571258545\n",
      "1.9391441345214844\n",
      "1.9391435384750366\n",
      "1.9391396045684814\n",
      "1.9391381740570068\n",
      "1.9391357898712158\n",
      "1.939133882522583\n",
      "1.9391307830810547\n",
      "1.9391272068023682\n",
      "1.9391244649887085\n",
      "1.939123511314392\n",
      "1.9391199350357056\n",
      "1.9391181468963623\n",
      "1.93911612033844\n",
      "1.9391136169433594\n",
      "1.9391111135482788\n",
      "1.939109444618225\n",
      "1.9391086101531982\n",
      "1.9391062259674072\n",
      "1.9391043186187744\n",
      "1.9391006231307983\n",
      "1.939099669456482\n",
      "1.9390971660614014\n",
      "1.939092993736267\n",
      "1.9390901327133179\n",
      "1.9390875101089478\n",
      "1.9390888214111328\n",
      "1.9390850067138672\n",
      "1.9390819072723389\n",
      "1.9390798807144165\n",
      "1.9390789270401\n",
      "1.9390789270401\n",
      "1.9390745162963867\n",
      "1.9390712976455688\n",
      "1.9390710592269897\n",
      "1.9390672445297241\n",
      "1.939064621925354\n",
      "1.9390621185302734\n",
      "1.9390602111816406\n",
      "1.9390586614608765\n",
      "1.9390575885772705\n",
      "1.9390567541122437\n",
      "1.9390519857406616\n",
      "1.9390512704849243\n",
      "1.9390485286712646\n",
      "1.9390465021133423\n",
      "1.939043402671814\n",
      "1.9390424489974976\n",
      "1.939038634300232\n",
      "1.9390360116958618\n",
      "1.9390361309051514\n",
      "1.9390332698822021\n",
      "1.939030647277832\n",
      "1.9390299320220947\n",
      "1.9390270709991455\n",
      "1.939026117324829\n",
      "1.9390243291854858\n",
      "1.9390232563018799\n",
      "1.9390199184417725\n",
      "1.9390172958374023\n",
      "1.9390169382095337\n",
      "1.9390151500701904\n",
      "1.9390119314193726\n",
      "1.9390106201171875\n",
      "1.9390079975128174\n",
      "1.9390065670013428\n",
      "1.9390029907226562\n",
      "1.9390016794204712\n",
      "1.9390008449554443\n",
      "1.9389982223510742\n",
      "1.9389960765838623\n",
      "1.9389934539794922\n",
      "1.938990592956543\n",
      "1.938990592956543\n",
      "1.938989281654358\n",
      "1.9389854669570923\n",
      "1.938985824584961\n",
      "1.9389829635620117\n",
      "1.9389795064926147\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad() # 옵티마이저의 그래디언트를 0으로 초기화\n",
    "    output = multi_model(x) # 모델을 통해 값을 예측\n",
    "    loss = loss_func(output, label) # 정답 데이터와 예측 값과의 차이를 통해 손실함수 계산\n",
    "    print(loss.item())\n",
    "    loss.backward() # 자동미분을 통해 가중치에 대한 그래디언트 계산 calculate gradient\n",
    "    optimizer.step() # 계산한 그래디언트를 통해 가중치 업데이트 w = w - alpha * gradient\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "3c4624bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[1.8472, 2.8568, 1.1032]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.7917], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(multi_model.weight)\n",
    "print(multi_model.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a88c3f",
   "metadata": {},
   "source": [
    "# 퀴즈 (Easy)  \n",
    "1) 하이퍼파라미터를 조정해서 모델의 가중치와 편향이 정답에 가깝도록 학습시켜보세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eeb7cc9",
   "metadata": {},
   "source": [
    "## 3.3 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "69ab3471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 칠판에 그리기\n",
    "x_data = [[0, 2], [1, 2], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3f895469",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = nn.Linear(2, 1)\n",
    "sigmoid = nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c05c9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저\n",
    "optimizer = optim.SGD(linear_model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "872e68ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2100101709365845\n",
      "tensor(1.2100)\n",
      "1.205311894416809\n",
      "1.2006360292434692\n",
      "1.1959822177886963\n",
      "1.1913506984710693\n",
      "1.1867414712905884\n",
      "1.1821547746658325\n",
      "1.1775903701782227\n",
      "1.173048496246338\n",
      "1.1685291528701782\n",
      "1.1640325784683228\n",
      "tensor(1.1640)\n",
      "1.1595584154129028\n",
      "1.1551071405410767\n",
      "1.1506785154342651\n",
      "1.1462726593017578\n",
      "1.1418895721435547\n",
      "1.1375294923782349\n",
      "1.1331921815872192\n",
      "1.1288777589797974\n",
      "1.1245864629745483\n",
      "1.120318055152893\n",
      "tensor(1.1203)\n",
      "1.1160727739334106\n",
      "1.111850619316101\n",
      "1.1076513528823853\n",
      "1.1034750938415527\n",
      "1.0993221998214722\n",
      "1.0951924324035645\n",
      "1.0910857915878296\n",
      "1.0870023965835571\n",
      "1.082942008972168\n",
      "1.0789051055908203\n",
      "tensor(1.0789)\n",
      "1.074891209602356\n",
      "1.070900559425354\n",
      "1.0669333934783936\n",
      "1.0629892349243164\n",
      "1.0590683221817017\n",
      "1.0551707744598389\n",
      "1.051296353340149\n",
      "1.047445297241211\n",
      "1.0436173677444458\n",
      "1.039812684059143\n",
      "tensor(1.0398)\n",
      "1.0360313653945923\n",
      "1.0322731733322144\n",
      "1.0285382270812988\n",
      "1.0248264074325562\n",
      "1.0211378335952759\n",
      "1.017472267150879\n",
      "1.0138299465179443\n",
      "1.0102107524871826\n",
      "1.0066145658493042\n",
      "1.003041386604309\n",
      "tensor(1.0030)\n",
      "0.9994913935661316\n",
      "0.9959642887115479\n",
      "0.9924601912498474\n",
      "0.988978922367096\n",
      "0.9855207800865173\n",
      "0.9820852279663086\n",
      "0.9786726832389832\n",
      "0.9752829074859619\n",
      "0.9719157814979553\n",
      "0.9685714840888977\n",
      "tensor(0.9686)\n",
      "0.9652497172355652\n",
      "0.9619506001472473\n",
      "0.9586739540100098\n",
      "0.9554198384284973\n",
      "0.9521881937980652\n",
      "0.9489789605140686\n",
      "0.945792019367218\n",
      "0.9426273703575134\n",
      "0.9394848942756653\n",
      "0.9363645911216736\n",
      "tensor(0.9364)\n",
      "0.9332664012908936\n",
      "0.9301902651786804\n",
      "0.9271359443664551\n",
      "0.9241036772727966\n",
      "0.921093225479126\n",
      "0.9181044697761536\n",
      "0.9151372909545898\n",
      "0.9121918082237244\n",
      "0.9092679023742676\n",
      "0.9063653945922852\n",
      "tensor(0.9064)\n",
      "0.9034843444824219\n",
      "0.9006244540214539\n",
      "0.8977858424186707\n",
      "0.8949684500694275\n",
      "0.8921720385551453\n",
      "0.8893964886665344\n",
      "0.8866419792175293\n",
      "0.8839080929756165\n",
      "0.881195068359375\n",
      "0.8785024285316467\n",
      "tensor(0.8785)\n",
      "0.8758305907249451\n",
      "0.8731791377067566\n",
      "0.8705479502677917\n",
      "0.8679370284080505\n",
      "0.8653462529182434\n",
      "0.8627756237983704\n",
      "0.8602249622344971\n",
      "0.8576940894126892\n",
      "0.855182945728302\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "for i in range(num_epoch):\n",
    "    optimizer.zero_grad() \n",
    "    output = sigmoid(linear_model(x_train))\n",
    "    loss = bce_loss(output, y_train) \n",
    "    print(loss.item())\n",
    "    loss.backward() \n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print(loss.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "cde7690b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.1904,  0.2681]], requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af233f82",
   "metadata": {},
   "source": [
    "## 3.4 클래스를 통한 회귀 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "1739293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        # 부모클래스의 nn.Module 의 생성자를 먼저 호출한다.\n",
    "        super(LinearRegression, self).__init__()\n",
    "        self.linear_layer = nn.Linear(1, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # forward 메소드는 클래스 내에서 레이어들 간의 연산을 구현하는 부분이다.\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "class MultiRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultiRegression, self).__init__()\n",
    "        self.multi_layer = nn.Linear(3, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.multi_layer(x)\n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear_layer = nn.Linear(2, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.linear_layer(x)\n",
    "        x = sigmoid(x)\n",
    "        return x\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "multi_model = MultiRegression()\n",
    "logistic_model = LogisticRegression()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bc331f",
   "metadata": {},
   "source": [
    "## 퀴즈 (Normal)  \n",
    "위 세 가지 모델을 구현했으면 또 반복문을 통해 학습시켜야 합니다.  \n",
    "이는 귀찮은 과정이니 함수 형태로 만들어서 코드의 반복을 줄여봅시다.  \n",
    "텐서플로우에서 사용했던 fit 함수를 직접 만들어봅시다.  \n",
    "fit() 함수는 model, optimizer, loss_func, x_train, y_train, epochs를 입력으로 받습니다.  \n",
    "위에서 수행한 반복문을 함수형태로 만들어서 세 가지 회귀모델에 적용할 것입니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0aa034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9ecc8679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, optimizer, loss_func, x_train, y_train, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_train)\n",
    "        L = loss_func(output, y_train) \n",
    "        L.backward() \n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Epoch: {epoch + 1}/{epochs} | Loss: {L.item():4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9d8a8301",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 | Loss: 206.707535\n",
      "Epoch: 101/1000 | Loss: 80.300575\n",
      "Epoch: 201/1000 | Loss: 25.145985\n",
      "Epoch: 301/1000 | Loss: 6.747341\n",
      "Epoch: 401/1000 | Loss: 2.115411\n",
      "Epoch: 501/1000 | Loss: 1.192140\n",
      "Epoch: 601/1000 | Loss: 1.023997\n",
      "Epoch: 701/1000 | Loss: 0.991115\n",
      "Epoch: 801/1000 | Loss: 0.984252\n",
      "Epoch: 901/1000 | Loss: 0.982901\n",
      "Parameter containing:\n",
      "tensor([[1.9979]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# dataset for linear regression\n",
    "num_data = 1000\n",
    "epochs = 1000\n",
    "\n",
    "x = init.uniform_(torch.Tensor(num_data, 1), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(num_data, 1), std=1)\n",
    "y = 2*x + 3\n",
    "y_noise = y + noise\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(linear_model.parameters(), lr)\n",
    "fit(linear_model, optimizer, mse_loss, x, y_noise, epochs)\n",
    "print(linear_model.linear_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6901faa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10])\n",
      "y.shape torch.Size([10, 1])\n",
      "Epoch: 1/1000 | Loss: 377.118988\n",
      "Epoch: 101/1000 | Loss: 146.060760\n",
      "Epoch: 201/1000 | Loss: 50.614040\n",
      "Epoch: 301/1000 | Loss: 17.787920\n",
      "Epoch: 401/1000 | Loss: 7.917123\n",
      "Epoch: 501/1000 | Loss: 4.465247\n",
      "Epoch: 601/1000 | Loss: 2.749716\n",
      "Epoch: 701/1000 | Loss: 1.731630\n",
      "Epoch: 801/1000 | Loss: 1.125065\n",
      "Epoch: 901/1000 | Loss: 0.780732\n",
      "Parameter containing:\n",
      "tensor([[1.9109, 2.9347, 1.0136]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# dataset for multivariate regression\n",
    "num_data = 1000\n",
    "num_epoch = 1000\n",
    "x = init.uniform_(torch.Tensor(10, 3), -10, 10)\n",
    "noise = init.normal_(torch.FloatTensor(10, 1), std=1)\n",
    "weights = torch.tensor([2., 3., 1.])\n",
    "print(x.matmul(weights).shape)\n",
    "y = x.matmul(weights) + -1\n",
    "y = y.unsqueeze(1)\n",
    "print(f\"y.shape {y.shape}\")\n",
    "y_noise = y + noise\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(multi_model.parameters(), lr)\n",
    "fit(multi_model, optimizer, mse_loss, x, y_noise, num_epoch)\n",
    "print(multi_model.multi_layer.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "d1ff2848",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 | Loss: 1.180484\n",
      "Epoch: 101/1000 | Loss: 0.895627\n",
      "Epoch: 201/1000 | Loss: 0.716588\n",
      "Epoch: 301/1000 | Loss: 0.624826\n",
      "Epoch: 401/1000 | Loss: 0.579649\n",
      "Epoch: 501/1000 | Loss: 0.552558\n",
      "Epoch: 601/1000 | Loss: 0.531382\n",
      "Epoch: 701/1000 | Loss: 0.512291\n",
      "Epoch: 801/1000 | Loss: 0.494334\n",
      "Epoch: 901/1000 | Loss: 0.477328\n",
      "Parameter containing:\n",
      "tensor([[ 0.3856, -0.0820]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# dataset for logistic regression\n",
    "num_epoch = 1000\n",
    "x_data = [[0, 2], [1, 2], [3, 1], [4, 3], [5, 3], [6, 2]]\n",
    "y_data = [[0], [0], [0], [1], [1], [1]]\n",
    "x_train = torch.FloatTensor(x_data)\n",
    "y_train = torch.FloatTensor(y_data)\n",
    "lr = 0.001\n",
    "optimizer = optim.Adam(logistic_model.parameters(), lr)\n",
    "fit(logistic_model, optimizer, bce_loss, x_train, y_train, num_epoch)\n",
    "print(logistic_model.linear_layer.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec0f487",
   "metadata": {},
   "source": [
    "## Softmax 회귀  \n",
    "https://wikidocs.net/60575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175fa206",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
