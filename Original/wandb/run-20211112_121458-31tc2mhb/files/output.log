torch.Size([1, 28, 28])
1 28 28
13
6
2
Train Epoch: 1 | Batch Status: 0/60000             (0% | Loss: 2.341823
C:\Users\ye200\Aiffel\Torch-Master\Original\models\CNN.py:31: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  return F.log_softmax(x)
Train Epoch: 1 | Batch Status: 6400/60000             (11% | Loss: 0.335370
Train Epoch: 1 | Batch Status: 12800/60000             (21% | Loss: 0.491488
Train Epoch: 1 | Batch Status: 19200/60000             (32% | Loss: 0.513162
Train Epoch: 1 | Batch Status: 25600/60000             (43% | Loss: 0.267396
Train Epoch: 1 | Batch Status: 32000/60000             (53% | Loss: 0.435545
Train Epoch: 1 | Batch Status: 38400/60000             (64% | Loss: 0.464473
Train Epoch: 1 | Batch Status: 44800/60000             (75% | Loss: 0.258817
Train Epoch: 1 | Batch Status: 51200/60000             (85% | Loss: 0.265793
wandb: WARNING Step must only increase in log calls.  Step 0 < 937; dropping {'val_loss': tensor(0.4986, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1 < 937; dropping {'val_loss': tensor(0.2170, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 2 < 937; dropping {'val_loss': tensor(0.3087, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 3 < 937; dropping {'val_loss': tensor(0.4189, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 4 < 937; dropping {'val_loss': tensor(0.3912, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 5 < 937; dropping {'val_loss': tensor(0.2842, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 6 < 937; dropping {'val_loss': tensor(0.4448, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 7 < 937; dropping {'val_loss': tensor(0.1932, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 8 < 937; dropping {'val_loss': tensor(0.3890, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 9 < 937; dropping {'val_loss': tensor(0.2514, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 10 < 937; dropping {'val_loss': tensor(0.4241, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 11 < 937; dropping {'val_loss': tensor(0.3087, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 12 < 937; dropping {'val_loss': tensor(0.2827, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 13 < 937; dropping {'val_loss': tensor(0.3029, grad_fn=<NllLossBackward0>)}.
Train Epoch: 1 | Batch Status: 57600/60000             (96% | Loss: 0.372184
wandb: WARNING Step must only increase in log calls.  Step 14 < 937; dropping {'val_loss': tensor(0.4367, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 15 < 937; dropping {'val_loss': tensor(0.4652, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 16 < 937; dropping {'val_loss': tensor(0.2211, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 17 < 937; dropping {'val_loss': tensor(0.3384, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 18 < 937; dropping {'val_loss': tensor(0.2627, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 19 < 937; dropping {'val_loss': tensor(0.2329, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 20 < 937; dropping {'val_loss': tensor(0.2395, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 21 < 937; dropping {'val_loss': tensor(0.3873, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 22 < 937; dropping {'val_loss': tensor(0.4988, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 23 < 937; dropping {'val_loss': tensor(0.2311, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 24 < 937; dropping {'val_loss': tensor(0.3549, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 25 < 937; dropping {'val_loss': tensor(0.2443, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 26 < 937; dropping {'val_loss': tensor(0.2117, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 27 < 937; dropping {'val_loss': tensor(0.4014, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 28 < 937; dropping {'val_loss': tensor(0.3720, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 29 < 937; dropping {'val_loss': tensor(0.2972, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 30 < 937; dropping {'val_loss': tensor(0.3174, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 31 < 937; dropping {'val_loss': tensor(0.4076, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 32 < 937; dropping {'val_loss': tensor(0.2213, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 33 < 937; dropping {'val_loss': tensor(0.5743, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 34 < 937; dropping {'val_loss': tensor(0.3769, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 35 < 937; dropping {'val_loss': tensor(0.2616, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 36 < 937; dropping {'val_loss': tensor(0.2557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 37 < 937; dropping {'val_loss': tensor(0.4508, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 38 < 937; dropping {'val_loss': tensor(0.3472, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 39 < 937; dropping {'val_loss': tensor(0.2612, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 40 < 937; dropping {'val_loss': tensor(0.3047, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 41 < 937; dropping {'val_loss': tensor(0.3118, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 42 < 937; dropping {'val_loss': tensor(0.2938, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 43 < 937; dropping {'val_loss': tensor(0.4152, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 44 < 937; dropping {'val_loss': tensor(0.4620, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 45 < 937; dropping {'val_loss': tensor(0.3659, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 46 < 937; dropping {'val_loss': tensor(0.2350, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 47 < 937; dropping {'val_loss': tensor(0.4331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 48 < 937; dropping {'val_loss': tensor(0.2551, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 49 < 937; dropping {'val_loss': tensor(0.2431, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 50 < 937; dropping {'val_loss': tensor(0.3776, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 51 < 937; dropping {'val_loss': tensor(0.2272, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 52 < 937; dropping {'val_loss': tensor(0.2832, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 53 < 937; dropping {'val_loss': tensor(0.1236, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 54 < 937; dropping {'val_loss': tensor(0.3335, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 55 < 937; dropping {'val_loss': tensor(0.4016, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 56 < 937; dropping {'val_loss': tensor(0.3361, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 57 < 937; dropping {'val_loss': tensor(0.3578, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 58 < 937; dropping {'val_loss': tensor(0.3420, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 59 < 937; dropping {'val_loss': tensor(0.1280, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 60 < 937; dropping {'val_loss': tensor(0.2485, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 61 < 937; dropping {'val_loss': tensor(0.3218, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 62 < 937; dropping {'val_loss': tensor(0.3472, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 63 < 937; dropping {'val_loss': tensor(0.3842, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 64 < 937; dropping {'val_loss': tensor(0.1955, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 65 < 937; dropping {'val_loss': tensor(0.1728, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 66 < 937; dropping {'val_loss': tensor(0.2210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 67 < 937; dropping {'val_loss': tensor(0.3184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 68 < 937; dropping {'val_loss': tensor(0.2873, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 69 < 937; dropping {'val_loss': tensor(0.3875, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 70 < 937; dropping {'val_loss': tensor(0.2996, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 71 < 937; dropping {'val_loss': tensor(0.2676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 72 < 937; dropping {'val_loss': tensor(0.4621, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 73 < 937; dropping {'val_loss': tensor(0.1756, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 74 < 937; dropping {'val_loss': tensor(0.2700, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 75 < 937; dropping {'val_loss': tensor(0.3188, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 76 < 937; dropping {'val_loss': tensor(0.5075, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 77 < 937; dropping {'val_loss': tensor(0.4313, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 78 < 937; dropping {'val_loss': tensor(0.2344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 79 < 937; dropping {'val_loss': tensor(0.2724, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 80 < 937; dropping {'val_loss': tensor(0.3246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 81 < 937; dropping {'val_loss': tensor(0.5939, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 82 < 937; dropping {'val_loss': tensor(0.1974, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 83 < 937; dropping {'val_loss': tensor(0.4518, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 84 < 937; dropping {'val_loss': tensor(0.3470, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 85 < 937; dropping {'val_loss': tensor(0.2829, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 86 < 937; dropping {'val_loss': tensor(0.3485, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 87 < 937; dropping {'val_loss': tensor(0.2260, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 88 < 937; dropping {'val_loss': tensor(0.4467, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 89 < 937; dropping {'val_loss': tensor(0.2944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 90 < 937; dropping {'val_loss': tensor(0.2581, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 91 < 937; dropping {'val_loss': tensor(0.2956, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 92 < 937; dropping {'val_loss': tensor(0.3541, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 93 < 937; dropping {'val_loss': tensor(0.5468, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 94 < 937; dropping {'val_loss': tensor(0.3474, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 95 < 937; dropping {'val_loss': tensor(0.2377, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 96 < 937; dropping {'val_loss': tensor(0.2127, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 97 < 937; dropping {'val_loss': tensor(0.3348, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 98 < 937; dropping {'val_loss': tensor(0.2276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 99 < 937; dropping {'val_loss': tensor(0.3420, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 100 < 937; dropping {'val_loss': tensor(0.4243, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 101 < 937; dropping {'val_loss': tensor(0.3310, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 102 < 937; dropping {'val_loss': tensor(0.3433, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 103 < 937; dropping {'val_loss': tensor(0.2528, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 104 < 937; dropping {'val_loss': tensor(0.3358, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 105 < 937; dropping {'val_loss': tensor(0.3020, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 106 < 937; dropping {'val_loss': tensor(0.2410, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 107 < 937; dropping {'val_loss': tensor(0.2594, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 108 < 937; dropping {'val_loss': tensor(0.2116, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 109 < 937; dropping {'val_loss': tensor(0.2867, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 110 < 937; dropping {'val_loss': tensor(0.1914, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 111 < 937; dropping {'val_loss': tensor(0.4285, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 112 < 937; dropping {'val_loss': tensor(0.3218, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 113 < 937; dropping {'val_loss': tensor(0.2937, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 114 < 937; dropping {'val_loss': tensor(0.2176, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 115 < 937; dropping {'val_loss': tensor(0.3885, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 116 < 937; dropping {'val_loss': tensor(0.3273, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 117 < 937; dropping {'val_loss': tensor(0.3917, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 118 < 937; dropping {'val_loss': tensor(0.2826, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 0/60000             (0% | Loss: 0.208681
wandb: WARNING Step must only increase in log calls.  Step 119 < 937; dropping {'val_loss': tensor(0.3055, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 120 < 937; dropping {'val_loss': tensor(0.2147, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 121 < 937; dropping {'val_loss': tensor(0.1396, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 122 < 937; dropping {'val_loss': tensor(0.3930, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 123 < 937; dropping {'val_loss': tensor(0.2962, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 124 < 937; dropping {'val_loss': tensor(0.4472, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 125 < 937; dropping {'val_loss': tensor(0.2252, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 126 < 937; dropping {'val_loss': tensor(0.2810, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 127 < 937; dropping {'val_loss': tensor(0.3071, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 128 < 937; dropping {'val_loss': tensor(0.3938, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 129 < 937; dropping {'val_loss': tensor(0.1122, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 130 < 937; dropping {'val_loss': tensor(0.2475, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 131 < 937; dropping {'val_loss': tensor(0.3088, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 132 < 937; dropping {'val_loss': tensor(0.2570, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 133 < 937; dropping {'val_loss': tensor(0.2281, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 134 < 937; dropping {'val_loss': tensor(0.2478, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 135 < 937; dropping {'val_loss': tensor(0.3024, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 136 < 937; dropping {'val_loss': tensor(0.3821, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 137 < 937; dropping {'val_loss': tensor(0.4301, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 138 < 937; dropping {'val_loss': tensor(0.2720, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 139 < 937; dropping {'val_loss': tensor(0.3150, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 140 < 937; dropping {'val_loss': tensor(0.3025, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 141 < 937; dropping {'val_loss': tensor(0.3664, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 142 < 937; dropping {'val_loss': tensor(0.2412, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 143 < 937; dropping {'val_loss': tensor(0.3406, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 144 < 937; dropping {'val_loss': tensor(0.1143, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 145 < 937; dropping {'val_loss': tensor(0.2224, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 146 < 937; dropping {'val_loss': tensor(0.4228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 147 < 937; dropping {'val_loss': tensor(0.2276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 148 < 937; dropping {'val_loss': tensor(0.2811, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 149 < 937; dropping {'val_loss': tensor(0.3447, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 150 < 937; dropping {'val_loss': tensor(0.2374, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 151 < 937; dropping {'val_loss': tensor(0.1107, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 152 < 937; dropping {'val_loss': tensor(0.0937, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 153 < 937; dropping {'val_loss': tensor(0.2254, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 154 < 937; dropping {'val_loss': tensor(0.3781, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 155 < 937; dropping {'val_loss': tensor(0.3123, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 156 < 937; dropping {'val_loss': tensor(0.1801, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 64 < 937; dropping {'train_loss': tensor(0.2087, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 65 < 937; dropping {'train_loss': tensor(0.2273, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 66 < 937; dropping {'train_loss': tensor(0.3302, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 67 < 937; dropping {'train_loss': tensor(0.3289, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 68 < 937; dropping {'train_loss': tensor(0.1543, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 69 < 937; dropping {'train_loss': tensor(0.4223, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 70 < 937; dropping {'train_loss': tensor(0.5593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 71 < 937; dropping {'train_loss': tensor(0.2346, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 72 < 937; dropping {'train_loss': tensor(0.2068, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 73 < 937; dropping {'train_loss': tensor(0.2210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 74 < 937; dropping {'train_loss': tensor(0.3068, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 75 < 937; dropping {'train_loss': tensor(0.2985, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 76 < 937; dropping {'train_loss': tensor(0.2853, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 77 < 937; dropping {'train_loss': tensor(0.2920, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 78 < 937; dropping {'train_loss': tensor(0.1724, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 79 < 937; dropping {'train_loss': tensor(0.2011, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 80 < 937; dropping {'train_loss': tensor(0.1891, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 81 < 937; dropping {'train_loss': tensor(0.2466, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 82 < 937; dropping {'train_loss': tensor(0.3404, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 83 < 937; dropping {'train_loss': tensor(0.2918, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 84 < 937; dropping {'train_loss': tensor(0.2448, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 85 < 937; dropping {'train_loss': tensor(0.3359, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 86 < 937; dropping {'train_loss': tensor(0.3920, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 87 < 937; dropping {'train_loss': tensor(0.2503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 88 < 937; dropping {'train_loss': tensor(0.3794, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 89 < 937; dropping {'train_loss': tensor(0.2302, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 90 < 937; dropping {'train_loss': tensor(0.4165, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 91 < 937; dropping {'train_loss': tensor(0.2246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 92 < 937; dropping {'train_loss': tensor(0.4257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 93 < 937; dropping {'train_loss': tensor(0.1640, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 94 < 937; dropping {'train_loss': tensor(0.4129, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 95 < 937; dropping {'train_loss': tensor(0.3803, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 96 < 937; dropping {'train_loss': tensor(0.3291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 97 < 937; dropping {'train_loss': tensor(0.2190, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 98 < 937; dropping {'train_loss': tensor(0.4495, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 99 < 937; dropping {'train_loss': tensor(0.2486, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 100 < 937; dropping {'train_loss': tensor(0.3498, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 101 < 937; dropping {'train_loss': tensor(0.4580, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 102 < 937; dropping {'train_loss': tensor(0.3663, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 103 < 937; dropping {'train_loss': tensor(0.2376, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 104 < 937; dropping {'train_loss': tensor(0.3594, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 105 < 937; dropping {'train_loss': tensor(0.4463, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 106 < 937; dropping {'train_loss': tensor(0.1528, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 107 < 937; dropping {'train_loss': tensor(0.2998, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 108 < 937; dropping {'train_loss': tensor(0.3330, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 109 < 937; dropping {'train_loss': tensor(0.4061, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 110 < 937; dropping {'train_loss': tensor(0.2871, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 111 < 937; dropping {'train_loss': tensor(0.3120, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 112 < 937; dropping {'train_loss': tensor(0.3571, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 113 < 937; dropping {'train_loss': tensor(0.5556, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 114 < 937; dropping {'train_loss': tensor(0.2049, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 115 < 937; dropping {'train_loss': tensor(0.2926, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 116 < 937; dropping {'train_loss': tensor(0.3781, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 117 < 937; dropping {'train_loss': tensor(0.3817, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 118 < 937; dropping {'train_loss': tensor(0.1923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 119 < 937; dropping {'train_loss': tensor(0.3511, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 120 < 937; dropping {'train_loss': tensor(0.2858, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 121 < 937; dropping {'train_loss': tensor(0.2461, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 122 < 937; dropping {'train_loss': tensor(0.4424, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 123 < 937; dropping {'train_loss': tensor(0.2558, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 124 < 937; dropping {'train_loss': tensor(0.3345, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 125 < 937; dropping {'train_loss': tensor(0.4190, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 126 < 937; dropping {'train_loss': tensor(0.1922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 127 < 937; dropping {'train_loss': tensor(0.2621, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 128 < 937; dropping {'train_loss': tensor(0.2656, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 129 < 937; dropping {'train_loss': tensor(0.3153, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 130 < 937; dropping {'train_loss': tensor(0.2219, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 131 < 937; dropping {'train_loss': tensor(0.2369, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 132 < 937; dropping {'train_loss': tensor(0.2276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 133 < 937; dropping {'train_loss': tensor(0.2963, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 134 < 937; dropping {'train_loss': tensor(0.3452, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 135 < 937; dropping {'train_loss': tensor(0.1575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 136 < 937; dropping {'train_loss': tensor(0.4455, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 137 < 937; dropping {'train_loss': tensor(0.1902, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 138 < 937; dropping {'train_loss': tensor(0.2666, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 139 < 937; dropping {'train_loss': tensor(0.2344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 140 < 937; dropping {'train_loss': tensor(0.4567, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 141 < 937; dropping {'train_loss': tensor(0.2256, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 142 < 937; dropping {'train_loss': tensor(0.4776, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 143 < 937; dropping {'train_loss': tensor(0.4589, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 144 < 937; dropping {'train_loss': tensor(0.2127, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 145 < 937; dropping {'train_loss': tensor(0.4210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 146 < 937; dropping {'train_loss': tensor(0.2798, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 147 < 937; dropping {'train_loss': tensor(0.3703, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 148 < 937; dropping {'train_loss': tensor(0.4645, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 149 < 937; dropping {'train_loss': tensor(0.3155, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 150 < 937; dropping {'train_loss': tensor(0.4640, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 151 < 937; dropping {'train_loss': tensor(0.2525, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 152 < 937; dropping {'train_loss': tensor(0.1265, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 153 < 937; dropping {'train_loss': tensor(0.2198, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 154 < 937; dropping {'train_loss': tensor(0.2811, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 155 < 937; dropping {'train_loss': tensor(0.2980, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 156 < 937; dropping {'train_loss': tensor(0.2877, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 157 < 937; dropping {'train_loss': tensor(0.3634, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 158 < 937; dropping {'train_loss': tensor(0.3130, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 159 < 937; dropping {'train_loss': tensor(0.2880, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 160 < 937; dropping {'train_loss': tensor(0.4334, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 161 < 937; dropping {'train_loss': tensor(0.2786, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 162 < 937; dropping {'train_loss': tensor(0.2572, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 163 < 937; dropping {'train_loss': tensor(0.1819, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 164 < 937; dropping {'train_loss': tensor(0.3669, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 165 < 937; dropping {'train_loss': tensor(0.2934, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 166 < 937; dropping {'train_loss': tensor(0.1235, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 167 < 937; dropping {'train_loss': tensor(0.2611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 168 < 937; dropping {'train_loss': tensor(0.1612, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 169 < 937; dropping {'train_loss': tensor(0.1899, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 170 < 937; dropping {'train_loss': tensor(0.2718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 171 < 937; dropping {'train_loss': tensor(0.3094, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 172 < 937; dropping {'train_loss': tensor(0.2854, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 6400/60000             (11% | Loss: 0.366855
wandb: WARNING Step must only increase in log calls.  Step 173 < 937; dropping {'train_loss': tensor(0.3139, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 174 < 937; dropping {'train_loss': tensor(0.3018, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 175 < 937; dropping {'train_loss': tensor(0.2936, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 176 < 937; dropping {'train_loss': tensor(0.3445, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 177 < 937; dropping {'train_loss': tensor(0.4256, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 178 < 937; dropping {'train_loss': tensor(0.4375, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 179 < 937; dropping {'train_loss': tensor(0.3610, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 180 < 937; dropping {'train_loss': tensor(0.3385, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 181 < 937; dropping {'train_loss': tensor(0.1113, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 182 < 937; dropping {'train_loss': tensor(0.4944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 183 < 937; dropping {'train_loss': tensor(0.4469, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 184 < 937; dropping {'train_loss': tensor(0.2277, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 185 < 937; dropping {'train_loss': tensor(0.1623, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 186 < 937; dropping {'train_loss': tensor(0.2300, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 187 < 937; dropping {'train_loss': tensor(0.1612, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 188 < 937; dropping {'train_loss': tensor(0.2007, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 189 < 937; dropping {'train_loss': tensor(0.2243, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 190 < 937; dropping {'train_loss': tensor(0.1114, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 191 < 937; dropping {'train_loss': tensor(0.2437, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 192 < 937; dropping {'train_loss': tensor(0.3806, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 193 < 937; dropping {'train_loss': tensor(0.4061, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 194 < 937; dropping {'train_loss': tensor(0.2263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 195 < 937; dropping {'train_loss': tensor(0.3476, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 196 < 937; dropping {'train_loss': tensor(0.3433, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 197 < 937; dropping {'train_loss': tensor(0.2192, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 198 < 937; dropping {'train_loss': tensor(0.3320, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 199 < 937; dropping {'train_loss': tensor(0.1954, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 200 < 937; dropping {'train_loss': tensor(0.2754, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 201 < 937; dropping {'train_loss': tensor(0.3365, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 202 < 937; dropping {'train_loss': tensor(0.3245, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 203 < 937; dropping {'train_loss': tensor(0.3079, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 204 < 937; dropping {'train_loss': tensor(0.4279, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 205 < 937; dropping {'train_loss': tensor(0.2046, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 206 < 937; dropping {'train_loss': tensor(0.3785, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 207 < 937; dropping {'train_loss': tensor(0.2663, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 208 < 937; dropping {'train_loss': tensor(0.3516, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 209 < 937; dropping {'train_loss': tensor(0.3236, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 210 < 937; dropping {'train_loss': tensor(0.3622, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 211 < 937; dropping {'train_loss': tensor(0.2619, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 212 < 937; dropping {'train_loss': tensor(0.3334, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 213 < 937; dropping {'train_loss': tensor(0.2727, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 214 < 937; dropping {'train_loss': tensor(0.2738, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 215 < 937; dropping {'train_loss': tensor(0.3546, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 216 < 937; dropping {'train_loss': tensor(0.3910, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 217 < 937; dropping {'train_loss': tensor(0.2532, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 218 < 937; dropping {'train_loss': tensor(0.1847, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 219 < 937; dropping {'train_loss': tensor(0.3759, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 220 < 937; dropping {'train_loss': tensor(0.2418, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 221 < 937; dropping {'train_loss': tensor(0.2052, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 222 < 937; dropping {'train_loss': tensor(0.3492, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 223 < 937; dropping {'train_loss': tensor(0.2824, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 224 < 937; dropping {'train_loss': tensor(0.1562, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 225 < 937; dropping {'train_loss': tensor(0.4711, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 226 < 937; dropping {'train_loss': tensor(0.2659, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 227 < 937; dropping {'train_loss': tensor(0.1585, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 228 < 937; dropping {'train_loss': tensor(0.2514, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 229 < 937; dropping {'train_loss': tensor(0.2311, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 230 < 937; dropping {'train_loss': tensor(0.1661, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 231 < 937; dropping {'train_loss': tensor(0.3371, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 232 < 937; dropping {'train_loss': tensor(0.2983, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 233 < 937; dropping {'train_loss': tensor(0.2243, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 234 < 937; dropping {'train_loss': tensor(0.4198, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 235 < 937; dropping {'train_loss': tensor(0.2613, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 236 < 937; dropping {'train_loss': tensor(0.2884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 237 < 937; dropping {'train_loss': tensor(0.2775, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 238 < 937; dropping {'train_loss': tensor(0.2690, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 239 < 937; dropping {'train_loss': tensor(0.3155, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 12800/60000             (21% | Loss: 0.282945
wandb: WARNING Step must only increase in log calls.  Step 240 < 937; dropping {'train_loss': tensor(0.3164, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 241 < 937; dropping {'train_loss': tensor(0.2641, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 242 < 937; dropping {'train_loss': tensor(0.3038, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 243 < 937; dropping {'train_loss': tensor(0.4088, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 244 < 937; dropping {'train_loss': tensor(0.2548, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 245 < 937; dropping {'train_loss': tensor(0.4830, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 246 < 937; dropping {'train_loss': tensor(0.4087, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 247 < 937; dropping {'train_loss': tensor(0.2761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 248 < 937; dropping {'train_loss': tensor(0.2134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 249 < 937; dropping {'train_loss': tensor(0.5372, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 250 < 937; dropping {'train_loss': tensor(0.1009, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 251 < 937; dropping {'train_loss': tensor(0.3773, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 252 < 937; dropping {'train_loss': tensor(0.1271, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 253 < 937; dropping {'train_loss': tensor(0.3008, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 254 < 937; dropping {'train_loss': tensor(0.4024, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 255 < 937; dropping {'train_loss': tensor(0.5384, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 256 < 937; dropping {'train_loss': tensor(0.3723, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 257 < 937; dropping {'train_loss': tensor(0.1606, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 258 < 937; dropping {'train_loss': tensor(0.3643, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 259 < 937; dropping {'train_loss': tensor(0.2602, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 260 < 937; dropping {'train_loss': tensor(0.4456, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 261 < 937; dropping {'train_loss': tensor(0.2675, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 262 < 937; dropping {'train_loss': tensor(0.2898, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 263 < 937; dropping {'train_loss': tensor(0.2852, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 264 < 937; dropping {'train_loss': tensor(0.2829, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 265 < 937; dropping {'train_loss': tensor(0.1537, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 266 < 937; dropping {'train_loss': tensor(0.1756, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 267 < 937; dropping {'train_loss': tensor(0.1200, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 268 < 937; dropping {'train_loss': tensor(0.1260, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 269 < 937; dropping {'train_loss': tensor(0.4224, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 270 < 937; dropping {'train_loss': tensor(0.3898, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 271 < 937; dropping {'train_loss': tensor(0.1116, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 272 < 937; dropping {'train_loss': tensor(0.3309, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 273 < 937; dropping {'train_loss': tensor(0.2268, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 274 < 937; dropping {'train_loss': tensor(0.3160, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 275 < 937; dropping {'train_loss': tensor(0.3376, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 276 < 937; dropping {'train_loss': tensor(0.4457, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 277 < 937; dropping {'train_loss': tensor(0.1591, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 278 < 937; dropping {'train_loss': tensor(0.3543, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 279 < 937; dropping {'train_loss': tensor(0.0936, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 280 < 937; dropping {'train_loss': tensor(0.3447, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 281 < 937; dropping {'train_loss': tensor(0.1976, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 282 < 937; dropping {'train_loss': tensor(0.4174, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 283 < 937; dropping {'train_loss': tensor(0.2885, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 284 < 937; dropping {'train_loss': tensor(0.1879, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 285 < 937; dropping {'train_loss': tensor(0.2709, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 293 < 937; dropping {'train_loss': tensor(0.3404, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 294 < 937; dropping {'train_loss': tensor(0.2715, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 295 < 937; dropping {'train_loss': tensor(0.2125, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 296 < 937; dropping {'train_loss': tensor(0.2697, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 297 < 937; dropping {'train_loss': tensor(0.4706, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 298 < 937; dropping {'train_loss': tensor(0.2071, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 299 < 937; dropping {'train_loss': tensor(0.3711, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 300 < 937; dropping {'train_loss': tensor(0.3013, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 301 < 937; dropping {'train_loss': tensor(0.3196, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 302 < 937; dropping {'train_loss': tensor(0.3318, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 303 < 937; dropping {'train_loss': tensor(0.2252, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 304 < 937; dropping {'train_loss': tensor(0.4412, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 305 < 937; dropping {'train_loss': tensor(0.1579, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 306 < 937; dropping {'train_loss': tensor(0.3850, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 307 < 937; dropping {'train_loss': tensor(0.2605, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 308 < 937; dropping {'train_loss': tensor(0.2423, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 309 < 937; dropping {'train_loss': tensor(0.3741, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 310 < 937; dropping {'train_loss': tensor(0.2621, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 311 < 937; dropping {'train_loss': tensor(0.2995, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 312 < 937; dropping {'train_loss': tensor(0.4135, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 313 < 937; dropping {'train_loss': tensor(0.3107, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 314 < 937; dropping {'train_loss': tensor(0.1680, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 315 < 937; dropping {'train_loss': tensor(0.1681, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 316 < 937; dropping {'train_loss': tensor(0.4138, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 317 < 937; dropping {'train_loss': tensor(0.2575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 318 < 937; dropping {'train_loss': tensor(0.4473, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 319 < 937; dropping {'train_loss': tensor(0.2017, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 320 < 937; dropping {'train_loss': tensor(0.3961, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 321 < 937; dropping {'train_loss': tensor(0.4932, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 322 < 937; dropping {'train_loss': tensor(0.2653, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 323 < 937; dropping {'train_loss': tensor(0.4058, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 324 < 937; dropping {'train_loss': tensor(0.4363, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 325 < 937; dropping {'train_loss': tensor(0.3848, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 326 < 937; dropping {'train_loss': tensor(0.1440, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 327 < 937; dropping {'train_loss': tensor(0.3229, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 328 < 937; dropping {'train_loss': tensor(0.2798, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 329 < 937; dropping {'train_loss': tensor(0.3110, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 330 < 937; dropping {'train_loss': tensor(0.1846, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 331 < 937; dropping {'train_loss': tensor(0.2632, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 332 < 937; dropping {'train_loss': tensor(0.3311, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 333 < 937; dropping {'train_loss': tensor(0.3396, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 334 < 937; dropping {'train_loss': tensor(0.3048, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 335 < 937; dropping {'train_loss': tensor(0.2923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 336 < 937; dropping {'train_loss': tensor(0.1928, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 337 < 937; dropping {'train_loss': tensor(0.4411, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 338 < 937; dropping {'train_loss': tensor(0.2374, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 339 < 937; dropping {'train_loss': tensor(0.1614, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 340 < 937; dropping {'train_loss': tensor(0.2381, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 341 < 937; dropping {'train_loss': tensor(0.3975, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 342 < 937; dropping {'train_loss': tensor(0.3544, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 343 < 937; dropping {'train_loss': tensor(0.3576, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 344 < 937; dropping {'train_loss': tensor(0.2592, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 345 < 937; dropping {'train_loss': tensor(0.1197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 346 < 937; dropping {'train_loss': tensor(0.4228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 347 < 937; dropping {'train_loss': tensor(0.7460, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 348 < 937; dropping {'train_loss': tensor(0.3252, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 349 < 937; dropping {'train_loss': tensor(0.2530, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 350 < 937; dropping {'train_loss': tensor(0.4584, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 351 < 937; dropping {'train_loss': tensor(0.3125, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 352 < 937; dropping {'train_loss': tensor(0.2052, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 19200/60000             (32% | Loss: 0.226853
wandb: WARNING Step must only increase in log calls.  Step 353 < 937; dropping {'train_loss': tensor(0.3421, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 354 < 937; dropping {'train_loss': tensor(0.3867, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 355 < 937; dropping {'train_loss': tensor(0.3297, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 356 < 937; dropping {'train_loss': tensor(0.4741, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 357 < 937; dropping {'train_loss': tensor(0.2726, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 358 < 937; dropping {'train_loss': tensor(0.1835, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 359 < 937; dropping {'train_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 360 < 937; dropping {'train_loss': tensor(0.3182, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 361 < 937; dropping {'train_loss': tensor(0.2371, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 362 < 937; dropping {'train_loss': tensor(0.2967, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 363 < 937; dropping {'train_loss': tensor(0.4637, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 364 < 937; dropping {'train_loss': tensor(0.2269, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 365 < 937; dropping {'train_loss': tensor(0.1234, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 366 < 937; dropping {'train_loss': tensor(0.3778, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 367 < 937; dropping {'train_loss': tensor(0.3462, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 368 < 937; dropping {'train_loss': tensor(0.2593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 369 < 937; dropping {'train_loss': tensor(0.4355, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 370 < 937; dropping {'train_loss': tensor(0.4744, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 371 < 937; dropping {'train_loss': tensor(0.5593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 372 < 937; dropping {'train_loss': tensor(0.2416, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 373 < 937; dropping {'train_loss': tensor(0.3331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 374 < 937; dropping {'train_loss': tensor(0.2708, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 375 < 937; dropping {'train_loss': tensor(0.1681, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 376 < 937; dropping {'train_loss': tensor(0.2810, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 377 < 937; dropping {'train_loss': tensor(0.1350, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 378 < 937; dropping {'train_loss': tensor(0.3046, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 379 < 937; dropping {'train_loss': tensor(0.2317, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 380 < 937; dropping {'train_loss': tensor(0.3731, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 381 < 937; dropping {'train_loss': tensor(0.3196, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 382 < 937; dropping {'train_loss': tensor(0.4459, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 383 < 937; dropping {'train_loss': tensor(0.1778, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 384 < 937; dropping {'train_loss': tensor(0.3330, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 385 < 937; dropping {'train_loss': tensor(0.3043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 386 < 937; dropping {'train_loss': tensor(0.4877, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 387 < 937; dropping {'train_loss': tensor(0.1318, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 388 < 937; dropping {'train_loss': tensor(0.1943, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 389 < 937; dropping {'train_loss': tensor(0.3503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 390 < 937; dropping {'train_loss': tensor(0.2167, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 391 < 937; dropping {'train_loss': tensor(0.2227, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 392 < 937; dropping {'train_loss': tensor(0.2361, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 393 < 937; dropping {'train_loss': tensor(0.4519, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 394 < 937; dropping {'train_loss': tensor(0.4037, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 395 < 937; dropping {'train_loss': tensor(0.1979, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 396 < 937; dropping {'train_loss': tensor(0.3714, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 397 < 937; dropping {'train_loss': tensor(0.1160, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 398 < 937; dropping {'train_loss': tensor(0.4299, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 399 < 937; dropping {'train_loss': tensor(0.2071, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 400 < 937; dropping {'train_loss': tensor(0.3253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 401 < 937; dropping {'train_loss': tensor(0.2317, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 402 < 937; dropping {'train_loss': tensor(0.3661, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 403 < 937; dropping {'train_loss': tensor(0.3832, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 404 < 937; dropping {'train_loss': tensor(0.3278, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 405 < 937; dropping {'train_loss': tensor(0.2346, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 406 < 937; dropping {'train_loss': tensor(0.4099, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 407 < 937; dropping {'train_loss': tensor(0.4491, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 408 < 937; dropping {'train_loss': tensor(0.3251, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 409 < 937; dropping {'train_loss': tensor(0.3114, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 410 < 937; dropping {'train_loss': tensor(0.4517, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 411 < 937; dropping {'train_loss': tensor(0.4413, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 412 < 937; dropping {'train_loss': tensor(0.1569, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 413 < 937; dropping {'train_loss': tensor(0.2718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 414 < 937; dropping {'train_loss': tensor(0.3148, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 415 < 937; dropping {'train_loss': tensor(0.3357, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 416 < 937; dropping {'train_loss': tensor(0.3440, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 417 < 937; dropping {'train_loss': tensor(0.3812, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 418 < 937; dropping {'train_loss': tensor(0.3399, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 419 < 937; dropping {'train_loss': tensor(0.4071, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 420 < 937; dropping {'train_loss': tensor(0.1237, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 421 < 937; dropping {'train_loss': tensor(0.2985, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 422 < 937; dropping {'train_loss': tensor(0.3295, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 423 < 937; dropping {'train_loss': tensor(0.1429, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 424 < 937; dropping {'train_loss': tensor(0.3725, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 425 < 937; dropping {'train_loss': tensor(0.2977, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 426 < 937; dropping {'train_loss': tensor(0.4133, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 427 < 937; dropping {'train_loss': tensor(0.3652, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 25600/60000             (43% | Loss: 0.434207
wandb: WARNING Step must only increase in log calls.  Step 428 < 937; dropping {'train_loss': tensor(0.3392, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 429 < 937; dropping {'train_loss': tensor(0.3211, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 430 < 937; dropping {'train_loss': tensor(0.2042, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 431 < 937; dropping {'train_loss': tensor(0.3006, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 432 < 937; dropping {'train_loss': tensor(0.3689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 433 < 937; dropping {'train_loss': tensor(0.3078, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 434 < 937; dropping {'train_loss': tensor(0.3261, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 435 < 937; dropping {'train_loss': tensor(0.2818, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 436 < 937; dropping {'train_loss': tensor(0.3503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 437 < 937; dropping {'train_loss': tensor(0.3191, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 438 < 937; dropping {'train_loss': tensor(0.3382, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 439 < 937; dropping {'train_loss': tensor(0.2564, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 440 < 937; dropping {'train_loss': tensor(0.4777, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 441 < 937; dropping {'train_loss': tensor(0.4072, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 442 < 937; dropping {'train_loss': tensor(0.5234, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 443 < 937; dropping {'train_loss': tensor(0.3377, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 444 < 937; dropping {'train_loss': tensor(0.3035, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 445 < 937; dropping {'train_loss': tensor(0.2693, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 446 < 937; dropping {'train_loss': tensor(0.3288, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 447 < 937; dropping {'train_loss': tensor(0.3819, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 448 < 937; dropping {'train_loss': tensor(0.3183, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 449 < 937; dropping {'train_loss': tensor(0.2894, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 450 < 937; dropping {'train_loss': tensor(0.2611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 451 < 937; dropping {'train_loss': tensor(0.6166, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 452 < 937; dropping {'train_loss': tensor(0.3221, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 453 < 937; dropping {'train_loss': tensor(0.3556, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 454 < 937; dropping {'train_loss': tensor(0.1892, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 455 < 937; dropping {'train_loss': tensor(0.3936, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 456 < 937; dropping {'train_loss': tensor(0.2377, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 457 < 937; dropping {'train_loss': tensor(0.4962, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 458 < 937; dropping {'train_loss': tensor(0.3050, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 459 < 937; dropping {'train_loss': tensor(0.4344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 460 < 937; dropping {'train_loss': tensor(0.3295, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 461 < 937; dropping {'train_loss': tensor(0.3428, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 462 < 937; dropping {'train_loss': tensor(0.2331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 463 < 937; dropping {'train_loss': tensor(0.3341, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 464 < 937; dropping {'train_loss': tensor(0.4342, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 465 < 937; dropping {'train_loss': tensor(0.2217, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 466 < 937; dropping {'train_loss': tensor(0.4348, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 467 < 937; dropping {'train_loss': tensor(0.1493, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 468 < 937; dropping {'train_loss': tensor(0.5280, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 469 < 937; dropping {'train_loss': tensor(0.2801, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 470 < 937; dropping {'train_loss': tensor(0.3321, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 471 < 937; dropping {'train_loss': tensor(0.3083, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 472 < 937; dropping {'train_loss': tensor(0.2997, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 473 < 937; dropping {'train_loss': tensor(0.2891, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 474 < 937; dropping {'train_loss': tensor(0.3061, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 475 < 937; dropping {'train_loss': tensor(0.3499, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 476 < 937; dropping {'train_loss': tensor(0.2722, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 477 < 937; dropping {'train_loss': tensor(0.2464, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 478 < 937; dropping {'train_loss': tensor(0.2496, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 479 < 937; dropping {'train_loss': tensor(0.2510, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 480 < 937; dropping {'train_loss': tensor(0.5271, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 481 < 937; dropping {'train_loss': tensor(0.3933, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 482 < 937; dropping {'train_loss': tensor(0.2965, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 483 < 937; dropping {'train_loss': tensor(0.3446, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 484 < 937; dropping {'train_loss': tensor(0.1610, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 485 < 937; dropping {'train_loss': tensor(0.1523, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 486 < 937; dropping {'train_loss': tensor(0.2587, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 487 < 937; dropping {'train_loss': tensor(0.2257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 488 < 937; dropping {'train_loss': tensor(0.2255, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 489 < 937; dropping {'train_loss': tensor(0.1376, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 490 < 937; dropping {'train_loss': tensor(0.2653, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 491 < 937; dropping {'train_loss': tensor(0.3581, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 492 < 937; dropping {'train_loss': tensor(0.3214, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 493 < 937; dropping {'train_loss': tensor(0.3669, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 494 < 937; dropping {'train_loss': tensor(0.2310, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 495 < 937; dropping {'train_loss': tensor(0.5404, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 496 < 937; dropping {'train_loss': tensor(0.1687, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 497 < 937; dropping {'train_loss': tensor(0.3130, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 498 < 937; dropping {'train_loss': tensor(0.0787, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 499 < 937; dropping {'train_loss': tensor(0.3136, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 500 < 937; dropping {'train_loss': tensor(0.1645, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 501 < 937; dropping {'train_loss': tensor(0.3560, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 502 < 937; dropping {'train_loss': tensor(0.3040, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 503 < 937; dropping {'train_loss': tensor(0.2590, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 504 < 937; dropping {'train_loss': tensor(0.1170, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 505 < 937; dropping {'train_loss': tensor(0.3305, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 506 < 937; dropping {'train_loss': tensor(0.4379, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 507 < 937; dropping {'train_loss': tensor(0.2265, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 508 < 937; dropping {'train_loss': tensor(0.4140, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 509 < 937; dropping {'train_loss': tensor(0.2432, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 510 < 937; dropping {'train_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 511 < 937; dropping {'train_loss': tensor(0.3113, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 512 < 937; dropping {'train_loss': tensor(0.3060, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 513 < 937; dropping {'train_loss': tensor(0.2515, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 514 < 937; dropping {'train_loss': tensor(0.0898, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 515 < 937; dropping {'train_loss': tensor(0.3028, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 516 < 937; dropping {'train_loss': tensor(0.4880, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 517 < 937; dropping {'train_loss': tensor(0.3079, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 518 < 937; dropping {'train_loss': tensor(0.2503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 519 < 937; dropping {'train_loss': tensor(0.1385, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 520 < 937; dropping {'train_loss': tensor(0.3867, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 521 < 937; dropping {'train_loss': tensor(0.4370, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 522 < 937; dropping {'train_loss': tensor(0.3166, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 523 < 937; dropping {'train_loss': tensor(0.1657, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 524 < 937; dropping {'train_loss': tensor(0.1296, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 525 < 937; dropping {'train_loss': tensor(0.1607, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 526 < 937; dropping {'train_loss': tensor(0.2270, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 527 < 937; dropping {'train_loss': tensor(0.3130, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 528 < 937; dropping {'train_loss': tensor(0.2718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 529 < 937; dropping {'train_loss': tensor(0.3736, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 530 < 937; dropping {'train_loss': tensor(0.3611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 531 < 937; dropping {'train_loss': tensor(0.2691, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 532 < 937; dropping {'train_loss': tensor(0.3954, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 533 < 937; dropping {'train_loss': tensor(0.3856, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 534 < 937; dropping {'train_loss': tensor(0.2318, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 535 < 937; dropping {'train_loss': tensor(0.4554, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 536 < 937; dropping {'train_loss': tensor(0.1671, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 537 < 937; dropping {'train_loss': tensor(0.5331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 538 < 937; dropping {'train_loss': tensor(0.2586, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 539 < 937; dropping {'train_loss': tensor(0.4765, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 540 < 937; dropping {'train_loss': tensor(0.1490, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 541 < 937; dropping {'train_loss': tensor(0.3025, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 542 < 937; dropping {'train_loss': tensor(0.4059, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 543 < 937; dropping {'train_loss': tensor(0.4435, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 544 < 937; dropping {'train_loss': tensor(0.2533, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 545 < 937; dropping {'train_loss': tensor(0.3841, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 546 < 937; dropping {'train_loss': tensor(0.2434, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 547 < 937; dropping {'train_loss': tensor(0.2646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 548 < 937; dropping {'train_loss': tensor(0.1466, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 549 < 937; dropping {'train_loss': tensor(0.3768, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 550 < 937; dropping {'train_loss': tensor(0.2230, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 551 < 937; dropping {'train_loss': tensor(0.3046, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 552 < 937; dropping {'train_loss': tensor(0.3839, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 553 < 937; dropping {'train_loss': tensor(0.2658, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 554 < 937; dropping {'train_loss': tensor(0.2596, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 555 < 937; dropping {'train_loss': tensor(0.3677, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 556 < 937; dropping {'train_loss': tensor(0.3225, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 557 < 937; dropping {'train_loss': tensor(0.3715, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 558 < 937; dropping {'train_loss': tensor(0.3322, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 559 < 937; dropping {'train_loss': tensor(0.2971, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 560 < 937; dropping {'train_loss': tensor(0.4394, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 561 < 937; dropping {'train_loss': tensor(0.3874, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 562 < 937; dropping {'train_loss': tensor(0.1140, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 563 < 937; dropping {'train_loss': tensor(0.2641, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 564 < 937; dropping {'train_loss': tensor(0.5710, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 565 < 937; dropping {'train_loss': tensor(0.4590, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 566 < 937; dropping {'train_loss': tensor(0.2404, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 567 < 937; dropping {'train_loss': tensor(0.3696, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 568 < 937; dropping {'train_loss': tensor(0.4459, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 569 < 937; dropping {'train_loss': tensor(0.3361, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 570 < 937; dropping {'train_loss': tensor(0.2940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 571 < 937; dropping {'train_loss': tensor(0.1988, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 572 < 937; dropping {'train_loss': tensor(0.3059, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 573 < 937; dropping {'train_loss': tensor(0.2294, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 574 < 937; dropping {'train_loss': tensor(0.3615, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 575 < 937; dropping {'train_loss': tensor(0.3437, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 32000/60000             (53% | Loss: 0.571046
wandb: WARNING Step must only increase in log calls.  Step 576 < 937; dropping {'train_loss': tensor(0.1913, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 577 < 937; dropping {'train_loss': tensor(0.3599, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 578 < 937; dropping {'train_loss': tensor(0.1621, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 579 < 937; dropping {'train_loss': tensor(0.3627, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 580 < 937; dropping {'train_loss': tensor(0.3073, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 581 < 937; dropping {'train_loss': tensor(0.3034, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 582 < 937; dropping {'train_loss': tensor(0.2600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 583 < 937; dropping {'train_loss': tensor(0.3280, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 584 < 937; dropping {'train_loss': tensor(0.2047, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 585 < 937; dropping {'train_loss': tensor(0.2758, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 586 < 937; dropping {'train_loss': tensor(0.3261, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 587 < 937; dropping {'train_loss': tensor(0.3337, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 588 < 937; dropping {'train_loss': tensor(0.4249, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 589 < 937; dropping {'train_loss': tensor(0.3457, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 590 < 937; dropping {'train_loss': tensor(0.2244, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 591 < 937; dropping {'train_loss': tensor(0.3629, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 592 < 937; dropping {'train_loss': tensor(0.4426, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 593 < 937; dropping {'train_loss': tensor(0.4750, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 594 < 937; dropping {'train_loss': tensor(0.3296, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 595 < 937; dropping {'train_loss': tensor(0.2316, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 596 < 937; dropping {'train_loss': tensor(0.3290, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 597 < 937; dropping {'train_loss': tensor(0.2205, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 598 < 937; dropping {'train_loss': tensor(0.2904, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 599 < 937; dropping {'train_loss': tensor(0.4655, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 600 < 937; dropping {'train_loss': tensor(0.3590, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 601 < 937; dropping {'train_loss': tensor(0.3137, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 602 < 937; dropping {'train_loss': tensor(0.2382, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 603 < 937; dropping {'train_loss': tensor(0.3319, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 604 < 937; dropping {'train_loss': tensor(0.2408, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 605 < 937; dropping {'train_loss': tensor(0.3039, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 606 < 937; dropping {'train_loss': tensor(0.2977, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 607 < 937; dropping {'train_loss': tensor(0.3671, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 608 < 937; dropping {'train_loss': tensor(0.3379, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 609 < 937; dropping {'train_loss': tensor(0.1842, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 610 < 937; dropping {'train_loss': tensor(0.1903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 611 < 937; dropping {'train_loss': tensor(0.1019, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 612 < 937; dropping {'train_loss': tensor(0.1925, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 613 < 937; dropping {'train_loss': tensor(0.1827, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 614 < 937; dropping {'train_loss': tensor(0.2605, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 615 < 937; dropping {'train_loss': tensor(0.4969, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 616 < 937; dropping {'train_loss': tensor(0.0964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 617 < 937; dropping {'train_loss': tensor(0.2951, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 618 < 937; dropping {'train_loss': tensor(0.2849, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 619 < 937; dropping {'train_loss': tensor(0.2566, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 620 < 937; dropping {'train_loss': tensor(0.4283, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 621 < 937; dropping {'train_loss': tensor(0.2871, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 622 < 937; dropping {'train_loss': tensor(0.1576, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 623 < 937; dropping {'train_loss': tensor(0.3325, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 624 < 937; dropping {'train_loss': tensor(0.2623, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 625 < 937; dropping {'train_loss': tensor(0.3385, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 626 < 937; dropping {'train_loss': tensor(0.2337, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 627 < 937; dropping {'train_loss': tensor(0.2037, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 628 < 937; dropping {'train_loss': tensor(0.1001, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 629 < 937; dropping {'train_loss': tensor(0.1929, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 630 < 937; dropping {'train_loss': tensor(0.2671, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 631 < 937; dropping {'train_loss': tensor(0.0808, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 632 < 937; dropping {'train_loss': tensor(0.1725, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 633 < 937; dropping {'train_loss': tensor(0.1773, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 634 < 937; dropping {'train_loss': tensor(0.3838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 635 < 937; dropping {'train_loss': tensor(0.1526, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 636 < 937; dropping {'train_loss': tensor(0.4425, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 637 < 937; dropping {'train_loss': tensor(0.4249, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 638 < 937; dropping {'train_loss': tensor(0.2983, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 639 < 937; dropping {'train_loss': tensor(0.3467, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 640 < 937; dropping {'train_loss': tensor(0.4358, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 641 < 937; dropping {'train_loss': tensor(0.2695, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 642 < 937; dropping {'train_loss': tensor(0.3980, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 643 < 937; dropping {'train_loss': tensor(0.3017, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 644 < 937; dropping {'train_loss': tensor(0.5331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 645 < 937; dropping {'train_loss': tensor(0.4864, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 646 < 937; dropping {'train_loss': tensor(0.1483, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 647 < 937; dropping {'train_loss': tensor(0.3599, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 648 < 937; dropping {'train_loss': tensor(0.1628, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 649 < 937; dropping {'train_loss': tensor(0.1847, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 650 < 937; dropping {'train_loss': tensor(0.4318, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 38400/60000             (64% | Loss: 0.228997
wandb: WARNING Step must only increase in log calls.  Step 651 < 937; dropping {'train_loss': tensor(0.4164, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 652 < 937; dropping {'train_loss': tensor(0.2570, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 653 < 937; dropping {'train_loss': tensor(0.2513, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 654 < 937; dropping {'train_loss': tensor(0.2375, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 655 < 937; dropping {'train_loss': tensor(0.1466, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 656 < 937; dropping {'train_loss': tensor(0.2907, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 657 < 937; dropping {'train_loss': tensor(0.3911, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 658 < 937; dropping {'train_loss': tensor(0.3992, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 659 < 937; dropping {'train_loss': tensor(0.2912, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 660 < 937; dropping {'train_loss': tensor(0.5007, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 661 < 937; dropping {'train_loss': tensor(0.3986, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 662 < 937; dropping {'train_loss': tensor(0.1837, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 663 < 937; dropping {'train_loss': tensor(0.5180, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 664 < 937; dropping {'train_loss': tensor(0.2290, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 665 < 937; dropping {'train_loss': tensor(0.3153, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 666 < 937; dropping {'train_loss': tensor(0.3078, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 667 < 937; dropping {'train_loss': tensor(0.3546, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 668 < 937; dropping {'train_loss': tensor(0.4282, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 669 < 937; dropping {'train_loss': tensor(0.2381, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 670 < 937; dropping {'train_loss': tensor(0.3316, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 671 < 937; dropping {'train_loss': tensor(0.5131, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 672 < 937; dropping {'train_loss': tensor(0.2204, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 673 < 937; dropping {'train_loss': tensor(0.1899, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 674 < 937; dropping {'train_loss': tensor(0.3416, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 675 < 937; dropping {'train_loss': tensor(0.5221, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 676 < 937; dropping {'train_loss': tensor(0.2495, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 677 < 937; dropping {'train_loss': tensor(0.4567, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 678 < 937; dropping {'train_loss': tensor(0.3283, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 679 < 937; dropping {'train_loss': tensor(0.3303, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 680 < 937; dropping {'train_loss': tensor(0.1362, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 681 < 937; dropping {'train_loss': tensor(0.3085, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 682 < 937; dropping {'train_loss': tensor(0.1871, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 683 < 937; dropping {'train_loss': tensor(0.3180, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 684 < 937; dropping {'train_loss': tensor(0.3724, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 685 < 937; dropping {'train_loss': tensor(0.3101, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 686 < 937; dropping {'train_loss': tensor(0.1528, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 687 < 937; dropping {'train_loss': tensor(0.2642, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 688 < 937; dropping {'train_loss': tensor(0.4903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 689 < 937; dropping {'train_loss': tensor(0.2972, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 690 < 937; dropping {'train_loss': tensor(0.1604, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 691 < 937; dropping {'train_loss': tensor(0.3439, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 692 < 937; dropping {'train_loss': tensor(0.2134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 693 < 937; dropping {'train_loss': tensor(0.2649, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 694 < 937; dropping {'train_loss': tensor(0.3981, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 695 < 937; dropping {'train_loss': tensor(0.1561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 696 < 937; dropping {'train_loss': tensor(0.5586, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 697 < 937; dropping {'train_loss': tensor(0.3130, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 698 < 937; dropping {'train_loss': tensor(0.4892, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 699 < 937; dropping {'train_loss': tensor(0.3654, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 700 < 937; dropping {'train_loss': tensor(0.2619, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 701 < 937; dropping {'train_loss': tensor(0.2334, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 702 < 937; dropping {'train_loss': tensor(0.3245, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 703 < 937; dropping {'train_loss': tensor(0.1509, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 704 < 937; dropping {'train_loss': tensor(0.2611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 705 < 937; dropping {'train_loss': tensor(0.2380, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 706 < 937; dropping {'train_loss': tensor(0.2266, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 707 < 937; dropping {'train_loss': tensor(0.3384, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 708 < 937; dropping {'train_loss': tensor(0.3804, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 709 < 937; dropping {'train_loss': tensor(0.2274, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 710 < 937; dropping {'train_loss': tensor(0.2795, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 711 < 937; dropping {'train_loss': tensor(0.2979, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 712 < 937; dropping {'train_loss': tensor(0.3024, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 713 < 937; dropping {'train_loss': tensor(0.2793, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 714 < 937; dropping {'train_loss': tensor(0.2650, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 715 < 937; dropping {'train_loss': tensor(0.1424, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 716 < 937; dropping {'train_loss': tensor(0.3809, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 717 < 937; dropping {'train_loss': tensor(0.4923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 718 < 937; dropping {'train_loss': tensor(0.2864, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 719 < 937; dropping {'train_loss': tensor(0.2031, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 720 < 937; dropping {'train_loss': tensor(0.1895, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 721 < 937; dropping {'train_loss': tensor(0.1585, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 722 < 937; dropping {'train_loss': tensor(0.3304, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 723 < 937; dropping {'train_loss': tensor(0.2650, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 724 < 937; dropping {'train_loss': tensor(0.3136, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 725 < 937; dropping {'train_loss': tensor(0.4148, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 726 < 937; dropping {'train_loss': tensor(0.2276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 727 < 937; dropping {'train_loss': tensor(0.3122, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 728 < 937; dropping {'train_loss': tensor(0.3409, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 729 < 937; dropping {'train_loss': tensor(0.4636, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 730 < 937; dropping {'train_loss': tensor(0.2290, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 731 < 937; dropping {'train_loss': tensor(0.3787, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 732 < 937; dropping {'train_loss': tensor(0.1682, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 733 < 937; dropping {'train_loss': tensor(0.4494, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 734 < 937; dropping {'train_loss': tensor(0.4769, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 735 < 937; dropping {'train_loss': tensor(0.1179, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 736 < 937; dropping {'train_loss': tensor(0.3666, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 737 < 937; dropping {'train_loss': tensor(0.1689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 738 < 937; dropping {'train_loss': tensor(0.2289, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 739 < 937; dropping {'train_loss': tensor(0.2125, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 740 < 937; dropping {'train_loss': tensor(0.2322, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 741 < 937; dropping {'train_loss': tensor(0.2007, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 742 < 937; dropping {'train_loss': tensor(0.1648, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 743 < 937; dropping {'train_loss': tensor(0.2771, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 744 < 937; dropping {'train_loss': tensor(0.1850, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 745 < 937; dropping {'train_loss': tensor(0.2405, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 746 < 937; dropping {'train_loss': tensor(0.2851, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 747 < 937; dropping {'train_loss': tensor(0.1969, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 748 < 937; dropping {'train_loss': tensor(0.1272, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 749 < 937; dropping {'train_loss': tensor(0.3971, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 750 < 937; dropping {'train_loss': tensor(0.1083, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 751 < 937; dropping {'train_loss': tensor(0.3676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 752 < 937; dropping {'train_loss': tensor(0.3166, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 753 < 937; dropping {'train_loss': tensor(0.2892, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 754 < 937; dropping {'train_loss': tensor(0.1919, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 755 < 937; dropping {'train_loss': tensor(0.1659, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 756 < 937; dropping {'train_loss': tensor(0.3092, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 757 < 937; dropping {'train_loss': tensor(0.3856, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 758 < 937; dropping {'train_loss': tensor(0.1864, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 759 < 937; dropping {'train_loss': tensor(0.3101, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 760 < 937; dropping {'train_loss': tensor(0.3038, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 761 < 937; dropping {'train_loss': tensor(0.3027, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 762 < 937; dropping {'train_loss': tensor(0.2233, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 763 < 937; dropping {'train_loss': tensor(0.1964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 764 < 937; dropping {'train_loss': tensor(0.4084, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 765 < 937; dropping {'train_loss': tensor(0.3781, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 766 < 937; dropping {'train_loss': tensor(0.1974, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 767 < 937; dropping {'train_loss': tensor(0.1955, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 768 < 937; dropping {'train_loss': tensor(0.1850, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 769 < 937; dropping {'train_loss': tensor(0.3392, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 770 < 937; dropping {'train_loss': tensor(0.2574, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 771 < 937; dropping {'train_loss': tensor(0.1504, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 772 < 937; dropping {'train_loss': tensor(0.2476, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 773 < 937; dropping {'train_loss': tensor(0.3517, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 774 < 937; dropping {'train_loss': tensor(0.3036, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 775 < 937; dropping {'train_loss': tensor(0.2933, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 776 < 937; dropping {'train_loss': tensor(0.3273, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 777 < 937; dropping {'train_loss': tensor(0.1983, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 44800/60000             (75% | Loss: 0.408432
wandb: WARNING Step must only increase in log calls.  Step 778 < 937; dropping {'train_loss': tensor(0.2596, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 779 < 937; dropping {'train_loss': tensor(0.1841, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 780 < 937; dropping {'train_loss': tensor(0.2378, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 781 < 937; dropping {'train_loss': tensor(0.1794, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 782 < 937; dropping {'train_loss': tensor(0.2278, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 783 < 937; dropping {'train_loss': tensor(0.4440, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 784 < 937; dropping {'train_loss': tensor(0.4082, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 785 < 937; dropping {'train_loss': tensor(0.1635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 786 < 937; dropping {'train_loss': tensor(0.3532, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 787 < 937; dropping {'train_loss': tensor(0.1877, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 788 < 937; dropping {'train_loss': tensor(0.4125, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 789 < 937; dropping {'train_loss': tensor(0.5026, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 790 < 937; dropping {'train_loss': tensor(0.4173, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 791 < 937; dropping {'train_loss': tensor(0.2833, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 792 < 937; dropping {'train_loss': tensor(0.2450, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 793 < 937; dropping {'train_loss': tensor(0.3000, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 794 < 937; dropping {'train_loss': tensor(0.1492, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 795 < 937; dropping {'train_loss': tensor(0.3539, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 796 < 937; dropping {'train_loss': tensor(0.2979, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 797 < 937; dropping {'train_loss': tensor(0.2696, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 798 < 937; dropping {'train_loss': tensor(0.3685, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 799 < 937; dropping {'train_loss': tensor(0.1591, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 800 < 937; dropping {'train_loss': tensor(0.2538, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 801 < 937; dropping {'train_loss': tensor(0.1821, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 802 < 937; dropping {'train_loss': tensor(0.3426, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 803 < 937; dropping {'train_loss': tensor(0.2641, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 804 < 937; dropping {'train_loss': tensor(0.2926, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 805 < 937; dropping {'train_loss': tensor(0.2234, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 806 < 937; dropping {'train_loss': tensor(0.1929, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 807 < 937; dropping {'train_loss': tensor(0.3726, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 808 < 937; dropping {'train_loss': tensor(0.3806, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 809 < 937; dropping {'train_loss': tensor(0.3870, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 810 < 937; dropping {'train_loss': tensor(0.1271, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 811 < 937; dropping {'train_loss': tensor(0.2851, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 812 < 937; dropping {'train_loss': tensor(0.5272, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 813 < 937; dropping {'train_loss': tensor(0.2284, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 814 < 937; dropping {'train_loss': tensor(0.2607, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 815 < 937; dropping {'train_loss': tensor(0.1523, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 816 < 937; dropping {'train_loss': tensor(0.2701, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 817 < 937; dropping {'train_loss': tensor(0.2742, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 818 < 937; dropping {'train_loss': tensor(0.3377, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 819 < 937; dropping {'train_loss': tensor(0.3050, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 820 < 937; dropping {'train_loss': tensor(0.3020, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 821 < 937; dropping {'train_loss': tensor(0.4043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 822 < 937; dropping {'train_loss': tensor(0.1672, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 823 < 937; dropping {'train_loss': tensor(0.3689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 824 < 937; dropping {'train_loss': tensor(0.3803, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 825 < 937; dropping {'train_loss': tensor(0.3941, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 826 < 937; dropping {'train_loss': tensor(0.3298, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 827 < 937; dropping {'train_loss': tensor(0.3396, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 828 < 937; dropping {'train_loss': tensor(0.3064, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 829 < 937; dropping {'train_loss': tensor(0.3288, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 830 < 937; dropping {'train_loss': tensor(0.2492, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 831 < 937; dropping {'train_loss': tensor(0.2702, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 832 < 937; dropping {'train_loss': tensor(0.2199, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 833 < 937; dropping {'train_loss': tensor(0.3704, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 834 < 937; dropping {'train_loss': tensor(0.3298, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 835 < 937; dropping {'train_loss': tensor(0.2281, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 836 < 937; dropping {'train_loss': tensor(0.4392, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 837 < 937; dropping {'train_loss': tensor(0.3617, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 838 < 937; dropping {'train_loss': tensor(0.2673, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 839 < 937; dropping {'train_loss': tensor(0.2319, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 840 < 937; dropping {'train_loss': tensor(0.1530, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 841 < 937; dropping {'train_loss': tensor(0.2810, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 842 < 937; dropping {'train_loss': tensor(0.2241, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 51200/60000             (85% | Loss: 0.212495
wandb: WARNING Step must only increase in log calls.  Step 843 < 937; dropping {'train_loss': tensor(0.2016, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 844 < 937; dropping {'train_loss': tensor(0.2350, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 845 < 937; dropping {'train_loss': tensor(0.4057, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 846 < 937; dropping {'train_loss': tensor(0.4396, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 847 < 937; dropping {'train_loss': tensor(0.2313, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 848 < 937; dropping {'train_loss': tensor(0.1913, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 849 < 937; dropping {'train_loss': tensor(0.2227, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 850 < 937; dropping {'train_loss': tensor(0.3304, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 851 < 937; dropping {'train_loss': tensor(0.3691, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 852 < 937; dropping {'train_loss': tensor(0.1247, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 853 < 937; dropping {'train_loss': tensor(0.3762, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 854 < 937; dropping {'train_loss': tensor(0.0509, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 855 < 937; dropping {'train_loss': tensor(0.3432, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 856 < 937; dropping {'train_loss': tensor(0.2606, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 857 < 937; dropping {'train_loss': tensor(0.2102, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 858 < 937; dropping {'train_loss': tensor(0.2926, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 859 < 937; dropping {'train_loss': tensor(0.3103, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 860 < 937; dropping {'train_loss': tensor(0.2126, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 861 < 937; dropping {'train_loss': tensor(0.3090, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 862 < 937; dropping {'train_loss': tensor(0.2616, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 863 < 937; dropping {'train_loss': tensor(0.2807, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 864 < 937; dropping {'train_loss': tensor(0.2125, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 865 < 937; dropping {'train_loss': tensor(0.3056, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 866 < 937; dropping {'train_loss': tensor(0.4771, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 867 < 937; dropping {'train_loss': tensor(0.2246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 868 < 937; dropping {'train_loss': tensor(0.3758, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 869 < 937; dropping {'train_loss': tensor(0.3023, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 870 < 937; dropping {'train_loss': tensor(0.4919, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 871 < 937; dropping {'train_loss': tensor(0.3439, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 872 < 937; dropping {'train_loss': tensor(0.2719, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 873 < 937; dropping {'train_loss': tensor(0.4826, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 874 < 937; dropping {'train_loss': tensor(0.1928, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 875 < 937; dropping {'train_loss': tensor(0.2957, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 876 < 937; dropping {'train_loss': tensor(0.6956, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 877 < 937; dropping {'train_loss': tensor(0.1935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 878 < 937; dropping {'train_loss': tensor(0.4345, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 879 < 937; dropping {'train_loss': tensor(0.2975, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 880 < 937; dropping {'train_loss': tensor(0.3028, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 881 < 937; dropping {'train_loss': tensor(0.4234, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 882 < 937; dropping {'train_loss': tensor(0.3687, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 883 < 937; dropping {'train_loss': tensor(0.5761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 884 < 937; dropping {'train_loss': tensor(0.3619, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 885 < 937; dropping {'train_loss': tensor(0.3797, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 886 < 937; dropping {'train_loss': tensor(0.2903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 887 < 937; dropping {'train_loss': tensor(0.3151, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 888 < 937; dropping {'train_loss': tensor(0.1515, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 889 < 937; dropping {'train_loss': tensor(0.2669, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 890 < 937; dropping {'train_loss': tensor(0.3602, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 891 < 937; dropping {'train_loss': tensor(0.2008, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 892 < 937; dropping {'train_loss': tensor(0.1933, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 893 < 937; dropping {'train_loss': tensor(0.2333, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 894 < 937; dropping {'train_loss': tensor(0.5618, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 895 < 937; dropping {'train_loss': tensor(0.5709, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 896 < 937; dropping {'train_loss': tensor(0.2985, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 897 < 937; dropping {'train_loss': tensor(0.1982, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 898 < 937; dropping {'train_loss': tensor(0.1959, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 899 < 937; dropping {'train_loss': tensor(0.2388, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 900 < 937; dropping {'train_loss': tensor(0.2894, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 901 < 937; dropping {'train_loss': tensor(0.2369, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 902 < 937; dropping {'train_loss': tensor(0.2578, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 903 < 937; dropping {'train_loss': tensor(0.3593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 904 < 937; dropping {'train_loss': tensor(0.4905, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 905 < 937; dropping {'train_loss': tensor(0.3004, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 906 < 937; dropping {'train_loss': tensor(0.3308, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 907 < 937; dropping {'train_loss': tensor(0.2715, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 908 < 937; dropping {'train_loss': tensor(0.1678, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 909 < 937; dropping {'train_loss': tensor(0.1786, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 910 < 937; dropping {'train_loss': tensor(0.2420, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 911 < 937; dropping {'train_loss': tensor(0.5499, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 912 < 937; dropping {'train_loss': tensor(0.4123, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 913 < 937; dropping {'train_loss': tensor(0.1118, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 914 < 937; dropping {'train_loss': tensor(0.1506, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 915 < 937; dropping {'train_loss': tensor(0.0595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 916 < 937; dropping {'train_loss': tensor(0.3446, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 917 < 937; dropping {'train_loss': tensor(0.2984, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 918 < 937; dropping {'train_loss': tensor(0.2724, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 919 < 937; dropping {'train_loss': tensor(0.2901, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 920 < 937; dropping {'train_loss': tensor(0.2590, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 921 < 937; dropping {'train_loss': tensor(0.2153, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 922 < 937; dropping {'train_loss': tensor(0.4275, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 923 < 937; dropping {'train_loss': tensor(0.2327, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 924 < 937; dropping {'train_loss': tensor(0.3419, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 925 < 937; dropping {'train_loss': tensor(0.2719, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 926 < 937; dropping {'train_loss': tensor(0.3296, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 927 < 937; dropping {'train_loss': tensor(0.2768, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 928 < 937; dropping {'train_loss': tensor(0.2644, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 929 < 937; dropping {'train_loss': tensor(0.4069, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 930 < 937; dropping {'train_loss': tensor(0.4803, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 931 < 937; dropping {'train_loss': tensor(0.2448, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 932 < 937; dropping {'train_loss': tensor(0.2992, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 933 < 937; dropping {'train_loss': tensor(0.2590, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 934 < 937; dropping {'train_loss': tensor(0.2166, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 935 < 937; dropping {'train_loss': tensor(0.3627, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 936 < 937; dropping {'train_loss': tensor(0.3347, grad_fn=<NllLossBackward0>)}.
Train Epoch: 2 | Batch Status: 57600/60000             (96% | Loss: 0.290551
wandb: WARNING Step must only increase in log calls.  Step 64 < 1001; dropping {'val_loss': tensor(0.3289, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 65 < 1001; dropping {'val_loss': tensor(0.4008, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 66 < 1001; dropping {'val_loss': tensor(0.3638, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 67 < 1001; dropping {'val_loss': tensor(0.3713, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 68 < 1001; dropping {'val_loss': tensor(0.1115, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 69 < 1001; dropping {'val_loss': tensor(0.1429, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 70 < 1001; dropping {'val_loss': tensor(0.5212, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 71 < 1001; dropping {'val_loss': tensor(0.3248, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 72 < 1001; dropping {'val_loss': tensor(0.3062, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 73 < 1001; dropping {'val_loss': tensor(0.2730, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 74 < 1001; dropping {'val_loss': tensor(0.4553, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 75 < 1001; dropping {'val_loss': tensor(0.3944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 76 < 1001; dropping {'val_loss': tensor(0.4004, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 77 < 1001; dropping {'val_loss': tensor(0.3437, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 78 < 1001; dropping {'val_loss': tensor(0.2471, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 79 < 1001; dropping {'val_loss': tensor(0.2844, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 80 < 1001; dropping {'val_loss': tensor(0.2803, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 81 < 1001; dropping {'val_loss': tensor(0.2020, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 82 < 1001; dropping {'val_loss': tensor(0.3867, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 83 < 1001; dropping {'val_loss': tensor(0.6110, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 84 < 1001; dropping {'val_loss': tensor(0.4870, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 85 < 1001; dropping {'val_loss': tensor(0.3295, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 86 < 1001; dropping {'val_loss': tensor(0.2961, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 87 < 1001; dropping {'val_loss': tensor(0.3371, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 88 < 1001; dropping {'val_loss': tensor(0.2048, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 89 < 1001; dropping {'val_loss': tensor(0.3111, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 90 < 1001; dropping {'val_loss': tensor(0.4027, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 91 < 1001; dropping {'val_loss': tensor(0.4626, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 92 < 1001; dropping {'val_loss': tensor(0.3278, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 93 < 1001; dropping {'val_loss': tensor(0.2676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 94 < 1001; dropping {'val_loss': tensor(0.3915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 95 < 1001; dropping {'val_loss': tensor(0.2299, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 96 < 1001; dropping {'val_loss': tensor(0.4560, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 97 < 1001; dropping {'val_loss': tensor(0.4549, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 98 < 1001; dropping {'val_loss': tensor(0.1490, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 99 < 1001; dropping {'val_loss': tensor(0.3773, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 100 < 1001; dropping {'val_loss': tensor(0.3081, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 101 < 1001; dropping {'val_loss': tensor(0.3651, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 102 < 1001; dropping {'val_loss': tensor(0.4294, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 103 < 1001; dropping {'val_loss': tensor(0.4149, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 104 < 1001; dropping {'val_loss': tensor(0.3688, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 105 < 1001; dropping {'val_loss': tensor(0.2739, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 106 < 1001; dropping {'val_loss': tensor(0.4578, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 107 < 1001; dropping {'val_loss': tensor(0.3036, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 108 < 1001; dropping {'val_loss': tensor(0.3569, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 109 < 1001; dropping {'val_loss': tensor(0.3038, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 110 < 1001; dropping {'val_loss': tensor(0.3986, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 111 < 1001; dropping {'val_loss': tensor(0.1900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 112 < 1001; dropping {'val_loss': tensor(0.2219, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 113 < 1001; dropping {'val_loss': tensor(0.1312, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 114 < 1001; dropping {'val_loss': tensor(0.4721, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 115 < 1001; dropping {'val_loss': tensor(0.1600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 116 < 1001; dropping {'val_loss': tensor(0.1169, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 117 < 1001; dropping {'val_loss': tensor(0.4529, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 118 < 1001; dropping {'val_loss': tensor(0.2219, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 119 < 1001; dropping {'val_loss': tensor(0.1523, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 120 < 1001; dropping {'val_loss': tensor(0.2600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 121 < 1001; dropping {'val_loss': tensor(0.4306, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 122 < 1001; dropping {'val_loss': tensor(0.2222, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 123 < 1001; dropping {'val_loss': tensor(0.4716, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 124 < 1001; dropping {'val_loss': tensor(0.3309, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 125 < 1001; dropping {'val_loss': tensor(0.1638, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 126 < 1001; dropping {'val_loss': tensor(0.3148, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 127 < 1001; dropping {'val_loss': tensor(0.1697, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 128 < 1001; dropping {'val_loss': tensor(0.2950, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 129 < 1001; dropping {'val_loss': tensor(0.2625, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 130 < 1001; dropping {'val_loss': tensor(0.2622, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 131 < 1001; dropping {'val_loss': tensor(0.2725, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 132 < 1001; dropping {'val_loss': tensor(0.2673, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 133 < 1001; dropping {'val_loss': tensor(0.2083, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 134 < 1001; dropping {'val_loss': tensor(0.4254, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 135 < 1001; dropping {'val_loss': tensor(0.3651, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 136 < 1001; dropping {'val_loss': tensor(0.3479, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 137 < 1001; dropping {'val_loss': tensor(0.1292, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 138 < 1001; dropping {'val_loss': tensor(0.4595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 139 < 1001; dropping {'val_loss': tensor(0.3374, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 140 < 1001; dropping {'val_loss': tensor(0.2940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 141 < 1001; dropping {'val_loss': tensor(0.3646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 142 < 1001; dropping {'val_loss': tensor(0.3785, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 143 < 1001; dropping {'val_loss': tensor(0.2061, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 144 < 1001; dropping {'val_loss': tensor(0.3619, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 145 < 1001; dropping {'val_loss': tensor(0.2600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 146 < 1001; dropping {'val_loss': tensor(0.2274, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 147 < 1001; dropping {'val_loss': tensor(0.1137, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 148 < 1001; dropping {'val_loss': tensor(0.2924, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 149 < 1001; dropping {'val_loss': tensor(0.0918, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 150 < 1001; dropping {'val_loss': tensor(0.1911, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 151 < 1001; dropping {'val_loss': tensor(0.2247, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 152 < 1001; dropping {'val_loss': tensor(0.2108, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 153 < 1001; dropping {'val_loss': tensor(0.1573, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 154 < 1001; dropping {'val_loss': tensor(0.2503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 155 < 1001; dropping {'val_loss': tensor(0.4058, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 156 < 1001; dropping {'val_loss': tensor(0.0887, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 157 < 1001; dropping {'val_loss': tensor(0.0889, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 158 < 1001; dropping {'val_loss': tensor(0.2685, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 159 < 1001; dropping {'val_loss': tensor(0.1848, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 160 < 1001; dropping {'val_loss': tensor(0.3152, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 161 < 1001; dropping {'val_loss': tensor(0.2619, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 162 < 1001; dropping {'val_loss': tensor(0.2147, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 163 < 1001; dropping {'val_loss': tensor(0.1890, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 164 < 1001; dropping {'val_loss': tensor(0.3635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 165 < 1001; dropping {'val_loss': tensor(0.2407, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 166 < 1001; dropping {'val_loss': tensor(0.3681, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 167 < 1001; dropping {'val_loss': tensor(0.1315, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 168 < 1001; dropping {'val_loss': tensor(0.3532, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 169 < 1001; dropping {'val_loss': tensor(0.3821, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 170 < 1001; dropping {'val_loss': tensor(0.3044, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 171 < 1001; dropping {'val_loss': tensor(0.2544, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 172 < 1001; dropping {'val_loss': tensor(0.3057, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 173 < 1001; dropping {'val_loss': tensor(0.4286, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 174 < 1001; dropping {'val_loss': tensor(0.2560, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 175 < 1001; dropping {'val_loss': tensor(0.3446, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 176 < 1001; dropping {'val_loss': tensor(0.0535, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 177 < 1001; dropping {'val_loss': tensor(0.1167, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 178 < 1001; dropping {'val_loss': tensor(0.4191, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 179 < 1001; dropping {'val_loss': tensor(0.2624, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 180 < 1001; dropping {'val_loss': tensor(0.2959, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 181 < 1001; dropping {'val_loss': tensor(0.1513, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 182 < 1001; dropping {'val_loss': tensor(0.3312, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 183 < 1001; dropping {'val_loss': tensor(0.4877, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 184 < 1001; dropping {'val_loss': tensor(0.2141, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 185 < 1001; dropping {'val_loss': tensor(0.1161, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 186 < 1001; dropping {'val_loss': tensor(0.5944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 187 < 1001; dropping {'val_loss': tensor(0.2941, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 188 < 1001; dropping {'val_loss': tensor(0.3275, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 189 < 1001; dropping {'val_loss': tensor(0.2382, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 190 < 1001; dropping {'val_loss': tensor(0.2246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 191 < 1001; dropping {'val_loss': tensor(0.2959, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 192 < 1001; dropping {'val_loss': tensor(0.3255, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 193 < 1001; dropping {'val_loss': tensor(0.2197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 194 < 1001; dropping {'val_loss': tensor(0.2201, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 195 < 1001; dropping {'val_loss': tensor(0.2365, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 196 < 1001; dropping {'val_loss': tensor(0.4121, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 197 < 1001; dropping {'val_loss': tensor(0.3319, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 198 < 1001; dropping {'val_loss': tensor(0.2005, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 199 < 1001; dropping {'val_loss': tensor(0.2744, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 200 < 1001; dropping {'val_loss': tensor(0.2210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 201 < 1001; dropping {'val_loss': tensor(0.1911, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 202 < 1001; dropping {'val_loss': tensor(0.1325, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 203 < 1001; dropping {'val_loss': tensor(0.2849, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 204 < 1001; dropping {'val_loss': tensor(0.3648, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 205 < 1001; dropping {'val_loss': tensor(0.2265, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 206 < 1001; dropping {'val_loss': tensor(0.3766, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 207 < 1001; dropping {'val_loss': tensor(0.3558, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 208 < 1001; dropping {'val_loss': tensor(0.2595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 209 < 1001; dropping {'val_loss': tensor(0.3790, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 210 < 1001; dropping {'val_loss': tensor(0.2606, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 211 < 1001; dropping {'val_loss': tensor(0.3064, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 212 < 1001; dropping {'val_loss': tensor(0.3328, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 213 < 1001; dropping {'val_loss': tensor(0.4346, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 214 < 1001; dropping {'val_loss': tensor(0.5632, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 215 < 1001; dropping {'val_loss': tensor(0.3910, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 216 < 1001; dropping {'val_loss': tensor(0.3437, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 217 < 1001; dropping {'val_loss': tensor(0.5070, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 218 < 1001; dropping {'val_loss': tensor(0.1589, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 219 < 1001; dropping {'val_loss': tensor(0.3051, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 220 < 1001; dropping {'val_loss': tensor(0.1715, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 128 < 1001; dropping {'train_loss': tensor(0.1976, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 129 < 1001; dropping {'train_loss': tensor(0.2401, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 0/60000             (0% | Loss: 0.197570
wandb: WARNING Step must only increase in log calls.  Step 130 < 1001; dropping {'train_loss': tensor(0.2262, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 131 < 1001; dropping {'train_loss': tensor(0.2612, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 132 < 1001; dropping {'train_loss': tensor(0.2967, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 133 < 1001; dropping {'train_loss': tensor(0.2978, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 134 < 1001; dropping {'train_loss': tensor(0.3076, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 135 < 1001; dropping {'train_loss': tensor(0.1251, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 136 < 1001; dropping {'train_loss': tensor(0.2519, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 137 < 1001; dropping {'train_loss': tensor(0.2382, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 138 < 1001; dropping {'train_loss': tensor(0.5423, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 139 < 1001; dropping {'train_loss': tensor(0.0661, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 140 < 1001; dropping {'train_loss': tensor(0.5044, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 141 < 1001; dropping {'train_loss': tensor(0.3066, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 142 < 1001; dropping {'train_loss': tensor(0.1983, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 143 < 1001; dropping {'train_loss': tensor(0.3399, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 144 < 1001; dropping {'train_loss': tensor(0.3328, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 145 < 1001; dropping {'train_loss': tensor(0.5210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 146 < 1001; dropping {'train_loss': tensor(0.1865, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 147 < 1001; dropping {'train_loss': tensor(0.2387, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 148 < 1001; dropping {'train_loss': tensor(0.3600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 149 < 1001; dropping {'train_loss': tensor(0.4358, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 150 < 1001; dropping {'train_loss': tensor(0.2625, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 151 < 1001; dropping {'train_loss': tensor(0.1611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 152 < 1001; dropping {'train_loss': tensor(0.2985, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 153 < 1001; dropping {'train_loss': tensor(0.2646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 154 < 1001; dropping {'train_loss': tensor(0.3443, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 155 < 1001; dropping {'train_loss': tensor(0.1963, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 156 < 1001; dropping {'train_loss': tensor(0.3656, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 157 < 1001; dropping {'train_loss': tensor(0.3638, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 158 < 1001; dropping {'train_loss': tensor(0.4901, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 159 < 1001; dropping {'train_loss': tensor(0.2921, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 160 < 1001; dropping {'train_loss': tensor(0.2588, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 161 < 1001; dropping {'train_loss': tensor(0.2291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 162 < 1001; dropping {'train_loss': tensor(0.3129, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 163 < 1001; dropping {'train_loss': tensor(0.3525, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 164 < 1001; dropping {'train_loss': tensor(0.3675, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 165 < 1001; dropping {'train_loss': tensor(0.3647, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 166 < 1001; dropping {'train_loss': tensor(0.2151, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 167 < 1001; dropping {'train_loss': tensor(0.1555, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 168 < 1001; dropping {'train_loss': tensor(0.5936, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 169 < 1001; dropping {'train_loss': tensor(0.3361, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 170 < 1001; dropping {'train_loss': tensor(0.2474, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 171 < 1001; dropping {'train_loss': tensor(0.2749, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 172 < 1001; dropping {'train_loss': tensor(0.1948, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 173 < 1001; dropping {'train_loss': tensor(0.4530, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 174 < 1001; dropping {'train_loss': tensor(0.3322, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 175 < 1001; dropping {'train_loss': tensor(0.3316, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 176 < 1001; dropping {'train_loss': tensor(0.3311, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 177 < 1001; dropping {'train_loss': tensor(0.1499, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 178 < 1001; dropping {'train_loss': tensor(0.1903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 179 < 1001; dropping {'train_loss': tensor(0.2912, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 180 < 1001; dropping {'train_loss': tensor(0.4354, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 181 < 1001; dropping {'train_loss': tensor(0.4390, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 182 < 1001; dropping {'train_loss': tensor(0.2247, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 183 < 1001; dropping {'train_loss': tensor(0.1878, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 184 < 1001; dropping {'train_loss': tensor(0.4091, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 185 < 1001; dropping {'train_loss': tensor(0.3140, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 186 < 1001; dropping {'train_loss': tensor(0.1833, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 187 < 1001; dropping {'train_loss': tensor(0.2454, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 188 < 1001; dropping {'train_loss': tensor(0.5158, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 189 < 1001; dropping {'train_loss': tensor(0.2657, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 190 < 1001; dropping {'train_loss': tensor(0.1970, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 191 < 1001; dropping {'train_loss': tensor(0.1940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 192 < 1001; dropping {'train_loss': tensor(0.1153, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 193 < 1001; dropping {'train_loss': tensor(0.1594, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 194 < 1001; dropping {'train_loss': tensor(0.2692, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 195 < 1001; dropping {'train_loss': tensor(0.2279, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 196 < 1001; dropping {'train_loss': tensor(0.5882, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 197 < 1001; dropping {'train_loss': tensor(0.2717, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 198 < 1001; dropping {'train_loss': tensor(0.3079, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 199 < 1001; dropping {'train_loss': tensor(0.3325, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 200 < 1001; dropping {'train_loss': tensor(0.3392, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 201 < 1001; dropping {'train_loss': tensor(0.2505, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 202 < 1001; dropping {'train_loss': tensor(0.4305, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 203 < 1001; dropping {'train_loss': tensor(0.1200, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 204 < 1001; dropping {'train_loss': tensor(0.2851, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 205 < 1001; dropping {'train_loss': tensor(0.4438, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 206 < 1001; dropping {'train_loss': tensor(0.4755, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 207 < 1001; dropping {'train_loss': tensor(0.3081, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 208 < 1001; dropping {'train_loss': tensor(0.3156, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 209 < 1001; dropping {'train_loss': tensor(0.3535, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 210 < 1001; dropping {'train_loss': tensor(0.0531, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 211 < 1001; dropping {'train_loss': tensor(0.3083, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 212 < 1001; dropping {'train_loss': tensor(0.4291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 213 < 1001; dropping {'train_loss': tensor(0.3531, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 214 < 1001; dropping {'train_loss': tensor(0.3587, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 215 < 1001; dropping {'train_loss': tensor(0.1523, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 216 < 1001; dropping {'train_loss': tensor(0.3617, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 217 < 1001; dropping {'train_loss': tensor(0.2923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 218 < 1001; dropping {'train_loss': tensor(0.3053, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 219 < 1001; dropping {'train_loss': tensor(0.3043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 220 < 1001; dropping {'train_loss': tensor(0.2538, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 221 < 1001; dropping {'train_loss': tensor(0.2197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 222 < 1001; dropping {'train_loss': tensor(0.2950, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 223 < 1001; dropping {'train_loss': tensor(0.2292, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 224 < 1001; dropping {'train_loss': tensor(0.3507, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 225 < 1001; dropping {'train_loss': tensor(0.1729, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 226 < 1001; dropping {'train_loss': tensor(0.1144, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 227 < 1001; dropping {'train_loss': tensor(0.2167, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 228 < 1001; dropping {'train_loss': tensor(0.3676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 229 < 1001; dropping {'train_loss': tensor(0.5262, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 230 < 1001; dropping {'train_loss': tensor(0.2231, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 231 < 1001; dropping {'train_loss': tensor(0.2215, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 232 < 1001; dropping {'train_loss': tensor(0.4881, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 233 < 1001; dropping {'train_loss': tensor(0.3366, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 234 < 1001; dropping {'train_loss': tensor(0.3007, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 235 < 1001; dropping {'train_loss': tensor(0.2888, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 236 < 1001; dropping {'train_loss': tensor(0.4080, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 237 < 1001; dropping {'train_loss': tensor(0.4387, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 238 < 1001; dropping {'train_loss': tensor(0.1394, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 239 < 1001; dropping {'train_loss': tensor(0.3915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 240 < 1001; dropping {'train_loss': tensor(0.3876, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 241 < 1001; dropping {'train_loss': tensor(0.3649, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 242 < 1001; dropping {'train_loss': tensor(0.2880, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 243 < 1001; dropping {'train_loss': tensor(0.3001, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 244 < 1001; dropping {'train_loss': tensor(0.2795, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 245 < 1001; dropping {'train_loss': tensor(0.1963, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 246 < 1001; dropping {'train_loss': tensor(0.2919, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 247 < 1001; dropping {'train_loss': tensor(0.4595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 248 < 1001; dropping {'train_loss': tensor(0.3395, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 249 < 1001; dropping {'train_loss': tensor(0.2917, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 250 < 1001; dropping {'train_loss': tensor(0.1571, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 251 < 1001; dropping {'train_loss': tensor(0.2993, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 252 < 1001; dropping {'train_loss': tensor(0.2893, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 253 < 1001; dropping {'train_loss': tensor(0.2369, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 254 < 1001; dropping {'train_loss': tensor(0.3468, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 255 < 1001; dropping {'train_loss': tensor(0.2949, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 256 < 1001; dropping {'train_loss': tensor(0.1579, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 257 < 1001; dropping {'train_loss': tensor(0.2647, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 6400/60000             (11% | Loss: 0.367580
wandb: WARNING Step must only increase in log calls.  Step 258 < 1001; dropping {'train_loss': tensor(0.3338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 259 < 1001; dropping {'train_loss': tensor(0.2806, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 260 < 1001; dropping {'train_loss': tensor(0.2485, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 261 < 1001; dropping {'train_loss': tensor(0.1218, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 262 < 1001; dropping {'train_loss': tensor(0.3972, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 263 < 1001; dropping {'train_loss': tensor(0.4056, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 264 < 1001; dropping {'train_loss': tensor(0.3141, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 265 < 1001; dropping {'train_loss': tensor(0.1840, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 266 < 1001; dropping {'train_loss': tensor(0.3184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 267 < 1001; dropping {'train_loss': tensor(0.2901, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 268 < 1001; dropping {'train_loss': tensor(0.2306, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 269 < 1001; dropping {'train_loss': tensor(0.3167, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 270 < 1001; dropping {'train_loss': tensor(0.2695, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 271 < 1001; dropping {'train_loss': tensor(0.4094, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 272 < 1001; dropping {'train_loss': tensor(0.4555, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 273 < 1001; dropping {'train_loss': tensor(0.2163, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 274 < 1001; dropping {'train_loss': tensor(0.3556, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 275 < 1001; dropping {'train_loss': tensor(0.2481, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 276 < 1001; dropping {'train_loss': tensor(0.3072, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 277 < 1001; dropping {'train_loss': tensor(0.4964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 278 < 1001; dropping {'train_loss': tensor(0.2245, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 279 < 1001; dropping {'train_loss': tensor(0.1897, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 280 < 1001; dropping {'train_loss': tensor(0.2650, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 281 < 1001; dropping {'train_loss': tensor(0.2745, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 282 < 1001; dropping {'train_loss': tensor(0.2611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 283 < 1001; dropping {'train_loss': tensor(0.2981, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 284 < 1001; dropping {'train_loss': tensor(0.2396, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 285 < 1001; dropping {'train_loss': tensor(0.3515, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 286 < 1001; dropping {'train_loss': tensor(0.3089, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 287 < 1001; dropping {'train_loss': tensor(0.2923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 288 < 1001; dropping {'train_loss': tensor(0.3663, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 289 < 1001; dropping {'train_loss': tensor(0.2915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 290 < 1001; dropping {'train_loss': tensor(0.3276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 291 < 1001; dropping {'train_loss': tensor(0.2817, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 292 < 1001; dropping {'train_loss': tensor(0.0491, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 293 < 1001; dropping {'train_loss': tensor(0.3884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 294 < 1001; dropping {'train_loss': tensor(0.3855, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 295 < 1001; dropping {'train_loss': tensor(0.3385, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 296 < 1001; dropping {'train_loss': tensor(0.3140, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 297 < 1001; dropping {'train_loss': tensor(0.2368, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 298 < 1001; dropping {'train_loss': tensor(0.1168, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 299 < 1001; dropping {'train_loss': tensor(0.2734, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 300 < 1001; dropping {'train_loss': tensor(0.1955, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 301 < 1001; dropping {'train_loss': tensor(0.3633, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 302 < 1001; dropping {'train_loss': tensor(0.3746, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 303 < 1001; dropping {'train_loss': tensor(0.1949, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 304 < 1001; dropping {'train_loss': tensor(0.2913, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 305 < 1001; dropping {'train_loss': tensor(0.3338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 306 < 1001; dropping {'train_loss': tensor(0.3709, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 307 < 1001; dropping {'train_loss': tensor(0.4524, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 308 < 1001; dropping {'train_loss': tensor(0.2205, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 309 < 1001; dropping {'train_loss': tensor(0.2305, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 310 < 1001; dropping {'train_loss': tensor(0.4257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 311 < 1001; dropping {'train_loss': tensor(0.2121, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 312 < 1001; dropping {'train_loss': tensor(0.2091, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 313 < 1001; dropping {'train_loss': tensor(0.2622, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 314 < 1001; dropping {'train_loss': tensor(0.3160, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 315 < 1001; dropping {'train_loss': tensor(0.4080, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 316 < 1001; dropping {'train_loss': tensor(0.4593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 317 < 1001; dropping {'train_loss': tensor(0.3737, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 318 < 1001; dropping {'train_loss': tensor(0.5935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 319 < 1001; dropping {'train_loss': tensor(0.4047, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 320 < 1001; dropping {'train_loss': tensor(0.2043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 321 < 1001; dropping {'train_loss': tensor(0.4662, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 322 < 1001; dropping {'train_loss': tensor(0.3181, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 12800/60000             (21% | Loss: 0.296070
wandb: WARNING Step must only increase in log calls.  Step 323 < 1001; dropping {'train_loss': tensor(0.2210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 324 < 1001; dropping {'train_loss': tensor(0.2754, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 325 < 1001; dropping {'train_loss': tensor(0.3263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 326 < 1001; dropping {'train_loss': tensor(0.4029, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 327 < 1001; dropping {'train_loss': tensor(0.3054, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 328 < 1001; dropping {'train_loss': tensor(0.2961, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 329 < 1001; dropping {'train_loss': tensor(0.2290, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 330 < 1001; dropping {'train_loss': tensor(0.2987, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 331 < 1001; dropping {'train_loss': tensor(0.4301, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 332 < 1001; dropping {'train_loss': tensor(0.2293, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 333 < 1001; dropping {'train_loss': tensor(0.3726, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 334 < 1001; dropping {'train_loss': tensor(0.3323, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 335 < 1001; dropping {'train_loss': tensor(0.2377, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 336 < 1001; dropping {'train_loss': tensor(0.3055, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 337 < 1001; dropping {'train_loss': tensor(0.3004, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 338 < 1001; dropping {'train_loss': tensor(0.2423, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 339 < 1001; dropping {'train_loss': tensor(0.3434, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 340 < 1001; dropping {'train_loss': tensor(0.2594, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 341 < 1001; dropping {'train_loss': tensor(0.1838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 342 < 1001; dropping {'train_loss': tensor(0.3818, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 343 < 1001; dropping {'train_loss': tensor(0.3616, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 344 < 1001; dropping {'train_loss': tensor(0.2188, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 345 < 1001; dropping {'train_loss': tensor(0.2374, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 346 < 1001; dropping {'train_loss': tensor(0.0850, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 347 < 1001; dropping {'train_loss': tensor(0.2886, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 348 < 1001; dropping {'train_loss': tensor(0.2635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 349 < 1001; dropping {'train_loss': tensor(0.3049, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 350 < 1001; dropping {'train_loss': tensor(0.3245, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 351 < 1001; dropping {'train_loss': tensor(0.2213, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 352 < 1001; dropping {'train_loss': tensor(0.1133, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 353 < 1001; dropping {'train_loss': tensor(0.1883, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 354 < 1001; dropping {'train_loss': tensor(0.2750, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 355 < 1001; dropping {'train_loss': tensor(0.2645, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 356 < 1001; dropping {'train_loss': tensor(0.1362, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 357 < 1001; dropping {'train_loss': tensor(0.1829, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 358 < 1001; dropping {'train_loss': tensor(0.2176, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 359 < 1001; dropping {'train_loss': tensor(0.1519, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 360 < 1001; dropping {'train_loss': tensor(0.3329, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 361 < 1001; dropping {'train_loss': tensor(0.2927, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 362 < 1001; dropping {'train_loss': tensor(0.2921, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 363 < 1001; dropping {'train_loss': tensor(0.2920, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 364 < 1001; dropping {'train_loss': tensor(0.2229, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 365 < 1001; dropping {'train_loss': tensor(0.2624, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 366 < 1001; dropping {'train_loss': tensor(0.3327, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 367 < 1001; dropping {'train_loss': tensor(0.3077, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 368 < 1001; dropping {'train_loss': tensor(0.3636, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 369 < 1001; dropping {'train_loss': tensor(0.2646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 370 < 1001; dropping {'train_loss': tensor(0.3226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 371 < 1001; dropping {'train_loss': tensor(0.3095, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 372 < 1001; dropping {'train_loss': tensor(0.2316, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 373 < 1001; dropping {'train_loss': tensor(0.2421, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 374 < 1001; dropping {'train_loss': tensor(0.1496, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 375 < 1001; dropping {'train_loss': tensor(0.3413, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 376 < 1001; dropping {'train_loss': tensor(0.0854, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 377 < 1001; dropping {'train_loss': tensor(0.2919, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 378 < 1001; dropping {'train_loss': tensor(0.2344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 379 < 1001; dropping {'train_loss': tensor(0.2884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 380 < 1001; dropping {'train_loss': tensor(0.4009, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 381 < 1001; dropping {'train_loss': tensor(0.0840, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 382 < 1001; dropping {'train_loss': tensor(0.1930, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 383 < 1001; dropping {'train_loss': tensor(0.2978, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 384 < 1001; dropping {'train_loss': tensor(0.4461, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 385 < 1001; dropping {'train_loss': tensor(0.2689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 386 < 1001; dropping {'train_loss': tensor(0.2556, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 387 < 1001; dropping {'train_loss': tensor(0.3413, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 388 < 1001; dropping {'train_loss': tensor(0.3623, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 389 < 1001; dropping {'train_loss': tensor(0.4149, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 390 < 1001; dropping {'train_loss': tensor(0.4805, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 391 < 1001; dropping {'train_loss': tensor(0.1902, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 392 < 1001; dropping {'train_loss': tensor(0.3102, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 393 < 1001; dropping {'train_loss': tensor(0.2634, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 394 < 1001; dropping {'train_loss': tensor(0.2921, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 395 < 1001; dropping {'train_loss': tensor(0.3846, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 396 < 1001; dropping {'train_loss': tensor(0.0403, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 397 < 1001; dropping {'train_loss': tensor(0.2203, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 398 < 1001; dropping {'train_loss': tensor(0.5889, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 399 < 1001; dropping {'train_loss': tensor(0.2009, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 400 < 1001; dropping {'train_loss': tensor(0.1880, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 401 < 1001; dropping {'train_loss': tensor(0.1617, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 402 < 1001; dropping {'train_loss': tensor(0.2728, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 403 < 1001; dropping {'train_loss': tensor(0.4680, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 404 < 1001; dropping {'train_loss': tensor(0.3575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 405 < 1001; dropping {'train_loss': tensor(0.1935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 406 < 1001; dropping {'train_loss': tensor(0.2483, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 407 < 1001; dropping {'train_loss': tensor(0.1637, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 408 < 1001; dropping {'train_loss': tensor(0.2926, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 409 < 1001; dropping {'train_loss': tensor(0.3032, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 410 < 1001; dropping {'train_loss': tensor(0.2238, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 411 < 1001; dropping {'train_loss': tensor(0.2212, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 412 < 1001; dropping {'train_loss': tensor(0.1950, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 413 < 1001; dropping {'train_loss': tensor(0.4074, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 414 < 1001; dropping {'train_loss': tensor(0.1933, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 415 < 1001; dropping {'train_loss': tensor(0.2736, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 416 < 1001; dropping {'train_loss': tensor(0.2217, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 417 < 1001; dropping {'train_loss': tensor(0.2676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 418 < 1001; dropping {'train_loss': tensor(0.2263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 419 < 1001; dropping {'train_loss': tensor(0.2268, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 420 < 1001; dropping {'train_loss': tensor(0.3430, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 421 < 1001; dropping {'train_loss': tensor(0.3568, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 422 < 1001; dropping {'train_loss': tensor(0.2302, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 423 < 1001; dropping {'train_loss': tensor(0.4342, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 424 < 1001; dropping {'train_loss': tensor(0.3589, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 425 < 1001; dropping {'train_loss': tensor(0.2316, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 426 < 1001; dropping {'train_loss': tensor(0.2446, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 427 < 1001; dropping {'train_loss': tensor(0.3999, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 428 < 1001; dropping {'train_loss': tensor(0.1180, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 429 < 1001; dropping {'train_loss': tensor(0.0947, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 430 < 1001; dropping {'train_loss': tensor(0.3108, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 431 < 1001; dropping {'train_loss': tensor(0.5035, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 432 < 1001; dropping {'train_loss': tensor(0.5012, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 433 < 1001; dropping {'train_loss': tensor(0.2566, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 434 < 1001; dropping {'train_loss': tensor(0.4149, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 435 < 1001; dropping {'train_loss': tensor(0.1932, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 436 < 1001; dropping {'train_loss': tensor(0.1263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 437 < 1001; dropping {'train_loss': tensor(0.3134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 438 < 1001; dropping {'train_loss': tensor(0.2281, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 19200/60000             (32% | Loss: 0.118039
wandb: WARNING Step must only increase in log calls.  Step 439 < 1001; dropping {'train_loss': tensor(0.3776, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 440 < 1001; dropping {'train_loss': tensor(0.2438, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 441 < 1001; dropping {'train_loss': tensor(0.4011, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 442 < 1001; dropping {'train_loss': tensor(0.3848, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 443 < 1001; dropping {'train_loss': tensor(0.2583, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 444 < 1001; dropping {'train_loss': tensor(0.1605, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 445 < 1001; dropping {'train_loss': tensor(0.3923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 446 < 1001; dropping {'train_loss': tensor(0.2705, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 447 < 1001; dropping {'train_loss': tensor(0.3657, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 448 < 1001; dropping {'train_loss': tensor(0.3708, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 449 < 1001; dropping {'train_loss': tensor(0.3689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 450 < 1001; dropping {'train_loss': tensor(0.2626, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 451 < 1001; dropping {'train_loss': tensor(0.1927, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 452 < 1001; dropping {'train_loss': tensor(0.2090, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 453 < 1001; dropping {'train_loss': tensor(0.3503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 454 < 1001; dropping {'train_loss': tensor(0.3973, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 455 < 1001; dropping {'train_loss': tensor(0.3551, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 456 < 1001; dropping {'train_loss': tensor(0.3717, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 457 < 1001; dropping {'train_loss': tensor(0.3223, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 458 < 1001; dropping {'train_loss': tensor(0.2735, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 459 < 1001; dropping {'train_loss': tensor(0.2551, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 460 < 1001; dropping {'train_loss': tensor(0.3312, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 461 < 1001; dropping {'train_loss': tensor(0.2642, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 462 < 1001; dropping {'train_loss': tensor(0.3403, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 463 < 1001; dropping {'train_loss': tensor(0.2367, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 464 < 1001; dropping {'train_loss': tensor(0.2654, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 465 < 1001; dropping {'train_loss': tensor(0.2566, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 466 < 1001; dropping {'train_loss': tensor(0.2710, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 467 < 1001; dropping {'train_loss': tensor(0.1677, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 468 < 1001; dropping {'train_loss': tensor(0.2618, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 469 < 1001; dropping {'train_loss': tensor(0.3895, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 470 < 1001; dropping {'train_loss': tensor(0.5675, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 471 < 1001; dropping {'train_loss': tensor(0.3597, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 472 < 1001; dropping {'train_loss': tensor(0.2541, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 473 < 1001; dropping {'train_loss': tensor(0.2937, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 474 < 1001; dropping {'train_loss': tensor(0.2927, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 475 < 1001; dropping {'train_loss': tensor(0.1545, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 476 < 1001; dropping {'train_loss': tensor(0.1364, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 477 < 1001; dropping {'train_loss': tensor(0.2726, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 478 < 1001; dropping {'train_loss': tensor(0.5170, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 479 < 1001; dropping {'train_loss': tensor(0.3280, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 480 < 1001; dropping {'train_loss': tensor(0.2761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 481 < 1001; dropping {'train_loss': tensor(0.2111, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 482 < 1001; dropping {'train_loss': tensor(0.1458, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 483 < 1001; dropping {'train_loss': tensor(0.1587, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 484 < 1001; dropping {'train_loss': tensor(0.2308, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 485 < 1001; dropping {'train_loss': tensor(0.2957, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 486 < 1001; dropping {'train_loss': tensor(0.2257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 487 < 1001; dropping {'train_loss': tensor(0.4993, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 488 < 1001; dropping {'train_loss': tensor(0.4334, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 489 < 1001; dropping {'train_loss': tensor(0.2903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 490 < 1001; dropping {'train_loss': tensor(0.1071, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 491 < 1001; dropping {'train_loss': tensor(0.2064, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 492 < 1001; dropping {'train_loss': tensor(0.1461, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 493 < 1001; dropping {'train_loss': tensor(0.2942, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 494 < 1001; dropping {'train_loss': tensor(0.3184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 495 < 1001; dropping {'train_loss': tensor(0.2921, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 496 < 1001; dropping {'train_loss': tensor(0.5282, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 497 < 1001; dropping {'train_loss': tensor(0.3460, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 498 < 1001; dropping {'train_loss': tensor(0.2701, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 499 < 1001; dropping {'train_loss': tensor(0.2913, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 500 < 1001; dropping {'train_loss': tensor(0.2209, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 501 < 1001; dropping {'train_loss': tensor(0.2240, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 502 < 1001; dropping {'train_loss': tensor(0.2784, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 503 < 1001; dropping {'train_loss': tensor(0.3053, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 504 < 1001; dropping {'train_loss': tensor(0.2326, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 505 < 1001; dropping {'train_loss': tensor(0.3039, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 506 < 1001; dropping {'train_loss': tensor(0.3667, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 507 < 1001; dropping {'train_loss': tensor(0.4053, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 508 < 1001; dropping {'train_loss': tensor(0.3413, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 509 < 1001; dropping {'train_loss': tensor(0.4696, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 510 < 1001; dropping {'train_loss': tensor(0.1602, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 511 < 1001; dropping {'train_loss': tensor(0.3852, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 512 < 1001; dropping {'train_loss': tensor(0.2753, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 513 < 1001; dropping {'train_loss': tensor(0.1097, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 514 < 1001; dropping {'train_loss': tensor(0.1961, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 515 < 1001; dropping {'train_loss': tensor(0.1568, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 516 < 1001; dropping {'train_loss': tensor(0.5828, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 517 < 1001; dropping {'train_loss': tensor(0.2298, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 518 < 1001; dropping {'train_loss': tensor(0.1979, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 519 < 1001; dropping {'train_loss': tensor(0.3284, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 520 < 1001; dropping {'train_loss': tensor(0.3018, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 521 < 1001; dropping {'train_loss': tensor(0.1964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 522 < 1001; dropping {'train_loss': tensor(0.4856, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 523 < 1001; dropping {'train_loss': tensor(0.2677, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 524 < 1001; dropping {'train_loss': tensor(0.0606, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 525 < 1001; dropping {'train_loss': tensor(0.3690, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 526 < 1001; dropping {'train_loss': tensor(0.2973, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 527 < 1001; dropping {'train_loss': tensor(0.1659, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 528 < 1001; dropping {'train_loss': tensor(0.1585, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 529 < 1001; dropping {'train_loss': tensor(0.3468, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 530 < 1001; dropping {'train_loss': tensor(0.3522, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 531 < 1001; dropping {'train_loss': tensor(0.4496, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 532 < 1001; dropping {'train_loss': tensor(0.3386, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 533 < 1001; dropping {'train_loss': tensor(0.1936, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 534 < 1001; dropping {'train_loss': tensor(0.2291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 535 < 1001; dropping {'train_loss': tensor(0.2796, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 536 < 1001; dropping {'train_loss': tensor(0.1835, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 537 < 1001; dropping {'train_loss': tensor(0.1737, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 538 < 1001; dropping {'train_loss': tensor(0.5215, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 539 < 1001; dropping {'train_loss': tensor(0.2675, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 540 < 1001; dropping {'train_loss': tensor(0.3298, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 541 < 1001; dropping {'train_loss': tensor(0.3693, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 542 < 1001; dropping {'train_loss': tensor(0.2996, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 543 < 1001; dropping {'train_loss': tensor(0.1147, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 544 < 1001; dropping {'train_loss': tensor(0.2263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 545 < 1001; dropping {'train_loss': tensor(0.3316, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 546 < 1001; dropping {'train_loss': tensor(0.2622, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 547 < 1001; dropping {'train_loss': tensor(0.2195, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 548 < 1001; dropping {'train_loss': tensor(0.3115, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 549 < 1001; dropping {'train_loss': tensor(0.2135, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 550 < 1001; dropping {'train_loss': tensor(0.4179, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 551 < 1001; dropping {'train_loss': tensor(0.2562, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 552 < 1001; dropping {'train_loss': tensor(0.3420, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 553 < 1001; dropping {'train_loss': tensor(0.3159, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 554 < 1001; dropping {'train_loss': tensor(0.2218, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 555 < 1001; dropping {'train_loss': tensor(0.2981, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 556 < 1001; dropping {'train_loss': tensor(0.2585, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 557 < 1001; dropping {'train_loss': tensor(0.2213, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 558 < 1001; dropping {'train_loss': tensor(0.1899, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 559 < 1001; dropping {'train_loss': tensor(0.3134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 560 < 1001; dropping {'train_loss': tensor(0.2511, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 561 < 1001; dropping {'train_loss': tensor(0.1914, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 562 < 1001; dropping {'train_loss': tensor(0.3084, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 563 < 1001; dropping {'train_loss': tensor(0.4246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 564 < 1001; dropping {'train_loss': tensor(0.3266, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 565 < 1001; dropping {'train_loss': tensor(0.1869, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 566 < 1001; dropping {'train_loss': tensor(0.3715, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 567 < 1001; dropping {'train_loss': tensor(0.1501, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 568 < 1001; dropping {'train_loss': tensor(0.3335, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 25600/60000             (43% | Loss: 0.158542
wandb: WARNING Step must only increase in log calls.  Step 569 < 1001; dropping {'train_loss': tensor(0.4538, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 570 < 1001; dropping {'train_loss': tensor(0.3200, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 571 < 1001; dropping {'train_loss': tensor(0.2572, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 572 < 1001; dropping {'train_loss': tensor(0.3389, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 573 < 1001; dropping {'train_loss': tensor(0.1869, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 574 < 1001; dropping {'train_loss': tensor(0.2575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 575 < 1001; dropping {'train_loss': tensor(0.3275, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 576 < 1001; dropping {'train_loss': tensor(0.2453, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 577 < 1001; dropping {'train_loss': tensor(0.4085, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 578 < 1001; dropping {'train_loss': tensor(0.1860, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 579 < 1001; dropping {'train_loss': tensor(0.3744, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 580 < 1001; dropping {'train_loss': tensor(0.3042, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 581 < 1001; dropping {'train_loss': tensor(0.2379, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 582 < 1001; dropping {'train_loss': tensor(0.3080, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 583 < 1001; dropping {'train_loss': tensor(0.4963, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 584 < 1001; dropping {'train_loss': tensor(0.2982, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 585 < 1001; dropping {'train_loss': tensor(0.2560, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 586 < 1001; dropping {'train_loss': tensor(0.2042, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 587 < 1001; dropping {'train_loss': tensor(0.1838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 588 < 1001; dropping {'train_loss': tensor(0.3462, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 589 < 1001; dropping {'train_loss': tensor(0.3756, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 590 < 1001; dropping {'train_loss': tensor(0.3927, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 591 < 1001; dropping {'train_loss': tensor(0.3346, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 592 < 1001; dropping {'train_loss': tensor(0.2431, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 593 < 1001; dropping {'train_loss': tensor(0.4378, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 594 < 1001; dropping {'train_loss': tensor(0.4137, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 595 < 1001; dropping {'train_loss': tensor(0.3365, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 596 < 1001; dropping {'train_loss': tensor(0.3006, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 597 < 1001; dropping {'train_loss': tensor(0.3013, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 598 < 1001; dropping {'train_loss': tensor(0.3333, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 599 < 1001; dropping {'train_loss': tensor(0.1557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 600 < 1001; dropping {'train_loss': tensor(0.2997, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 601 < 1001; dropping {'train_loss': tensor(0.2358, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 602 < 1001; dropping {'train_loss': tensor(0.2942, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 603 < 1001; dropping {'train_loss': tensor(0.2719, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 604 < 1001; dropping {'train_loss': tensor(0.2943, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 605 < 1001; dropping {'train_loss': tensor(0.2230, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 606 < 1001; dropping {'train_loss': tensor(0.3355, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 607 < 1001; dropping {'train_loss': tensor(0.2674, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 608 < 1001; dropping {'train_loss': tensor(0.2587, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 609 < 1001; dropping {'train_loss': tensor(0.3836, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 610 < 1001; dropping {'train_loss': tensor(0.2199, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 611 < 1001; dropping {'train_loss': tensor(0.3364, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 612 < 1001; dropping {'train_loss': tensor(0.2461, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 613 < 1001; dropping {'train_loss': tensor(0.1854, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 614 < 1001; dropping {'train_loss': tensor(0.2680, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 615 < 1001; dropping {'train_loss': tensor(0.1922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 616 < 1001; dropping {'train_loss': tensor(0.2662, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 617 < 1001; dropping {'train_loss': tensor(0.3333, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 618 < 1001; dropping {'train_loss': tensor(0.3940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 619 < 1001; dropping {'train_loss': tensor(0.1836, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 620 < 1001; dropping {'train_loss': tensor(0.0754, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 621 < 1001; dropping {'train_loss': tensor(0.2937, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 622 < 1001; dropping {'train_loss': tensor(0.3838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 623 < 1001; dropping {'train_loss': tensor(0.4499, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 624 < 1001; dropping {'train_loss': tensor(0.2921, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 625 < 1001; dropping {'train_loss': tensor(0.2172, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 626 < 1001; dropping {'train_loss': tensor(0.2025, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 627 < 1001; dropping {'train_loss': tensor(0.2475, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 628 < 1001; dropping {'train_loss': tensor(0.4887, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 629 < 1001; dropping {'train_loss': tensor(0.3029, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 630 < 1001; dropping {'train_loss': tensor(0.2614, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 32000/60000             (53% | Loss: 0.488705
wandb: WARNING Step must only increase in log calls.  Step 631 < 1001; dropping {'train_loss': tensor(0.1534, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 632 < 1001; dropping {'train_loss': tensor(0.2536, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 633 < 1001; dropping {'train_loss': tensor(0.0820, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 634 < 1001; dropping {'train_loss': tensor(0.2680, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 635 < 1001; dropping {'train_loss': tensor(0.2214, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 636 < 1001; dropping {'train_loss': tensor(0.3346, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 637 < 1001; dropping {'train_loss': tensor(0.3295, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 638 < 1001; dropping {'train_loss': tensor(0.2923, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 639 < 1001; dropping {'train_loss': tensor(0.2968, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 640 < 1001; dropping {'train_loss': tensor(0.3528, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 641 < 1001; dropping {'train_loss': tensor(0.2095, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 642 < 1001; dropping {'train_loss': tensor(0.3244, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 643 < 1001; dropping {'train_loss': tensor(0.2120, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 644 < 1001; dropping {'train_loss': tensor(0.3722, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 645 < 1001; dropping {'train_loss': tensor(0.2822, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 646 < 1001; dropping {'train_loss': tensor(0.2859, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 647 < 1001; dropping {'train_loss': tensor(0.5159, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 648 < 1001; dropping {'train_loss': tensor(0.2558, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 649 < 1001; dropping {'train_loss': tensor(0.2858, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 650 < 1001; dropping {'train_loss': tensor(0.2052, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 651 < 1001; dropping {'train_loss': tensor(0.2568, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 652 < 1001; dropping {'train_loss': tensor(0.2337, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 653 < 1001; dropping {'train_loss': tensor(0.3375, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 654 < 1001; dropping {'train_loss': tensor(0.4714, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 655 < 1001; dropping {'train_loss': tensor(0.2708, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 656 < 1001; dropping {'train_loss': tensor(0.3777, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 657 < 1001; dropping {'train_loss': tensor(0.4233, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 658 < 1001; dropping {'train_loss': tensor(0.1575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 659 < 1001; dropping {'train_loss': tensor(0.2646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 660 < 1001; dropping {'train_loss': tensor(0.2984, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 661 < 1001; dropping {'train_loss': tensor(0.2332, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 662 < 1001; dropping {'train_loss': tensor(0.3958, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 663 < 1001; dropping {'train_loss': tensor(0.2623, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 664 < 1001; dropping {'train_loss': tensor(0.2000, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 665 < 1001; dropping {'train_loss': tensor(0.1726, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 666 < 1001; dropping {'train_loss': tensor(0.3078, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 667 < 1001; dropping {'train_loss': tensor(0.2595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 668 < 1001; dropping {'train_loss': tensor(0.1207, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 669 < 1001; dropping {'train_loss': tensor(0.2864, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 670 < 1001; dropping {'train_loss': tensor(0.3866, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 671 < 1001; dropping {'train_loss': tensor(0.3635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 672 < 1001; dropping {'train_loss': tensor(0.4061, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 673 < 1001; dropping {'train_loss': tensor(0.3048, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 674 < 1001; dropping {'train_loss': tensor(0.2332, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 675 < 1001; dropping {'train_loss': tensor(0.3746, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 676 < 1001; dropping {'train_loss': tensor(0.2762, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 677 < 1001; dropping {'train_loss': tensor(0.3024, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 678 < 1001; dropping {'train_loss': tensor(0.3685, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 679 < 1001; dropping {'train_loss': tensor(0.1981, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 680 < 1001; dropping {'train_loss': tensor(0.1889, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 681 < 1001; dropping {'train_loss': tensor(0.1822, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 682 < 1001; dropping {'train_loss': tensor(0.1573, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 683 < 1001; dropping {'train_loss': tensor(0.4116, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 684 < 1001; dropping {'train_loss': tensor(0.4561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 685 < 1001; dropping {'train_loss': tensor(0.3229, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 686 < 1001; dropping {'train_loss': tensor(0.1889, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 687 < 1001; dropping {'train_loss': tensor(0.4047, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 688 < 1001; dropping {'train_loss': tensor(0.1946, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 689 < 1001; dropping {'train_loss': tensor(0.2933, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 690 < 1001; dropping {'train_loss': tensor(0.3689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 691 < 1001; dropping {'train_loss': tensor(0.2542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 692 < 1001; dropping {'train_loss': tensor(0.2557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 693 < 1001; dropping {'train_loss': tensor(0.3143, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 694 < 1001; dropping {'train_loss': tensor(0.2113, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 695 < 1001; dropping {'train_loss': tensor(0.2957, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 696 < 1001; dropping {'train_loss': tensor(0.3643, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 697 < 1001; dropping {'train_loss': tensor(0.2184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 698 < 1001; dropping {'train_loss': tensor(0.0366, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 699 < 1001; dropping {'train_loss': tensor(0.2932, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 700 < 1001; dropping {'train_loss': tensor(0.2641, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 701 < 1001; dropping {'train_loss': tensor(0.2981, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 702 < 1001; dropping {'train_loss': tensor(0.1841, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 703 < 1001; dropping {'train_loss': tensor(0.2940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 704 < 1001; dropping {'train_loss': tensor(0.3054, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 705 < 1001; dropping {'train_loss': tensor(0.2718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 706 < 1001; dropping {'train_loss': tensor(0.4153, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 707 < 1001; dropping {'train_loss': tensor(0.3254, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 708 < 1001; dropping {'train_loss': tensor(0.2273, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 709 < 1001; dropping {'train_loss': tensor(0.3694, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 710 < 1001; dropping {'train_loss': tensor(0.1246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 711 < 1001; dropping {'train_loss': tensor(0.3439, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 712 < 1001; dropping {'train_loss': tensor(0.1749, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 713 < 1001; dropping {'train_loss': tensor(0.2182, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 714 < 1001; dropping {'train_loss': tensor(0.2173, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 715 < 1001; dropping {'train_loss': tensor(0.2120, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 716 < 1001; dropping {'train_loss': tensor(0.2637, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 717 < 1001; dropping {'train_loss': tensor(0.1163, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 718 < 1001; dropping {'train_loss': tensor(0.3636, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 719 < 1001; dropping {'train_loss': tensor(0.2231, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 720 < 1001; dropping {'train_loss': tensor(0.2735, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 721 < 1001; dropping {'train_loss': tensor(0.3108, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 722 < 1001; dropping {'train_loss': tensor(0.1838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 723 < 1001; dropping {'train_loss': tensor(0.1957, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 724 < 1001; dropping {'train_loss': tensor(0.3727, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 725 < 1001; dropping {'train_loss': tensor(0.2297, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 726 < 1001; dropping {'train_loss': tensor(0.2134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 727 < 1001; dropping {'train_loss': tensor(0.3042, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 728 < 1001; dropping {'train_loss': tensor(0.2327, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 729 < 1001; dropping {'train_loss': tensor(0.1786, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 730 < 1001; dropping {'train_loss': tensor(0.3798, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 731 < 1001; dropping {'train_loss': tensor(0.2925, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 732 < 1001; dropping {'train_loss': tensor(0.3242, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 733 < 1001; dropping {'train_loss': tensor(0.2206, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 734 < 1001; dropping {'train_loss': tensor(0.3083, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 735 < 1001; dropping {'train_loss': tensor(0.2253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 736 < 1001; dropping {'train_loss': tensor(0.3238, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 737 < 1001; dropping {'train_loss': tensor(0.3466, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 738 < 1001; dropping {'train_loss': tensor(0.3288, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 739 < 1001; dropping {'train_loss': tensor(0.4106, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 740 < 1001; dropping {'train_loss': tensor(0.3336, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 741 < 1001; dropping {'train_loss': tensor(0.4036, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 742 < 1001; dropping {'train_loss': tensor(0.2899, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 743 < 1001; dropping {'train_loss': tensor(0.3031, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 744 < 1001; dropping {'train_loss': tensor(0.1498, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 745 < 1001; dropping {'train_loss': tensor(0.1447, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 746 < 1001; dropping {'train_loss': tensor(0.1596, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 747 < 1001; dropping {'train_loss': tensor(0.2285, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 748 < 1001; dropping {'train_loss': tensor(0.1950, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 38400/60000             (64% | Loss: 0.232740
wandb: WARNING Step must only increase in log calls.  Step 749 < 1001; dropping {'train_loss': tensor(0.3183, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 750 < 1001; dropping {'train_loss': tensor(0.3670, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 751 < 1001; dropping {'train_loss': tensor(0.2383, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 752 < 1001; dropping {'train_loss': tensor(0.3126, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 753 < 1001; dropping {'train_loss': tensor(0.2580, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 754 < 1001; dropping {'train_loss': tensor(0.2575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 755 < 1001; dropping {'train_loss': tensor(0.2999, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 756 < 1001; dropping {'train_loss': tensor(0.1889, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 757 < 1001; dropping {'train_loss': tensor(0.2011, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 758 < 1001; dropping {'train_loss': tensor(0.2182, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 759 < 1001; dropping {'train_loss': tensor(0.2507, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 760 < 1001; dropping {'train_loss': tensor(0.2592, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 761 < 1001; dropping {'train_loss': tensor(0.2691, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 762 < 1001; dropping {'train_loss': tensor(0.3662, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 763 < 1001; dropping {'train_loss': tensor(0.2937, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 764 < 1001; dropping {'train_loss': tensor(0.1890, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 765 < 1001; dropping {'train_loss': tensor(0.3614, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 766 < 1001; dropping {'train_loss': tensor(0.2334, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 767 < 1001; dropping {'train_loss': tensor(0.3308, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 768 < 1001; dropping {'train_loss': tensor(0.1920, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 769 < 1001; dropping {'train_loss': tensor(0.2580, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 770 < 1001; dropping {'train_loss': tensor(0.3453, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 771 < 1001; dropping {'train_loss': tensor(0.2313, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 772 < 1001; dropping {'train_loss': tensor(0.4788, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 773 < 1001; dropping {'train_loss': tensor(0.2786, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 774 < 1001; dropping {'train_loss': tensor(0.2531, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 775 < 1001; dropping {'train_loss': tensor(0.1473, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 776 < 1001; dropping {'train_loss': tensor(0.4365, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 777 < 1001; dropping {'train_loss': tensor(0.1844, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 778 < 1001; dropping {'train_loss': tensor(0.3035, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 779 < 1001; dropping {'train_loss': tensor(0.2676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 780 < 1001; dropping {'train_loss': tensor(0.2602, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 781 < 1001; dropping {'train_loss': tensor(0.2665, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 782 < 1001; dropping {'train_loss': tensor(0.1750, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 783 < 1001; dropping {'train_loss': tensor(0.1873, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 784 < 1001; dropping {'train_loss': tensor(0.0745, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 785 < 1001; dropping {'train_loss': tensor(0.1746, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 786 < 1001; dropping {'train_loss': tensor(0.3335, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 787 < 1001; dropping {'train_loss': tensor(0.4836, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 788 < 1001; dropping {'train_loss': tensor(0.0826, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 789 < 1001; dropping {'train_loss': tensor(0.3332, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 790 < 1001; dropping {'train_loss': tensor(0.3641, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 791 < 1001; dropping {'train_loss': tensor(0.2563, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 792 < 1001; dropping {'train_loss': tensor(0.2195, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 793 < 1001; dropping {'train_loss': tensor(0.2557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 794 < 1001; dropping {'train_loss': tensor(0.1872, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 795 < 1001; dropping {'train_loss': tensor(0.2367, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 796 < 1001; dropping {'train_loss': tensor(0.2783, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 797 < 1001; dropping {'train_loss': tensor(0.1224, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 798 < 1001; dropping {'train_loss': tensor(0.1501, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 799 < 1001; dropping {'train_loss': tensor(0.5086, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 800 < 1001; dropping {'train_loss': tensor(0.2477, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 801 < 1001; dropping {'train_loss': tensor(0.3769, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 802 < 1001; dropping {'train_loss': tensor(0.1878, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 803 < 1001; dropping {'train_loss': tensor(0.2571, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 804 < 1001; dropping {'train_loss': tensor(0.3030, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 805 < 1001; dropping {'train_loss': tensor(0.2772, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 806 < 1001; dropping {'train_loss': tensor(0.2402, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 807 < 1001; dropping {'train_loss': tensor(0.3219, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 808 < 1001; dropping {'train_loss': tensor(0.3105, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 809 < 1001; dropping {'train_loss': tensor(0.2185, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 810 < 1001; dropping {'train_loss': tensor(0.1884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 811 < 1001; dropping {'train_loss': tensor(0.1987, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 812 < 1001; dropping {'train_loss': tensor(0.1552, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 813 < 1001; dropping {'train_loss': tensor(0.3169, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 814 < 1001; dropping {'train_loss': tensor(0.3686, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 815 < 1001; dropping {'train_loss': tensor(0.2952, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 816 < 1001; dropping {'train_loss': tensor(0.1878, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 817 < 1001; dropping {'train_loss': tensor(0.3635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 818 < 1001; dropping {'train_loss': tensor(0.4743, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 819 < 1001; dropping {'train_loss': tensor(0.2954, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 820 < 1001; dropping {'train_loss': tensor(0.1741, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 821 < 1001; dropping {'train_loss': tensor(0.3703, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 822 < 1001; dropping {'train_loss': tensor(0.3546, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 823 < 1001; dropping {'train_loss': tensor(0.1521, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 824 < 1001; dropping {'train_loss': tensor(0.3347, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 825 < 1001; dropping {'train_loss': tensor(0.5251, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 826 < 1001; dropping {'train_loss': tensor(0.4375, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 827 < 1001; dropping {'train_loss': tensor(0.3011, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 828 < 1001; dropping {'train_loss': tensor(0.2656, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 829 < 1001; dropping {'train_loss': tensor(0.3200, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 830 < 1001; dropping {'train_loss': tensor(0.2899, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 831 < 1001; dropping {'train_loss': tensor(0.4196, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 832 < 1001; dropping {'train_loss': tensor(0.3022, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 833 < 1001; dropping {'train_loss': tensor(0.2122, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 834 < 1001; dropping {'train_loss': tensor(0.1669, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 835 < 1001; dropping {'train_loss': tensor(0.1545, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 836 < 1001; dropping {'train_loss': tensor(0.2578, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 837 < 1001; dropping {'train_loss': tensor(0.2043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 838 < 1001; dropping {'train_loss': tensor(0.2608, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 839 < 1001; dropping {'train_loss': tensor(0.2847, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 840 < 1001; dropping {'train_loss': tensor(0.2990, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 841 < 1001; dropping {'train_loss': tensor(0.2639, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 842 < 1001; dropping {'train_loss': tensor(0.2569, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 843 < 1001; dropping {'train_loss': tensor(0.1634, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 844 < 1001; dropping {'train_loss': tensor(0.2832, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 845 < 1001; dropping {'train_loss': tensor(0.3174, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 846 < 1001; dropping {'train_loss': tensor(0.3377, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 847 < 1001; dropping {'train_loss': tensor(0.2953, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 848 < 1001; dropping {'train_loss': tensor(0.2250, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 849 < 1001; dropping {'train_loss': tensor(0.2130, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 850 < 1001; dropping {'train_loss': tensor(0.2754, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 851 < 1001; dropping {'train_loss': tensor(0.3839, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 852 < 1001; dropping {'train_loss': tensor(0.3300, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 853 < 1001; dropping {'train_loss': tensor(0.2928, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 854 < 1001; dropping {'train_loss': tensor(0.2087, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 855 < 1001; dropping {'train_loss': tensor(0.3620, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 856 < 1001; dropping {'train_loss': tensor(0.2557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 857 < 1001; dropping {'train_loss': tensor(0.4733, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 858 < 1001; dropping {'train_loss': tensor(0.1613, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 859 < 1001; dropping {'train_loss': tensor(0.4000, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 860 < 1001; dropping {'train_loss': tensor(0.2763, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 861 < 1001; dropping {'train_loss': tensor(0.1816, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 862 < 1001; dropping {'train_loss': tensor(0.3447, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 863 < 1001; dropping {'train_loss': tensor(0.2215, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 864 < 1001; dropping {'train_loss': tensor(0.2206, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 865 < 1001; dropping {'train_loss': tensor(0.1857, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 866 < 1001; dropping {'train_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 867 < 1001; dropping {'train_loss': tensor(0.2597, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 868 < 1001; dropping {'train_loss': tensor(0.4157, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 869 < 1001; dropping {'train_loss': tensor(0.2650, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 870 < 1001; dropping {'train_loss': tensor(0.2244, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 871 < 1001; dropping {'train_loss': tensor(0.1205, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 872 < 1001; dropping {'train_loss': tensor(0.2291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 873 < 1001; dropping {'train_loss': tensor(0.2329, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 874 < 1001; dropping {'train_loss': tensor(0.2320, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 44800/60000             (75% | Loss: 0.265593
wandb: WARNING Step must only increase in log calls.  Step 875 < 1001; dropping {'train_loss': tensor(0.1898, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 876 < 1001; dropping {'train_loss': tensor(0.1471, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 877 < 1001; dropping {'train_loss': tensor(0.1817, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 878 < 1001; dropping {'train_loss': tensor(0.3696, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 879 < 1001; dropping {'train_loss': tensor(0.3828, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 880 < 1001; dropping {'train_loss': tensor(0.4439, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 881 < 1001; dropping {'train_loss': tensor(0.2557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 882 < 1001; dropping {'train_loss': tensor(0.3799, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 883 < 1001; dropping {'train_loss': tensor(0.5134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 884 < 1001; dropping {'train_loss': tensor(0.4832, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 885 < 1001; dropping {'train_loss': tensor(0.5181, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 886 < 1001; dropping {'train_loss': tensor(0.1505, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 887 < 1001; dropping {'train_loss': tensor(0.2584, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 888 < 1001; dropping {'train_loss': tensor(0.1291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 889 < 1001; dropping {'train_loss': tensor(0.3293, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 890 < 1001; dropping {'train_loss': tensor(0.1448, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 891 < 1001; dropping {'train_loss': tensor(0.2647, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 892 < 1001; dropping {'train_loss': tensor(0.1841, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 893 < 1001; dropping {'train_loss': tensor(0.5092, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 894 < 1001; dropping {'train_loss': tensor(0.2802, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 895 < 1001; dropping {'train_loss': tensor(0.3334, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 896 < 1001; dropping {'train_loss': tensor(0.0948, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 897 < 1001; dropping {'train_loss': tensor(0.3684, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 898 < 1001; dropping {'train_loss': tensor(0.0758, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 899 < 1001; dropping {'train_loss': tensor(0.0778, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 900 < 1001; dropping {'train_loss': tensor(0.4783, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 901 < 1001; dropping {'train_loss': tensor(0.2625, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 902 < 1001; dropping {'train_loss': tensor(0.2910, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 903 < 1001; dropping {'train_loss': tensor(0.2197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 904 < 1001; dropping {'train_loss': tensor(0.2262, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 905 < 1001; dropping {'train_loss': tensor(0.2635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 906 < 1001; dropping {'train_loss': tensor(0.3361, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 907 < 1001; dropping {'train_loss': tensor(0.3523, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 908 < 1001; dropping {'train_loss': tensor(0.3068, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 909 < 1001; dropping {'train_loss': tensor(0.2927, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 910 < 1001; dropping {'train_loss': tensor(0.4163, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 911 < 1001; dropping {'train_loss': tensor(0.1865, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 912 < 1001; dropping {'train_loss': tensor(0.3884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 913 < 1001; dropping {'train_loss': tensor(0.2319, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 914 < 1001; dropping {'train_loss': tensor(0.3214, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 915 < 1001; dropping {'train_loss': tensor(0.4962, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 916 < 1001; dropping {'train_loss': tensor(0.1965, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 917 < 1001; dropping {'train_loss': tensor(0.2204, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 918 < 1001; dropping {'train_loss': tensor(0.3125, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 919 < 1001; dropping {'train_loss': tensor(0.2722, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 920 < 1001; dropping {'train_loss': tensor(0.2760, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 921 < 1001; dropping {'train_loss': tensor(0.2623, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 922 < 1001; dropping {'train_loss': tensor(0.2744, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 923 < 1001; dropping {'train_loss': tensor(0.0780, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 924 < 1001; dropping {'train_loss': tensor(0.3359, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 925 < 1001; dropping {'train_loss': tensor(0.3675, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 926 < 1001; dropping {'train_loss': tensor(0.3039, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 927 < 1001; dropping {'train_loss': tensor(0.3394, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 928 < 1001; dropping {'train_loss': tensor(0.2882, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 929 < 1001; dropping {'train_loss': tensor(0.2197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 930 < 1001; dropping {'train_loss': tensor(0.3287, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 931 < 1001; dropping {'train_loss': tensor(0.2585, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 932 < 1001; dropping {'train_loss': tensor(0.3282, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 933 < 1001; dropping {'train_loss': tensor(0.2257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 934 < 1001; dropping {'train_loss': tensor(0.3700, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 935 < 1001; dropping {'train_loss': tensor(0.2598, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 936 < 1001; dropping {'train_loss': tensor(0.1646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 937 < 1001; dropping {'train_loss': tensor(0.3438, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 938 < 1001; dropping {'train_loss': tensor(0.1558, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 939 < 1001; dropping {'train_loss': tensor(0.3827, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 940 < 1001; dropping {'train_loss': tensor(0.2561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 941 < 1001; dropping {'train_loss': tensor(0.4542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 942 < 1001; dropping {'train_loss': tensor(0.1774, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 943 < 1001; dropping {'train_loss': tensor(0.1175, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 944 < 1001; dropping {'train_loss': tensor(0.2451, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 945 < 1001; dropping {'train_loss': tensor(0.2265, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 946 < 1001; dropping {'train_loss': tensor(0.3065, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 51200/60000             (85% | Loss: 0.288234
wandb: WARNING Step must only increase in log calls.  Step 947 < 1001; dropping {'train_loss': tensor(0.3228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 948 < 1001; dropping {'train_loss': tensor(0.4179, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 949 < 1001; dropping {'train_loss': tensor(0.2957, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 950 < 1001; dropping {'train_loss': tensor(0.2213, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 951 < 1001; dropping {'train_loss': tensor(0.3675, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 952 < 1001; dropping {'train_loss': tensor(0.2209, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 953 < 1001; dropping {'train_loss': tensor(0.3926, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 954 < 1001; dropping {'train_loss': tensor(0.1062, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 955 < 1001; dropping {'train_loss': tensor(0.3491, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 956 < 1001; dropping {'train_loss': tensor(0.2232, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 957 < 1001; dropping {'train_loss': tensor(0.2723, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 958 < 1001; dropping {'train_loss': tensor(0.1796, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 959 < 1001; dropping {'train_loss': tensor(0.2891, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 960 < 1001; dropping {'train_loss': tensor(0.2179, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 961 < 1001; dropping {'train_loss': tensor(0.3082, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 962 < 1001; dropping {'train_loss': tensor(0.1736, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 963 < 1001; dropping {'train_loss': tensor(0.2491, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 964 < 1001; dropping {'train_loss': tensor(0.2217, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 965 < 1001; dropping {'train_loss': tensor(0.3269, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 966 < 1001; dropping {'train_loss': tensor(0.2566, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 967 < 1001; dropping {'train_loss': tensor(0.1496, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 968 < 1001; dropping {'train_loss': tensor(0.2742, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 969 < 1001; dropping {'train_loss': tensor(0.2842, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 970 < 1001; dropping {'train_loss': tensor(0.4544, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 971 < 1001; dropping {'train_loss': tensor(0.2295, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 972 < 1001; dropping {'train_loss': tensor(0.3670, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 973 < 1001; dropping {'train_loss': tensor(0.2186, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 974 < 1001; dropping {'train_loss': tensor(0.2964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 975 < 1001; dropping {'train_loss': tensor(0.3215, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 976 < 1001; dropping {'train_loss': tensor(0.2834, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 977 < 1001; dropping {'train_loss': tensor(0.2551, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 978 < 1001; dropping {'train_loss': tensor(0.3683, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 979 < 1001; dropping {'train_loss': tensor(0.2206, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 980 < 1001; dropping {'train_loss': tensor(0.2205, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 981 < 1001; dropping {'train_loss': tensor(0.2674, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 982 < 1001; dropping {'train_loss': tensor(0.2590, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 983 < 1001; dropping {'train_loss': tensor(0.1961, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 984 < 1001; dropping {'train_loss': tensor(0.3642, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 985 < 1001; dropping {'train_loss': tensor(0.3489, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 986 < 1001; dropping {'train_loss': tensor(0.3994, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 987 < 1001; dropping {'train_loss': tensor(0.1549, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 988 < 1001; dropping {'train_loss': tensor(0.1902, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 989 < 1001; dropping {'train_loss': tensor(0.4074, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 990 < 1001; dropping {'train_loss': tensor(0.3925, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 991 < 1001; dropping {'train_loss': tensor(0.2205, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 992 < 1001; dropping {'train_loss': tensor(0.1563, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 993 < 1001; dropping {'train_loss': tensor(0.2540, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 994 < 1001; dropping {'train_loss': tensor(0.2611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 995 < 1001; dropping {'train_loss': tensor(0.2402, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 996 < 1001; dropping {'train_loss': tensor(0.2207, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 997 < 1001; dropping {'train_loss': tensor(0.3626, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 998 < 1001; dropping {'train_loss': tensor(0.4019, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 999 < 1001; dropping {'train_loss': tensor(0.2599, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1000 < 1001; dropping {'train_loss': tensor(0.3389, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 128 < 1065; dropping {'val_loss': tensor(0.2474, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 129 < 1065; dropping {'val_loss': tensor(0.1492, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 130 < 1065; dropping {'val_loss': tensor(0.3384, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 131 < 1065; dropping {'val_loss': tensor(0.3184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 132 < 1065; dropping {'val_loss': tensor(0.2159, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 133 < 1065; dropping {'val_loss': tensor(0.3871, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 134 < 1065; dropping {'val_loss': tensor(0.2209, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 135 < 1065; dropping {'val_loss': tensor(0.1379, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 136 < 1065; dropping {'val_loss': tensor(0.2621, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 137 < 1065; dropping {'val_loss': tensor(0.0751, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 138 < 1065; dropping {'val_loss': tensor(0.3837, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 139 < 1065; dropping {'val_loss': tensor(0.3819, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 140 < 1065; dropping {'val_loss': tensor(0.3406, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 141 < 1065; dropping {'val_loss': tensor(0.1940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 142 < 1065; dropping {'val_loss': tensor(0.3578, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 143 < 1065; dropping {'val_loss': tensor(0.3434, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 144 < 1065; dropping {'val_loss': tensor(0.4328, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 145 < 1065; dropping {'val_loss': tensor(0.3799, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 146 < 1065; dropping {'val_loss': tensor(0.3492, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 147 < 1065; dropping {'val_loss': tensor(0.2394, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 148 < 1065; dropping {'val_loss': tensor(0.2382, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 149 < 1065; dropping {'val_loss': tensor(0.2275, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 150 < 1065; dropping {'val_loss': tensor(0.2333, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 151 < 1065; dropping {'val_loss': tensor(0.4226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 152 < 1065; dropping {'val_loss': tensor(0.3325, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 153 < 1065; dropping {'val_loss': tensor(0.3457, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 154 < 1065; dropping {'val_loss': tensor(0.3262, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 155 < 1065; dropping {'val_loss': tensor(0.4079, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 156 < 1065; dropping {'val_loss': tensor(0.2830, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 157 < 1065; dropping {'val_loss': tensor(0.2659, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 158 < 1065; dropping {'val_loss': tensor(0.2984, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 159 < 1065; dropping {'val_loss': tensor(0.1692, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 160 < 1065; dropping {'val_loss': tensor(0.2552, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 161 < 1065; dropping {'val_loss': tensor(0.2283, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 162 < 1065; dropping {'val_loss': tensor(0.3478, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 163 < 1065; dropping {'val_loss': tensor(0.1319, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 164 < 1065; dropping {'val_loss': tensor(0.2654, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 165 < 1065; dropping {'val_loss': tensor(0.4615, grad_fn=<NllLossBackward0>)}.
Train Epoch: 3 | Batch Status: 57600/60000             (96% | Loss: 0.154142
wandb: WARNING Step must only increase in log calls.  Step 166 < 1065; dropping {'val_loss': tensor(0.1584, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 167 < 1065; dropping {'val_loss': tensor(0.4508, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 168 < 1065; dropping {'val_loss': tensor(0.3113, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 169 < 1065; dropping {'val_loss': tensor(0.3533, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 170 < 1065; dropping {'val_loss': tensor(0.1366, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 171 < 1065; dropping {'val_loss': tensor(0.2182, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 172 < 1065; dropping {'val_loss': tensor(0.2166, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 173 < 1065; dropping {'val_loss': tensor(0.2834, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 174 < 1065; dropping {'val_loss': tensor(0.2289, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 175 < 1065; dropping {'val_loss': tensor(0.1217, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 176 < 1065; dropping {'val_loss': tensor(0.3414, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 177 < 1065; dropping {'val_loss': tensor(0.3648, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 178 < 1065; dropping {'val_loss': tensor(0.2910, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 179 < 1065; dropping {'val_loss': tensor(0.2633, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 180 < 1065; dropping {'val_loss': tensor(0.3445, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 181 < 1065; dropping {'val_loss': tensor(0.3838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 182 < 1065; dropping {'val_loss': tensor(0.3914, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 183 < 1065; dropping {'val_loss': tensor(0.3683, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 184 < 1065; dropping {'val_loss': tensor(0.3271, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 185 < 1065; dropping {'val_loss': tensor(0.4003, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 186 < 1065; dropping {'val_loss': tensor(0.2018, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 187 < 1065; dropping {'val_loss': tensor(0.3739, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 188 < 1065; dropping {'val_loss': tensor(0.3796, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 189 < 1065; dropping {'val_loss': tensor(0.2210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 190 < 1065; dropping {'val_loss': tensor(0.4237, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 191 < 1065; dropping {'val_loss': tensor(0.2969, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 192 < 1065; dropping {'val_loss': tensor(0.3445, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 193 < 1065; dropping {'val_loss': tensor(0.2658, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 194 < 1065; dropping {'val_loss': tensor(0.3026, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 195 < 1065; dropping {'val_loss': tensor(0.1920, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 196 < 1065; dropping {'val_loss': tensor(0.4230, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 197 < 1065; dropping {'val_loss': tensor(0.2572, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 198 < 1065; dropping {'val_loss': tensor(0.5557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 199 < 1065; dropping {'val_loss': tensor(0.2090, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 200 < 1065; dropping {'val_loss': tensor(0.2988, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 201 < 1065; dropping {'val_loss': tensor(0.2646, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 202 < 1065; dropping {'val_loss': tensor(0.3103, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 203 < 1065; dropping {'val_loss': tensor(0.4909, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 204 < 1065; dropping {'val_loss': tensor(0.1983, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 205 < 1065; dropping {'val_loss': tensor(0.4091, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 206 < 1065; dropping {'val_loss': tensor(0.2567, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 207 < 1065; dropping {'val_loss': tensor(0.1097, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 208 < 1065; dropping {'val_loss': tensor(0.2699, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 209 < 1065; dropping {'val_loss': tensor(0.2718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 210 < 1065; dropping {'val_loss': tensor(0.2543, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 211 < 1065; dropping {'val_loss': tensor(0.4825, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 212 < 1065; dropping {'val_loss': tensor(0.2539, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 213 < 1065; dropping {'val_loss': tensor(0.3002, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 214 < 1065; dropping {'val_loss': tensor(0.4037, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 215 < 1065; dropping {'val_loss': tensor(0.1900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 216 < 1065; dropping {'val_loss': tensor(0.2671, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 217 < 1065; dropping {'val_loss': tensor(0.2171, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 218 < 1065; dropping {'val_loss': tensor(0.2818, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 219 < 1065; dropping {'val_loss': tensor(0.2865, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 220 < 1065; dropping {'val_loss': tensor(0.3250, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 221 < 1065; dropping {'val_loss': tensor(0.2387, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 222 < 1065; dropping {'val_loss': tensor(0.2338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 223 < 1065; dropping {'val_loss': tensor(0.2085, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 224 < 1065; dropping {'val_loss': tensor(0.3757, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 225 < 1065; dropping {'val_loss': tensor(0.1860, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 226 < 1065; dropping {'val_loss': tensor(0.1656, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 227 < 1065; dropping {'val_loss': tensor(0.3491, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 228 < 1065; dropping {'val_loss': tensor(0.5146, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 229 < 1065; dropping {'val_loss': tensor(0.2798, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 230 < 1065; dropping {'val_loss': tensor(0.3595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 231 < 1065; dropping {'val_loss': tensor(0.5551, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 232 < 1065; dropping {'val_loss': tensor(0.3128, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 233 < 1065; dropping {'val_loss': tensor(0.2904, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 234 < 1065; dropping {'val_loss': tensor(0.4007, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 235 < 1065; dropping {'val_loss': tensor(0.3813, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 236 < 1065; dropping {'val_loss': tensor(0.3103, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 237 < 1065; dropping {'val_loss': tensor(0.2927, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 238 < 1065; dropping {'val_loss': tensor(0.1891, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 239 < 1065; dropping {'val_loss': tensor(0.2029, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 240 < 1065; dropping {'val_loss': tensor(0.3363, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 241 < 1065; dropping {'val_loss': tensor(0.4358, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 242 < 1065; dropping {'val_loss': tensor(0.2563, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 243 < 1065; dropping {'val_loss': tensor(0.2496, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 244 < 1065; dropping {'val_loss': tensor(0.3289, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 0/60000             (0% | Loss: 0.221802
wandb: WARNING Step must only increase in log calls.  Step 245 < 1065; dropping {'val_loss': tensor(0.3166, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 246 < 1065; dropping {'val_loss': tensor(0.2021, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 247 < 1065; dropping {'val_loss': tensor(0.3098, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 248 < 1065; dropping {'val_loss': tensor(0.2566, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 249 < 1065; dropping {'val_loss': tensor(0.2759, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 250 < 1065; dropping {'val_loss': tensor(0.2402, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 251 < 1065; dropping {'val_loss': tensor(0.3949, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 252 < 1065; dropping {'val_loss': tensor(0.2280, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 253 < 1065; dropping {'val_loss': tensor(0.2761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 254 < 1065; dropping {'val_loss': tensor(0.3367, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 255 < 1065; dropping {'val_loss': tensor(0.2819, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 256 < 1065; dropping {'val_loss': tensor(0.4544, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 257 < 1065; dropping {'val_loss': tensor(0.2893, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 258 < 1065; dropping {'val_loss': tensor(0.2546, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 259 < 1065; dropping {'val_loss': tensor(0.3414, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 260 < 1065; dropping {'val_loss': tensor(0.4335, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 261 < 1065; dropping {'val_loss': tensor(0.2249, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 262 < 1065; dropping {'val_loss': tensor(0.2686, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 263 < 1065; dropping {'val_loss': tensor(0.5121, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 264 < 1065; dropping {'val_loss': tensor(0.2104, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 265 < 1065; dropping {'val_loss': tensor(0.5186, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 266 < 1065; dropping {'val_loss': tensor(0.4427, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 267 < 1065; dropping {'val_loss': tensor(0.3743, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 268 < 1065; dropping {'val_loss': tensor(0.4421, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 269 < 1065; dropping {'val_loss': tensor(0.2488, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 270 < 1065; dropping {'val_loss': tensor(0.2306, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 271 < 1065; dropping {'val_loss': tensor(0.3828, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 272 < 1065; dropping {'val_loss': tensor(0.4725, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 273 < 1065; dropping {'val_loss': tensor(0.2781, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 274 < 1065; dropping {'val_loss': tensor(0.3711, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 275 < 1065; dropping {'val_loss': tensor(0.4710, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 276 < 1065; dropping {'val_loss': tensor(0.2779, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 277 < 1065; dropping {'val_loss': tensor(0.3761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 278 < 1065; dropping {'val_loss': tensor(0.3195, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 279 < 1065; dropping {'val_loss': tensor(0.2221, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 280 < 1065; dropping {'val_loss': tensor(0.4077, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 281 < 1065; dropping {'val_loss': tensor(0.2922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 282 < 1065; dropping {'val_loss': tensor(0.3965, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 283 < 1065; dropping {'val_loss': tensor(0.3248, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 284 < 1065; dropping {'val_loss': tensor(0.1546, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 192 < 1065; dropping {'train_loss': tensor(0.2218, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 193 < 1065; dropping {'train_loss': tensor(0.2542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 194 < 1065; dropping {'train_loss': tensor(0.2253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 195 < 1065; dropping {'train_loss': tensor(0.2387, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 196 < 1065; dropping {'train_loss': tensor(0.2255, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 197 < 1065; dropping {'train_loss': tensor(0.2683, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 198 < 1065; dropping {'train_loss': tensor(0.4277, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 199 < 1065; dropping {'train_loss': tensor(0.1985, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 200 < 1065; dropping {'train_loss': tensor(0.3731, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 201 < 1065; dropping {'train_loss': tensor(0.3045, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 202 < 1065; dropping {'train_loss': tensor(0.3342, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 203 < 1065; dropping {'train_loss': tensor(0.3266, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 204 < 1065; dropping {'train_loss': tensor(0.2591, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 205 < 1065; dropping {'train_loss': tensor(0.3360, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 206 < 1065; dropping {'train_loss': tensor(0.4234, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 207 < 1065; dropping {'train_loss': tensor(0.2841, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 208 < 1065; dropping {'train_loss': tensor(0.2948, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 209 < 1065; dropping {'train_loss': tensor(0.2922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 210 < 1065; dropping {'train_loss': tensor(0.3547, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 211 < 1065; dropping {'train_loss': tensor(0.2217, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 212 < 1065; dropping {'train_loss': tensor(0.1119, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 213 < 1065; dropping {'train_loss': tensor(0.2364, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 214 < 1065; dropping {'train_loss': tensor(0.3319, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 215 < 1065; dropping {'train_loss': tensor(0.4119, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 216 < 1065; dropping {'train_loss': tensor(0.2521, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 217 < 1065; dropping {'train_loss': tensor(0.3253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 218 < 1065; dropping {'train_loss': tensor(0.4000, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 219 < 1065; dropping {'train_loss': tensor(0.2918, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 220 < 1065; dropping {'train_loss': tensor(0.3677, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 221 < 1065; dropping {'train_loss': tensor(0.2740, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 222 < 1065; dropping {'train_loss': tensor(0.2330, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 223 < 1065; dropping {'train_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 224 < 1065; dropping {'train_loss': tensor(0.1859, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 225 < 1065; dropping {'train_loss': tensor(0.2284, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 226 < 1065; dropping {'train_loss': tensor(0.2428, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 227 < 1065; dropping {'train_loss': tensor(0.4538, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 228 < 1065; dropping {'train_loss': tensor(0.3285, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 229 < 1065; dropping {'train_loss': tensor(0.3253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 230 < 1065; dropping {'train_loss': tensor(0.2615, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 231 < 1065; dropping {'train_loss': tensor(0.3629, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 232 < 1065; dropping {'train_loss': tensor(0.1197, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 6400/60000             (11% | Loss: 0.265096
wandb: WARNING Step must only increase in log calls.  Step 233 < 1065; dropping {'train_loss': tensor(0.1600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 234 < 1065; dropping {'train_loss': tensor(0.2579, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 235 < 1065; dropping {'train_loss': tensor(0.2176, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 236 < 1065; dropping {'train_loss': tensor(0.2530, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 237 < 1065; dropping {'train_loss': tensor(0.3181, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 238 < 1065; dropping {'train_loss': tensor(0.4000, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 239 < 1065; dropping {'train_loss': tensor(0.3076, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 240 < 1065; dropping {'train_loss': tensor(0.3249, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 241 < 1065; dropping {'train_loss': tensor(0.2562, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 242 < 1065; dropping {'train_loss': tensor(0.2242, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 243 < 1065; dropping {'train_loss': tensor(0.1508, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 244 < 1065; dropping {'train_loss': tensor(0.3938, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 245 < 1065; dropping {'train_loss': tensor(0.1931, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 246 < 1065; dropping {'train_loss': tensor(0.3702, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 247 < 1065; dropping {'train_loss': tensor(0.2856, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 248 < 1065; dropping {'train_loss': tensor(0.3718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 249 < 1065; dropping {'train_loss': tensor(0.2310, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 250 < 1065; dropping {'train_loss': tensor(0.2938, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 251 < 1065; dropping {'train_loss': tensor(0.2179, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 252 < 1065; dropping {'train_loss': tensor(0.1888, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 253 < 1065; dropping {'train_loss': tensor(0.2219, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 254 < 1065; dropping {'train_loss': tensor(0.2573, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 255 < 1065; dropping {'train_loss': tensor(0.1858, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 256 < 1065; dropping {'train_loss': tensor(0.2165, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 257 < 1065; dropping {'train_loss': tensor(0.1561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 258 < 1065; dropping {'train_loss': tensor(0.4277, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 259 < 1065; dropping {'train_loss': tensor(0.1716, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 260 < 1065; dropping {'train_loss': tensor(0.1853, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 261 < 1065; dropping {'train_loss': tensor(0.3702, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 262 < 1065; dropping {'train_loss': tensor(0.2665, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 263 < 1065; dropping {'train_loss': tensor(0.2197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 264 < 1065; dropping {'train_loss': tensor(0.2570, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 265 < 1065; dropping {'train_loss': tensor(0.3437, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 266 < 1065; dropping {'train_loss': tensor(0.1115, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 267 < 1065; dropping {'train_loss': tensor(0.3711, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 268 < 1065; dropping {'train_loss': tensor(0.2922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 269 < 1065; dropping {'train_loss': tensor(0.2584, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 270 < 1065; dropping {'train_loss': tensor(0.4383, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 271 < 1065; dropping {'train_loss': tensor(0.3181, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 272 < 1065; dropping {'train_loss': tensor(0.2959, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 273 < 1065; dropping {'train_loss': tensor(0.1877, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 274 < 1065; dropping {'train_loss': tensor(0.4080, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 275 < 1065; dropping {'train_loss': tensor(0.1475, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 276 < 1065; dropping {'train_loss': tensor(0.1213, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 277 < 1065; dropping {'train_loss': tensor(0.2907, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 278 < 1065; dropping {'train_loss': tensor(0.3654, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 279 < 1065; dropping {'train_loss': tensor(0.4439, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 280 < 1065; dropping {'train_loss': tensor(0.4009, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 281 < 1065; dropping {'train_loss': tensor(0.3759, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 282 < 1065; dropping {'train_loss': tensor(0.2435, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 283 < 1065; dropping {'train_loss': tensor(0.3612, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 284 < 1065; dropping {'train_loss': tensor(0.3406, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 285 < 1065; dropping {'train_loss': tensor(0.1189, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 286 < 1065; dropping {'train_loss': tensor(0.2341, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 287 < 1065; dropping {'train_loss': tensor(0.1900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 288 < 1065; dropping {'train_loss': tensor(0.2228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 289 < 1065; dropping {'train_loss': tensor(0.3059, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 290 < 1065; dropping {'train_loss': tensor(0.3266, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 291 < 1065; dropping {'train_loss': tensor(0.2205, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 292 < 1065; dropping {'train_loss': tensor(0.2651, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 293 < 1065; dropping {'train_loss': tensor(0.3021, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 294 < 1065; dropping {'train_loss': tensor(0.2259, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 295 < 1065; dropping {'train_loss': tensor(0.2692, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 296 < 1065; dropping {'train_loss': tensor(0.2980, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 297 < 1065; dropping {'train_loss': tensor(0.1859, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 298 < 1065; dropping {'train_loss': tensor(0.1809, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 299 < 1065; dropping {'train_loss': tensor(0.1855, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 300 < 1065; dropping {'train_loss': tensor(0.2554, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 301 < 1065; dropping {'train_loss': tensor(0.2561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 302 < 1065; dropping {'train_loss': tensor(0.2238, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 303 < 1065; dropping {'train_loss': tensor(0.2595, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 304 < 1065; dropping {'train_loss': tensor(0.3399, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 305 < 1065; dropping {'train_loss': tensor(0.3902, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 306 < 1065; dropping {'train_loss': tensor(0.2562, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 307 < 1065; dropping {'train_loss': tensor(0.2096, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 308 < 1065; dropping {'train_loss': tensor(0.2530, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 309 < 1065; dropping {'train_loss': tensor(0.0747, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 310 < 1065; dropping {'train_loss': tensor(0.3452, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 311 < 1065; dropping {'train_loss': tensor(0.3279, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 312 < 1065; dropping {'train_loss': tensor(0.2286, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 313 < 1065; dropping {'train_loss': tensor(0.2079, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 314 < 1065; dropping {'train_loss': tensor(0.4207, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 315 < 1065; dropping {'train_loss': tensor(0.2582, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 316 < 1065; dropping {'train_loss': tensor(0.2736, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 317 < 1065; dropping {'train_loss': tensor(0.3209, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 318 < 1065; dropping {'train_loss': tensor(0.2075, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 319 < 1065; dropping {'train_loss': tensor(0.2203, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 320 < 1065; dropping {'train_loss': tensor(0.2545, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 321 < 1065; dropping {'train_loss': tensor(0.2536, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 322 < 1065; dropping {'train_loss': tensor(0.1791, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 323 < 1065; dropping {'train_loss': tensor(0.3298, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 324 < 1065; dropping {'train_loss': tensor(0.3826, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 325 < 1065; dropping {'train_loss': tensor(0.3036, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 326 < 1065; dropping {'train_loss': tensor(0.3624, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 327 < 1065; dropping {'train_loss': tensor(0.2905, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 328 < 1065; dropping {'train_loss': tensor(0.1876, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 329 < 1065; dropping {'train_loss': tensor(0.2815, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 330 < 1065; dropping {'train_loss': tensor(0.1270, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 331 < 1065; dropping {'train_loss': tensor(0.2237, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 332 < 1065; dropping {'train_loss': tensor(0.2535, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 333 < 1065; dropping {'train_loss': tensor(0.2880, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 334 < 1065; dropping {'train_loss': tensor(0.1280, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 335 < 1065; dropping {'train_loss': tensor(0.3134, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 336 < 1065; dropping {'train_loss': tensor(0.2365, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 337 < 1065; dropping {'train_loss': tensor(0.0832, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 338 < 1065; dropping {'train_loss': tensor(0.4414, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 339 < 1065; dropping {'train_loss': tensor(0.2678, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 340 < 1065; dropping {'train_loss': tensor(0.2904, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 341 < 1065; dropping {'train_loss': tensor(0.3623, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 342 < 1065; dropping {'train_loss': tensor(0.2548, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 343 < 1065; dropping {'train_loss': tensor(0.1226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 344 < 1065; dropping {'train_loss': tensor(0.3670, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 345 < 1065; dropping {'train_loss': tensor(0.2645, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 346 < 1065; dropping {'train_loss': tensor(0.2026, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 347 < 1065; dropping {'train_loss': tensor(0.2358, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 348 < 1065; dropping {'train_loss': tensor(0.4072, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 349 < 1065; dropping {'train_loss': tensor(0.2183, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 350 < 1065; dropping {'train_loss': tensor(0.2944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 351 < 1065; dropping {'train_loss': tensor(0.1820, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 352 < 1065; dropping {'train_loss': tensor(0.1475, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 353 < 1065; dropping {'train_loss': tensor(0.3693, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 354 < 1065; dropping {'train_loss': tensor(0.2550, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 355 < 1065; dropping {'train_loss': tensor(0.2212, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 356 < 1065; dropping {'train_loss': tensor(0.3123, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 357 < 1065; dropping {'train_loss': tensor(0.1266, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 358 < 1065; dropping {'train_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 359 < 1065; dropping {'train_loss': tensor(0.5482, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 360 < 1065; dropping {'train_loss': tensor(0.0746, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 361 < 1065; dropping {'train_loss': tensor(0.2572, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 362 < 1065; dropping {'train_loss': tensor(0.2896, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 363 < 1065; dropping {'train_loss': tensor(0.2107, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 364 < 1065; dropping {'train_loss': tensor(0.1545, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 365 < 1065; dropping {'train_loss': tensor(0.1814, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 366 < 1065; dropping {'train_loss': tensor(0.2003, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 367 < 1065; dropping {'train_loss': tensor(0.1974, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 368 < 1065; dropping {'train_loss': tensor(0.3425, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 369 < 1065; dropping {'train_loss': tensor(0.2221, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 370 < 1065; dropping {'train_loss': tensor(0.2559, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 371 < 1065; dropping {'train_loss': tensor(0.3611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 372 < 1065; dropping {'train_loss': tensor(0.2959, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 12800/60000             (21% | Loss: 0.254177
wandb: WARNING Step must only increase in log calls.  Step 373 < 1065; dropping {'train_loss': tensor(0.2191, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 374 < 1065; dropping {'train_loss': tensor(0.1860, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 375 < 1065; dropping {'train_loss': tensor(0.2102, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 376 < 1065; dropping {'train_loss': tensor(0.2244, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 377 < 1065; dropping {'train_loss': tensor(0.2577, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 378 < 1065; dropping {'train_loss': tensor(0.3043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 379 < 1065; dropping {'train_loss': tensor(0.2306, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 380 < 1065; dropping {'train_loss': tensor(0.1490, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 381 < 1065; dropping {'train_loss': tensor(0.3931, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 382 < 1065; dropping {'train_loss': tensor(0.3276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 383 < 1065; dropping {'train_loss': tensor(0.3225, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 384 < 1065; dropping {'train_loss': tensor(0.1532, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 385 < 1065; dropping {'train_loss': tensor(0.2964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 386 < 1065; dropping {'train_loss': tensor(0.1859, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 387 < 1065; dropping {'train_loss': tensor(0.1097, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 388 < 1065; dropping {'train_loss': tensor(0.3635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 389 < 1065; dropping {'train_loss': tensor(0.2165, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 390 < 1065; dropping {'train_loss': tensor(0.4018, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 391 < 1065; dropping {'train_loss': tensor(0.1944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 392 < 1065; dropping {'train_loss': tensor(0.2542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 393 < 1065; dropping {'train_loss': tensor(0.2607, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 394 < 1065; dropping {'train_loss': tensor(0.3314, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 395 < 1065; dropping {'train_loss': tensor(0.2215, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 396 < 1065; dropping {'train_loss': tensor(0.2215, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 397 < 1065; dropping {'train_loss': tensor(0.1602, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 398 < 1065; dropping {'train_loss': tensor(0.4349, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 399 < 1065; dropping {'train_loss': tensor(0.3819, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 400 < 1065; dropping {'train_loss': tensor(0.3636, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 401 < 1065; dropping {'train_loss': tensor(0.2600, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 402 < 1065; dropping {'train_loss': tensor(0.2543, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 403 < 1065; dropping {'train_loss': tensor(0.2589, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 404 < 1065; dropping {'train_loss': tensor(0.3893, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 405 < 1065; dropping {'train_loss': tensor(0.3096, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 406 < 1065; dropping {'train_loss': tensor(0.4073, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 407 < 1065; dropping {'train_loss': tensor(0.4283, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 408 < 1065; dropping {'train_loss': tensor(0.3074, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 409 < 1065; dropping {'train_loss': tensor(0.2299, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 410 < 1065; dropping {'train_loss': tensor(0.1513, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 411 < 1065; dropping {'train_loss': tensor(0.1392, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 412 < 1065; dropping {'train_loss': tensor(0.2561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 413 < 1065; dropping {'train_loss': tensor(0.4181, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 414 < 1065; dropping {'train_loss': tensor(0.3229, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 415 < 1065; dropping {'train_loss': tensor(0.3992, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 416 < 1065; dropping {'train_loss': tensor(0.4023, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 417 < 1065; dropping {'train_loss': tensor(0.3402, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 418 < 1065; dropping {'train_loss': tensor(0.1954, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 419 < 1065; dropping {'train_loss': tensor(0.2822, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 420 < 1065; dropping {'train_loss': tensor(0.2888, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 421 < 1065; dropping {'train_loss': tensor(0.2655, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 422 < 1065; dropping {'train_loss': tensor(0.2660, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 423 < 1065; dropping {'train_loss': tensor(0.2530, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 424 < 1065; dropping {'train_loss': tensor(0.3973, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 425 < 1065; dropping {'train_loss': tensor(0.3083, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 426 < 1065; dropping {'train_loss': tensor(0.4078, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 427 < 1065; dropping {'train_loss': tensor(0.4545, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 428 < 1065; dropping {'train_loss': tensor(0.3074, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 429 < 1065; dropping {'train_loss': tensor(0.3257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 430 < 1065; dropping {'train_loss': tensor(0.2182, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 431 < 1065; dropping {'train_loss': tensor(0.1933, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 432 < 1065; dropping {'train_loss': tensor(0.1887, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 433 < 1065; dropping {'train_loss': tensor(0.2425, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 434 < 1065; dropping {'train_loss': tensor(0.1626, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 435 < 1065; dropping {'train_loss': tensor(0.2564, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 436 < 1065; dropping {'train_loss': tensor(0.2528, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 437 < 1065; dropping {'train_loss': tensor(0.1131, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 438 < 1065; dropping {'train_loss': tensor(0.3210, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 439 < 1065; dropping {'train_loss': tensor(0.0836, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 440 < 1065; dropping {'train_loss': tensor(0.2739, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 441 < 1065; dropping {'train_loss': tensor(0.2743, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 442 < 1065; dropping {'train_loss': tensor(0.2593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 443 < 1065; dropping {'train_loss': tensor(0.1126, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 444 < 1065; dropping {'train_loss': tensor(0.1901, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 19200/60000             (32% | Loss: 0.301796
wandb: WARNING Step must only increase in log calls.  Step 445 < 1065; dropping {'train_loss': tensor(0.2808, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 446 < 1065; dropping {'train_loss': tensor(0.4474, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 447 < 1065; dropping {'train_loss': tensor(0.3537, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 448 < 1065; dropping {'train_loss': tensor(0.2751, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 449 < 1065; dropping {'train_loss': tensor(0.2407, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 450 < 1065; dropping {'train_loss': tensor(0.2971, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 451 < 1065; dropping {'train_loss': tensor(0.4738, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 452 < 1065; dropping {'train_loss': tensor(0.4607, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 453 < 1065; dropping {'train_loss': tensor(0.4253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 454 < 1065; dropping {'train_loss': tensor(0.3402, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 455 < 1065; dropping {'train_loss': tensor(0.1265, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 456 < 1065; dropping {'train_loss': tensor(0.3865, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 457 < 1065; dropping {'train_loss': tensor(0.2500, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 458 < 1065; dropping {'train_loss': tensor(0.3119, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 459 < 1065; dropping {'train_loss': tensor(0.2127, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 460 < 1065; dropping {'train_loss': tensor(0.2539, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 461 < 1065; dropping {'train_loss': tensor(0.4008, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 462 < 1065; dropping {'train_loss': tensor(0.2935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 463 < 1065; dropping {'train_loss': tensor(0.3312, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 464 < 1065; dropping {'train_loss': tensor(0.2611, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 465 < 1065; dropping {'train_loss': tensor(0.2283, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 466 < 1065; dropping {'train_loss': tensor(0.3341, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 467 < 1065; dropping {'train_loss': tensor(0.2612, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 468 < 1065; dropping {'train_loss': tensor(0.3129, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 469 < 1065; dropping {'train_loss': tensor(0.2653, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 470 < 1065; dropping {'train_loss': tensor(0.3265, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 471 < 1065; dropping {'train_loss': tensor(0.0803, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 472 < 1065; dropping {'train_loss': tensor(0.2570, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 473 < 1065; dropping {'train_loss': tensor(0.1889, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 474 < 1065; dropping {'train_loss': tensor(0.1510, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 475 < 1065; dropping {'train_loss': tensor(0.2607, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 476 < 1065; dropping {'train_loss': tensor(0.3237, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 477 < 1065; dropping {'train_loss': tensor(0.0941, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 478 < 1065; dropping {'train_loss': tensor(0.4048, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 479 < 1065; dropping {'train_loss': tensor(0.3542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 480 < 1065; dropping {'train_loss': tensor(0.2285, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 481 < 1065; dropping {'train_loss': tensor(0.4088, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 482 < 1065; dropping {'train_loss': tensor(0.2910, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 483 < 1065; dropping {'train_loss': tensor(0.3491, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 484 < 1065; dropping {'train_loss': tensor(0.2656, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 485 < 1065; dropping {'train_loss': tensor(0.1960, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 486 < 1065; dropping {'train_loss': tensor(0.2281, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 487 < 1065; dropping {'train_loss': tensor(0.3719, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 488 < 1065; dropping {'train_loss': tensor(0.3104, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 489 < 1065; dropping {'train_loss': tensor(0.3291, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 490 < 1065; dropping {'train_loss': tensor(0.2812, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 491 < 1065; dropping {'train_loss': tensor(0.3716, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 492 < 1065; dropping {'train_loss': tensor(0.3018, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 493 < 1065; dropping {'train_loss': tensor(0.3046, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 494 < 1065; dropping {'train_loss': tensor(0.3095, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 495 < 1065; dropping {'train_loss': tensor(0.2350, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 496 < 1065; dropping {'train_loss': tensor(0.1123, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 497 < 1065; dropping {'train_loss': tensor(0.3355, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 498 < 1065; dropping {'train_loss': tensor(0.4164, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 499 < 1065; dropping {'train_loss': tensor(0.3195, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 500 < 1065; dropping {'train_loss': tensor(0.4387, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 501 < 1065; dropping {'train_loss': tensor(0.3785, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 502 < 1065; dropping {'train_loss': tensor(0.3297, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 503 < 1065; dropping {'train_loss': tensor(0.1464, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 504 < 1065; dropping {'train_loss': tensor(0.3014, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 505 < 1065; dropping {'train_loss': tensor(0.3459, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 506 < 1065; dropping {'train_loss': tensor(0.1343, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 507 < 1065; dropping {'train_loss': tensor(0.3277, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 508 < 1065; dropping {'train_loss': tensor(0.3989, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 509 < 1065; dropping {'train_loss': tensor(0.1145, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 510 < 1065; dropping {'train_loss': tensor(0.3342, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 512 < 1065; dropping {'train_loss': tensor(0.4754, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 513 < 1065; dropping {'train_loss': tensor(0.3006, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 514 < 1065; dropping {'train_loss': tensor(0.1619, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 515 < 1065; dropping {'train_loss': tensor(0.3416, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 516 < 1065; dropping {'train_loss': tensor(0.1708, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 517 < 1065; dropping {'train_loss': tensor(0.3114, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 518 < 1065; dropping {'train_loss': tensor(0.4253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 519 < 1065; dropping {'train_loss': tensor(0.3058, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 520 < 1065; dropping {'train_loss': tensor(0.2217, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 521 < 1065; dropping {'train_loss': tensor(0.1520, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 522 < 1065; dropping {'train_loss': tensor(0.3258, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 523 < 1065; dropping {'train_loss': tensor(0.2561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 524 < 1065; dropping {'train_loss': tensor(0.2568, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 525 < 1065; dropping {'train_loss': tensor(0.3122, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 526 < 1065; dropping {'train_loss': tensor(0.3382, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 527 < 1065; dropping {'train_loss': tensor(0.2471, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 528 < 1065; dropping {'train_loss': tensor(0.2615, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 529 < 1065; dropping {'train_loss': tensor(0.2086, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 530 < 1065; dropping {'train_loss': tensor(0.1737, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 531 < 1065; dropping {'train_loss': tensor(0.2228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 532 < 1065; dropping {'train_loss': tensor(0.3285, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 533 < 1065; dropping {'train_loss': tensor(0.4337, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 534 < 1065; dropping {'train_loss': tensor(0.2901, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 535 < 1065; dropping {'train_loss': tensor(0.3269, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 536 < 1065; dropping {'train_loss': tensor(0.3133, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 537 < 1065; dropping {'train_loss': tensor(0.4391, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 538 < 1065; dropping {'train_loss': tensor(0.2800, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 539 < 1065; dropping {'train_loss': tensor(0.3099, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 540 < 1065; dropping {'train_loss': tensor(0.3220, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 541 < 1065; dropping {'train_loss': tensor(0.2690, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 542 < 1065; dropping {'train_loss': tensor(0.4116, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 543 < 1065; dropping {'train_loss': tensor(0.2558, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 544 < 1065; dropping {'train_loss': tensor(0.2225, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 545 < 1065; dropping {'train_loss': tensor(0.1174, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 546 < 1065; dropping {'train_loss': tensor(0.1511, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 547 < 1065; dropping {'train_loss': tensor(0.3793, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 548 < 1065; dropping {'train_loss': tensor(0.3403, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 549 < 1065; dropping {'train_loss': tensor(0.4426, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 550 < 1065; dropping {'train_loss': tensor(0.4756, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 551 < 1065; dropping {'train_loss': tensor(0.3259, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 552 < 1065; dropping {'train_loss': tensor(0.4344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 553 < 1065; dropping {'train_loss': tensor(0.3107, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 554 < 1065; dropping {'train_loss': tensor(0.2949, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 555 < 1065; dropping {'train_loss': tensor(0.2728, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 556 < 1065; dropping {'train_loss': tensor(0.3276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 557 < 1065; dropping {'train_loss': tensor(0.2577, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 558 < 1065; dropping {'train_loss': tensor(0.2045, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 559 < 1065; dropping {'train_loss': tensor(0.4718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 560 < 1065; dropping {'train_loss': tensor(0.2778, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 561 < 1065; dropping {'train_loss': tensor(0.2635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 562 < 1065; dropping {'train_loss': tensor(0.2935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 563 < 1065; dropping {'train_loss': tensor(0.2887, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 564 < 1065; dropping {'train_loss': tensor(0.4043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 565 < 1065; dropping {'train_loss': tensor(0.2009, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 566 < 1065; dropping {'train_loss': tensor(0.3092, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 567 < 1065; dropping {'train_loss': tensor(0.2207, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 568 < 1065; dropping {'train_loss': tensor(0.3592, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 569 < 1065; dropping {'train_loss': tensor(0.3691, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 570 < 1065; dropping {'train_loss': tensor(0.2246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 571 < 1065; dropping {'train_loss': tensor(0.3332, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 572 < 1065; dropping {'train_loss': tensor(0.3269, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 573 < 1065; dropping {'train_loss': tensor(0.2248, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 574 < 1065; dropping {'train_loss': tensor(0.2570, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 575 < 1065; dropping {'train_loss': tensor(0.3028, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 576 < 1065; dropping {'train_loss': tensor(0.2448, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 25600/60000             (43% | Loss: 0.306399
wandb: WARNING Step must only increase in log calls.  Step 577 < 1065; dropping {'train_loss': tensor(0.1746, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 578 < 1065; dropping {'train_loss': tensor(0.0411, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 579 < 1065; dropping {'train_loss': tensor(0.2245, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 580 < 1065; dropping {'train_loss': tensor(0.3633, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 581 < 1065; dropping {'train_loss': tensor(0.2552, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 582 < 1065; dropping {'train_loss': tensor(0.3380, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 583 < 1065; dropping {'train_loss': tensor(0.4239, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 584 < 1065; dropping {'train_loss': tensor(0.2275, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 585 < 1065; dropping {'train_loss': tensor(0.1829, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 586 < 1065; dropping {'train_loss': tensor(0.2982, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 587 < 1065; dropping {'train_loss': tensor(0.3812, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 588 < 1065; dropping {'train_loss': tensor(0.2285, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 589 < 1065; dropping {'train_loss': tensor(0.3448, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 590 < 1065; dropping {'train_loss': tensor(0.2172, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 591 < 1065; dropping {'train_loss': tensor(0.2418, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 592 < 1065; dropping {'train_loss': tensor(0.3064, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 593 < 1065; dropping {'train_loss': tensor(0.1835, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 594 < 1065; dropping {'train_loss': tensor(0.3344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 595 < 1065; dropping {'train_loss': tensor(0.2190, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 596 < 1065; dropping {'train_loss': tensor(0.2584, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 597 < 1065; dropping {'train_loss': tensor(0.4022, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 598 < 1065; dropping {'train_loss': tensor(0.2635, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 599 < 1065; dropping {'train_loss': tensor(0.1814, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 600 < 1065; dropping {'train_loss': tensor(0.2328, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 601 < 1065; dropping {'train_loss': tensor(0.2236, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 602 < 1065; dropping {'train_loss': tensor(0.1256, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 603 < 1065; dropping {'train_loss': tensor(0.1598, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 604 < 1065; dropping {'train_loss': tensor(0.3246, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 605 < 1065; dropping {'train_loss': tensor(0.2561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 606 < 1065; dropping {'train_loss': tensor(0.1853, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 607 < 1065; dropping {'train_loss': tensor(0.5037, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 608 < 1065; dropping {'train_loss': tensor(0.3774, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 609 < 1065; dropping {'train_loss': tensor(0.2914, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 610 < 1065; dropping {'train_loss': tensor(0.2243, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 611 < 1065; dropping {'train_loss': tensor(0.3278, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 612 < 1065; dropping {'train_loss': tensor(0.4199, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 613 < 1065; dropping {'train_loss': tensor(0.1305, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 614 < 1065; dropping {'train_loss': tensor(0.3446, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 615 < 1065; dropping {'train_loss': tensor(0.3204, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 616 < 1065; dropping {'train_loss': tensor(0.3249, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 617 < 1065; dropping {'train_loss': tensor(0.4435, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 618 < 1065; dropping {'train_loss': tensor(0.2379, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 619 < 1065; dropping {'train_loss': tensor(0.3526, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 620 < 1065; dropping {'train_loss': tensor(0.2810, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 621 < 1065; dropping {'train_loss': tensor(0.2745, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 622 < 1065; dropping {'train_loss': tensor(0.2930, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 623 < 1065; dropping {'train_loss': tensor(0.4331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 624 < 1065; dropping {'train_loss': tensor(0.1155, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 625 < 1065; dropping {'train_loss': tensor(0.3681, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 626 < 1065; dropping {'train_loss': tensor(0.3042, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 627 < 1065; dropping {'train_loss': tensor(0.1696, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 628 < 1065; dropping {'train_loss': tensor(0.2903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 629 < 1065; dropping {'train_loss': tensor(0.4542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 630 < 1065; dropping {'train_loss': tensor(0.2884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 631 < 1065; dropping {'train_loss': tensor(0.2928, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 632 < 1065; dropping {'train_loss': tensor(0.3661, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 633 < 1065; dropping {'train_loss': tensor(0.2235, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 634 < 1065; dropping {'train_loss': tensor(0.5979, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 635 < 1065; dropping {'train_loss': tensor(0.3722, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 636 < 1065; dropping {'train_loss': tensor(0.3986, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 637 < 1065; dropping {'train_loss': tensor(0.4537, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 638 < 1065; dropping {'train_loss': tensor(0.1831, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 639 < 1065; dropping {'train_loss': tensor(0.1811, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 640 < 1065; dropping {'train_loss': tensor(0.3296, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 641 < 1065; dropping {'train_loss': tensor(0.2776, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 642 < 1065; dropping {'train_loss': tensor(0.1996, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 643 < 1065; dropping {'train_loss': tensor(0.4199, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 644 < 1065; dropping {'train_loss': tensor(0.0758, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 645 < 1065; dropping {'train_loss': tensor(0.2544, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 646 < 1065; dropping {'train_loss': tensor(0.1524, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 647 < 1065; dropping {'train_loss': tensor(0.3787, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 648 < 1065; dropping {'train_loss': tensor(0.4987, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 649 < 1065; dropping {'train_loss': tensor(0.3660, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 32000/60000             (53% | Loss: 0.075389
wandb: WARNING Step must only increase in log calls.  Step 650 < 1065; dropping {'train_loss': tensor(0.1637, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 651 < 1065; dropping {'train_loss': tensor(0.2313, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 652 < 1065; dropping {'train_loss': tensor(0.1874, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 653 < 1065; dropping {'train_loss': tensor(0.2234, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 654 < 1065; dropping {'train_loss': tensor(0.2278, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 655 < 1065; dropping {'train_loss': tensor(0.1881, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 656 < 1065; dropping {'train_loss': tensor(0.4048, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 657 < 1065; dropping {'train_loss': tensor(0.2548, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 658 < 1065; dropping {'train_loss': tensor(0.3297, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 659 < 1065; dropping {'train_loss': tensor(0.2592, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 660 < 1065; dropping {'train_loss': tensor(0.3454, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 661 < 1065; dropping {'train_loss': tensor(0.3498, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 662 < 1065; dropping {'train_loss': tensor(0.4301, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 663 < 1065; dropping {'train_loss': tensor(0.2243, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 664 < 1065; dropping {'train_loss': tensor(0.2372, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 665 < 1065; dropping {'train_loss': tensor(0.2668, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 666 < 1065; dropping {'train_loss': tensor(0.5212, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 667 < 1065; dropping {'train_loss': tensor(0.2048, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 668 < 1065; dropping {'train_loss': tensor(0.3203, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 669 < 1065; dropping {'train_loss': tensor(0.3872, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 670 < 1065; dropping {'train_loss': tensor(0.2480, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 671 < 1065; dropping {'train_loss': tensor(0.4521, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 672 < 1065; dropping {'train_loss': tensor(0.2007, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 673 < 1065; dropping {'train_loss': tensor(0.3524, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 674 < 1065; dropping {'train_loss': tensor(0.4521, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 675 < 1065; dropping {'train_loss': tensor(0.2935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 676 < 1065; dropping {'train_loss': tensor(0.2056, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 677 < 1065; dropping {'train_loss': tensor(0.3317, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 678 < 1065; dropping {'train_loss': tensor(0.3689, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 679 < 1065; dropping {'train_loss': tensor(0.2006, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 680 < 1065; dropping {'train_loss': tensor(0.2727, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 681 < 1065; dropping {'train_loss': tensor(0.3034, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 682 < 1065; dropping {'train_loss': tensor(0.2422, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 683 < 1065; dropping {'train_loss': tensor(0.2417, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 684 < 1065; dropping {'train_loss': tensor(0.3432, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 685 < 1065; dropping {'train_loss': tensor(0.3323, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 686 < 1065; dropping {'train_loss': tensor(0.4868, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 687 < 1065; dropping {'train_loss': tensor(0.1900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 688 < 1065; dropping {'train_loss': tensor(0.2769, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 689 < 1065; dropping {'train_loss': tensor(0.3626, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 690 < 1065; dropping {'train_loss': tensor(0.5245, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 691 < 1065; dropping {'train_loss': tensor(0.3892, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 692 < 1065; dropping {'train_loss': tensor(0.0754, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 693 < 1065; dropping {'train_loss': tensor(0.3137, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 694 < 1065; dropping {'train_loss': tensor(0.0805, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 695 < 1065; dropping {'train_loss': tensor(0.2837, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 696 < 1065; dropping {'train_loss': tensor(0.2922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 697 < 1065; dropping {'train_loss': tensor(0.2342, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 698 < 1065; dropping {'train_loss': tensor(0.2900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 699 < 1065; dropping {'train_loss': tensor(0.3809, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 700 < 1065; dropping {'train_loss': tensor(0.3963, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 701 < 1065; dropping {'train_loss': tensor(0.3654, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 702 < 1065; dropping {'train_loss': tensor(0.3300, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 703 < 1065; dropping {'train_loss': tensor(0.2731, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 704 < 1065; dropping {'train_loss': tensor(0.0803, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 705 < 1065; dropping {'train_loss': tensor(0.2360, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 706 < 1065; dropping {'train_loss': tensor(0.3268, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 707 < 1065; dropping {'train_loss': tensor(0.2332, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 708 < 1065; dropping {'train_loss': tensor(0.3645, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 709 < 1065; dropping {'train_loss': tensor(0.2405, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 710 < 1065; dropping {'train_loss': tensor(0.2576, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 711 < 1065; dropping {'train_loss': tensor(0.3451, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 712 < 1065; dropping {'train_loss': tensor(0.2345, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 713 < 1065; dropping {'train_loss': tensor(0.3989, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 714 < 1065; dropping {'train_loss': tensor(0.3714, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 715 < 1065; dropping {'train_loss': tensor(0.2378, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 716 < 1065; dropping {'train_loss': tensor(0.2173, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 717 < 1065; dropping {'train_loss': tensor(0.3053, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 718 < 1065; dropping {'train_loss': tensor(0.2567, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 719 < 1065; dropping {'train_loss': tensor(0.3505, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 720 < 1065; dropping {'train_loss': tensor(0.1460, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 721 < 1065; dropping {'train_loss': tensor(0.3212, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 722 < 1065; dropping {'train_loss': tensor(0.2561, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 723 < 1065; dropping {'train_loss': tensor(0.5106, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 724 < 1065; dropping {'train_loss': tensor(0.5093, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 725 < 1065; dropping {'train_loss': tensor(0.3678, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 726 < 1065; dropping {'train_loss': tensor(0.3431, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 727 < 1065; dropping {'train_loss': tensor(0.1959, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 728 < 1065; dropping {'train_loss': tensor(0.3357, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 729 < 1065; dropping {'train_loss': tensor(0.4773, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 730 < 1065; dropping {'train_loss': tensor(0.4381, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 731 < 1065; dropping {'train_loss': tensor(0.3976, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 732 < 1065; dropping {'train_loss': tensor(0.1903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 733 < 1065; dropping {'train_loss': tensor(0.3053, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 734 < 1065; dropping {'train_loss': tensor(0.1467, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 735 < 1065; dropping {'train_loss': tensor(0.2540, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 736 < 1065; dropping {'train_loss': tensor(0.1915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 737 < 1065; dropping {'train_loss': tensor(0.4151, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 738 < 1065; dropping {'train_loss': tensor(0.1814, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 739 < 1065; dropping {'train_loss': tensor(0.4761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 740 < 1065; dropping {'train_loss': tensor(0.4034, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 741 < 1065; dropping {'train_loss': tensor(0.2947, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 742 < 1065; dropping {'train_loss': tensor(0.2332, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 743 < 1065; dropping {'train_loss': tensor(0.5051, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 744 < 1065; dropping {'train_loss': tensor(0.3951, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 745 < 1065; dropping {'train_loss': tensor(0.0781, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 746 < 1065; dropping {'train_loss': tensor(0.3531, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 747 < 1065; dropping {'train_loss': tensor(0.2012, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 748 < 1065; dropping {'train_loss': tensor(0.3276, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 749 < 1065; dropping {'train_loss': tensor(0.2266, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 750 < 1065; dropping {'train_loss': tensor(0.2190, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 751 < 1065; dropping {'train_loss': tensor(0.4117, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 752 < 1065; dropping {'train_loss': tensor(0.3252, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 753 < 1065; dropping {'train_loss': tensor(0.2295, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 754 < 1065; dropping {'train_loss': tensor(0.2583, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 755 < 1065; dropping {'train_loss': tensor(0.1901, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 756 < 1065; dropping {'train_loss': tensor(0.1558, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 757 < 1065; dropping {'train_loss': tensor(0.3487, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 758 < 1065; dropping {'train_loss': tensor(0.1944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 759 < 1065; dropping {'train_loss': tensor(0.2195, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 760 < 1065; dropping {'train_loss': tensor(0.2172, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 761 < 1065; dropping {'train_loss': tensor(0.5292, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 762 < 1065; dropping {'train_loss': tensor(0.3255, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 763 < 1065; dropping {'train_loss': tensor(0.2300, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 764 < 1065; dropping {'train_loss': tensor(0.4874, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 765 < 1065; dropping {'train_loss': tensor(0.3013, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 766 < 1065; dropping {'train_loss': tensor(0.1977, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 767 < 1065; dropping {'train_loss': tensor(0.1581, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 768 < 1065; dropping {'train_loss': tensor(0.3993, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 769 < 1065; dropping {'train_loss': tensor(0.4536, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 770 < 1065; dropping {'train_loss': tensor(0.3360, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 771 < 1065; dropping {'train_loss': tensor(0.1158, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 772 < 1065; dropping {'train_loss': tensor(0.1450, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 773 < 1065; dropping {'train_loss': tensor(0.4197, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 774 < 1065; dropping {'train_loss': tensor(0.2930, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 775 < 1065; dropping {'train_loss': tensor(0.3001, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 776 < 1065; dropping {'train_loss': tensor(0.2184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 777 < 1065; dropping {'train_loss': tensor(0.2563, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 778 < 1065; dropping {'train_loss': tensor(0.2338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 779 < 1065; dropping {'train_loss': tensor(0.2549, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 780 < 1065; dropping {'train_loss': tensor(0.2404, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 781 < 1065; dropping {'train_loss': tensor(0.2984, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 782 < 1065; dropping {'train_loss': tensor(0.3395, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 783 < 1065; dropping {'train_loss': tensor(0.5776, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 784 < 1065; dropping {'train_loss': tensor(0.2424, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 785 < 1065; dropping {'train_loss': tensor(0.3650, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 786 < 1065; dropping {'train_loss': tensor(0.2915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 787 < 1065; dropping {'train_loss': tensor(0.4756, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 788 < 1065; dropping {'train_loss': tensor(0.2460, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 789 < 1065; dropping {'train_loss': tensor(0.2929, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 790 < 1065; dropping {'train_loss': tensor(0.4718, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 791 < 1065; dropping {'train_loss': tensor(0.1915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 792 < 1065; dropping {'train_loss': tensor(0.3306, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 793 < 1065; dropping {'train_loss': tensor(0.3739, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 794 < 1065; dropping {'train_loss': tensor(0.2674, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 795 < 1065; dropping {'train_loss': tensor(0.2236, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 796 < 1065; dropping {'train_loss': tensor(0.3996, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 38400/60000             (64% | Loss: 0.330628
wandb: WARNING Step must only increase in log calls.  Step 797 < 1065; dropping {'train_loss': tensor(0.2980, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 798 < 1065; dropping {'train_loss': tensor(0.2330, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 799 < 1065; dropping {'train_loss': tensor(0.3364, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 800 < 1065; dropping {'train_loss': tensor(0.3297, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 801 < 1065; dropping {'train_loss': tensor(0.3071, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 802 < 1065; dropping {'train_loss': tensor(0.2569, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 803 < 1065; dropping {'train_loss': tensor(0.3706, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 804 < 1065; dropping {'train_loss': tensor(0.1655, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 805 < 1065; dropping {'train_loss': tensor(0.1753, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 806 < 1065; dropping {'train_loss': tensor(0.4017, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 807 < 1065; dropping {'train_loss': tensor(0.3504, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 808 < 1065; dropping {'train_loss': tensor(0.3322, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 809 < 1065; dropping {'train_loss': tensor(0.4432, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 810 < 1065; dropping {'train_loss': tensor(0.2116, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 811 < 1065; dropping {'train_loss': tensor(0.3069, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 812 < 1065; dropping {'train_loss': tensor(0.0744, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 813 < 1065; dropping {'train_loss': tensor(0.3606, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 814 < 1065; dropping {'train_loss': tensor(0.2903, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 815 < 1065; dropping {'train_loss': tensor(0.0847, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 816 < 1065; dropping {'train_loss': tensor(0.1830, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 817 < 1065; dropping {'train_loss': tensor(0.2338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 818 < 1065; dropping {'train_loss': tensor(0.1966, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 819 < 1065; dropping {'train_loss': tensor(0.2247, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 820 < 1065; dropping {'train_loss': tensor(0.3475, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 821 < 1065; dropping {'train_loss': tensor(0.3043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 822 < 1065; dropping {'train_loss': tensor(0.3099, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 823 < 1065; dropping {'train_loss': tensor(0.5060, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 824 < 1065; dropping {'train_loss': tensor(0.2552, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 825 < 1065; dropping {'train_loss': tensor(0.3949, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 826 < 1065; dropping {'train_loss': tensor(0.2311, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 827 < 1065; dropping {'train_loss': tensor(0.3074, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 828 < 1065; dropping {'train_loss': tensor(0.4480, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 829 < 1065; dropping {'train_loss': tensor(0.2228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 830 < 1065; dropping {'train_loss': tensor(0.2567, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 831 < 1065; dropping {'train_loss': tensor(0.2066, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 832 < 1065; dropping {'train_loss': tensor(0.1169, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 833 < 1065; dropping {'train_loss': tensor(0.2167, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 834 < 1065; dropping {'train_loss': tensor(0.3539, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 835 < 1065; dropping {'train_loss': tensor(0.2888, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 836 < 1065; dropping {'train_loss': tensor(0.3476, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 837 < 1065; dropping {'train_loss': tensor(0.3579, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 838 < 1065; dropping {'train_loss': tensor(0.2338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 839 < 1065; dropping {'train_loss': tensor(0.2995, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 840 < 1065; dropping {'train_loss': tensor(0.1599, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 841 < 1065; dropping {'train_loss': tensor(0.1204, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 842 < 1065; dropping {'train_loss': tensor(0.1454, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 843 < 1065; dropping {'train_loss': tensor(0.2494, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 844 < 1065; dropping {'train_loss': tensor(0.1766, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 845 < 1065; dropping {'train_loss': tensor(0.3038, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 846 < 1065; dropping {'train_loss': tensor(0.2257, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 847 < 1065; dropping {'train_loss': tensor(0.3253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 848 < 1065; dropping {'train_loss': tensor(0.4035, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 849 < 1065; dropping {'train_loss': tensor(0.3322, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 44800/60000             (75% | Loss: 0.185776
wandb: WARNING Step must only increase in log calls.  Step 850 < 1065; dropping {'train_loss': tensor(0.2888, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 851 < 1065; dropping {'train_loss': tensor(0.2268, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 852 < 1065; dropping {'train_loss': tensor(0.1129, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 853 < 1065; dropping {'train_loss': tensor(0.1859, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 854 < 1065; dropping {'train_loss': tensor(0.2593, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 855 < 1065; dropping {'train_loss': tensor(0.1249, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 856 < 1065; dropping {'train_loss': tensor(0.4853, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 857 < 1065; dropping {'train_loss': tensor(0.3657, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 858 < 1065; dropping {'train_loss': tensor(0.1429, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 859 < 1065; dropping {'train_loss': tensor(0.1896, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 860 < 1065; dropping {'train_loss': tensor(0.2410, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 861 < 1065; dropping {'train_loss': tensor(0.3336, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 862 < 1065; dropping {'train_loss': tensor(0.3524, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 863 < 1065; dropping {'train_loss': tensor(0.4347, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 864 < 1065; dropping {'train_loss': tensor(0.2554, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 865 < 1065; dropping {'train_loss': tensor(0.2279, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 866 < 1065; dropping {'train_loss': tensor(0.2824, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 867 < 1065; dropping {'train_loss': tensor(0.2753, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 868 < 1065; dropping {'train_loss': tensor(0.3743, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 869 < 1065; dropping {'train_loss': tensor(0.0850, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 870 < 1065; dropping {'train_loss': tensor(0.2236, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 871 < 1065; dropping {'train_loss': tensor(0.2176, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 872 < 1065; dropping {'train_loss': tensor(0.4102, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 873 < 1065; dropping {'train_loss': tensor(0.3043, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 874 < 1065; dropping {'train_loss': tensor(0.1208, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 875 < 1065; dropping {'train_loss': tensor(0.4155, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 876 < 1065; dropping {'train_loss': tensor(0.3715, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 877 < 1065; dropping {'train_loss': tensor(0.2632, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 878 < 1065; dropping {'train_loss': tensor(0.3390, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 879 < 1065; dropping {'train_loss': tensor(0.3492, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 880 < 1065; dropping {'train_loss': tensor(0.3582, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 881 < 1065; dropping {'train_loss': tensor(0.2242, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 882 < 1065; dropping {'train_loss': tensor(0.1127, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 883 < 1065; dropping {'train_loss': tensor(0.2964, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 884 < 1065; dropping {'train_loss': tensor(0.2184, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 885 < 1065; dropping {'train_loss': tensor(0.5768, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 886 < 1065; dropping {'train_loss': tensor(0.1575, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 887 < 1065; dropping {'train_loss': tensor(0.3426, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 888 < 1065; dropping {'train_loss': tensor(0.2891, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 889 < 1065; dropping {'train_loss': tensor(0.3282, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 890 < 1065; dropping {'train_loss': tensor(0.2368, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 891 < 1065; dropping {'train_loss': tensor(0.1520, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 892 < 1065; dropping {'train_loss': tensor(0.1858, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 893 < 1065; dropping {'train_loss': tensor(0.1567, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 894 < 1065; dropping {'train_loss': tensor(0.2591, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 895 < 1065; dropping {'train_loss': tensor(0.2344, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 896 < 1065; dropping {'train_loss': tensor(0.3052, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 897 < 1065; dropping {'train_loss': tensor(0.3271, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 898 < 1065; dropping {'train_loss': tensor(0.1534, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 899 < 1065; dropping {'train_loss': tensor(0.2253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 900 < 1065; dropping {'train_loss': tensor(0.2605, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 901 < 1065; dropping {'train_loss': tensor(0.1128, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 902 < 1065; dropping {'train_loss': tensor(0.2496, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 903 < 1065; dropping {'train_loss': tensor(0.2922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 904 < 1065; dropping {'train_loss': tensor(0.1136, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 905 < 1065; dropping {'train_loss': tensor(0.2540, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 906 < 1065; dropping {'train_loss': tensor(0.2554, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 907 < 1065; dropping {'train_loss': tensor(0.2290, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 908 < 1065; dropping {'train_loss': tensor(0.0751, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 909 < 1065; dropping {'train_loss': tensor(0.1630, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 910 < 1065; dropping {'train_loss': tensor(0.4206, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 911 < 1065; dropping {'train_loss': tensor(0.3255, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 912 < 1065; dropping {'train_loss': tensor(0.4208, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 913 < 1065; dropping {'train_loss': tensor(0.3012, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 914 < 1065; dropping {'train_loss': tensor(0.4326, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 915 < 1065; dropping {'train_loss': tensor(0.2223, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 916 < 1065; dropping {'train_loss': tensor(0.2395, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 917 < 1065; dropping {'train_loss': tensor(0.2721, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 918 < 1065; dropping {'train_loss': tensor(0.3392, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 919 < 1065; dropping {'train_loss': tensor(0.1879, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 920 < 1065; dropping {'train_loss': tensor(0.4696, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 921 < 1065; dropping {'train_loss': tensor(0.4417, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 922 < 1065; dropping {'train_loss': tensor(0.2195, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 923 < 1065; dropping {'train_loss': tensor(0.2381, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 924 < 1065; dropping {'train_loss': tensor(0.4944, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 925 < 1065; dropping {'train_loss': tensor(0.1867, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 926 < 1065; dropping {'train_loss': tensor(0.1756, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 927 < 1065; dropping {'train_loss': tensor(0.1977, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 928 < 1065; dropping {'train_loss': tensor(0.3448, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 929 < 1065; dropping {'train_loss': tensor(0.1931, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 930 < 1065; dropping {'train_loss': tensor(0.3542, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 931 < 1065; dropping {'train_loss': tensor(0.1574, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 932 < 1065; dropping {'train_loss': tensor(0.1484, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 933 < 1065; dropping {'train_loss': tensor(0.1810, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 934 < 1065; dropping {'train_loss': tensor(0.3258, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 935 < 1065; dropping {'train_loss': tensor(0.2221, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 936 < 1065; dropping {'train_loss': tensor(0.2362, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 937 < 1065; dropping {'train_loss': tensor(0.2324, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 938 < 1065; dropping {'train_loss': tensor(0.2559, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 939 < 1065; dropping {'train_loss': tensor(0.1900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 940 < 1065; dropping {'train_loss': tensor(0.4742, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 941 < 1065; dropping {'train_loss': tensor(0.2331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 942 < 1065; dropping {'train_loss': tensor(0.2854, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 943 < 1065; dropping {'train_loss': tensor(0.1880, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 944 < 1065; dropping {'train_loss': tensor(0.2747, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 945 < 1065; dropping {'train_loss': tensor(0.3604, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 946 < 1065; dropping {'train_loss': tensor(0.3013, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 947 < 1065; dropping {'train_loss': tensor(0.1846, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 948 < 1065; dropping {'train_loss': tensor(0.2701, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 949 < 1065; dropping {'train_loss': tensor(0.5244, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 950 < 1065; dropping {'train_loss': tensor(0.2167, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 951 < 1065; dropping {'train_loss': tensor(0.2560, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 952 < 1065; dropping {'train_loss': tensor(0.2579, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 953 < 1065; dropping {'train_loss': tensor(0.3384, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 954 < 1065; dropping {'train_loss': tensor(0.2553, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 955 < 1065; dropping {'train_loss': tensor(0.2264, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 956 < 1065; dropping {'train_loss': tensor(0.2674, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 957 < 1065; dropping {'train_loss': tensor(0.2216, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 958 < 1065; dropping {'train_loss': tensor(0.2661, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 959 < 1065; dropping {'train_loss': tensor(0.4068, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 960 < 1065; dropping {'train_loss': tensor(0.1838, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 961 < 1065; dropping {'train_loss': tensor(0.4263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 962 < 1065; dropping {'train_loss': tensor(0.1761, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 963 < 1065; dropping {'train_loss': tensor(0.0869, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 964 < 1065; dropping {'train_loss': tensor(0.3127, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 965 < 1065; dropping {'train_loss': tensor(0.2919, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 966 < 1065; dropping {'train_loss': tensor(0.2537, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 967 < 1065; dropping {'train_loss': tensor(0.1102, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 968 < 1065; dropping {'train_loss': tensor(0.3131, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 969 < 1065; dropping {'train_loss': tensor(0.2540, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 970 < 1065; dropping {'train_loss': tensor(0.2318, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 971 < 1065; dropping {'train_loss': tensor(0.1456, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 972 < 1065; dropping {'train_loss': tensor(0.1900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 973 < 1065; dropping {'train_loss': tensor(0.3093, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 974 < 1065; dropping {'train_loss': tensor(0.2022, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 975 < 1065; dropping {'train_loss': tensor(0.1869, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 976 < 1065; dropping {'train_loss': tensor(0.0974, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 977 < 1065; dropping {'train_loss': tensor(0.3338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 978 < 1065; dropping {'train_loss': tensor(0.3651, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 979 < 1065; dropping {'train_loss': tensor(0.2940, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 980 < 1065; dropping {'train_loss': tensor(0.4945, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 981 < 1065; dropping {'train_loss': tensor(0.2198, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 982 < 1065; dropping {'train_loss': tensor(0.2778, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 983 < 1065; dropping {'train_loss': tensor(0.2006, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 984 < 1065; dropping {'train_loss': tensor(0.2254, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 985 < 1065; dropping {'train_loss': tensor(0.1529, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 986 < 1065; dropping {'train_loss': tensor(0.1851, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 987 < 1065; dropping {'train_loss': tensor(0.4926, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 988 < 1065; dropping {'train_loss': tensor(0.1876, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 989 < 1065; dropping {'train_loss': tensor(0.2559, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 990 < 1065; dropping {'train_loss': tensor(0.3263, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 991 < 1065; dropping {'train_loss': tensor(0.4792, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 992 < 1065; dropping {'train_loss': tensor(0.2192, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 993 < 1065; dropping {'train_loss': tensor(0.2915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 994 < 1065; dropping {'train_loss': tensor(0.1123, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 995 < 1065; dropping {'train_loss': tensor(0.2336, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 996 < 1065; dropping {'train_loss': tensor(0.2911, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 997 < 1065; dropping {'train_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 51200/60000             (85% | Loss: 0.219178
wandb: WARNING Step must only increase in log calls.  Step 998 < 1065; dropping {'train_loss': tensor(0.4529, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 999 < 1065; dropping {'train_loss': tensor(0.2780, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1000 < 1065; dropping {'train_loss': tensor(0.4198, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1001 < 1065; dropping {'train_loss': tensor(0.1275, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1002 < 1065; dropping {'train_loss': tensor(0.1828, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1003 < 1065; dropping {'train_loss': tensor(0.2650, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1004 < 1065; dropping {'train_loss': tensor(0.1842, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1005 < 1065; dropping {'train_loss': tensor(0.4198, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1006 < 1065; dropping {'train_loss': tensor(0.2248, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1007 < 1065; dropping {'train_loss': tensor(0.2175, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1008 < 1065; dropping {'train_loss': tensor(0.4341, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1009 < 1065; dropping {'train_loss': tensor(0.1533, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1010 < 1065; dropping {'train_loss': tensor(0.3812, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1011 < 1065; dropping {'train_loss': tensor(0.3268, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1012 < 1065; dropping {'train_loss': tensor(0.3840, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1013 < 1065; dropping {'train_loss': tensor(0.3973, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1014 < 1065; dropping {'train_loss': tensor(0.2241, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1015 < 1065; dropping {'train_loss': tensor(0.4173, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1016 < 1065; dropping {'train_loss': tensor(0.2737, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1017 < 1065; dropping {'train_loss': tensor(0.1783, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1018 < 1065; dropping {'train_loss': tensor(0.2387, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1019 < 1065; dropping {'train_loss': tensor(0.2959, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1020 < 1065; dropping {'train_loss': tensor(0.2238, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1021 < 1065; dropping {'train_loss': tensor(0.1430, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1022 < 1065; dropping {'train_loss': tensor(0.2115, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1023 < 1065; dropping {'train_loss': tensor(0.3436, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1024 < 1065; dropping {'train_loss': tensor(0.3056, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1025 < 1065; dropping {'train_loss': tensor(0.3648, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1026 < 1065; dropping {'train_loss': tensor(0.4378, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1027 < 1065; dropping {'train_loss': tensor(0.2287, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1028 < 1065; dropping {'train_loss': tensor(0.2606, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1029 < 1065; dropping {'train_loss': tensor(0.3182, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1030 < 1065; dropping {'train_loss': tensor(0.2922, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1031 < 1065; dropping {'train_loss': tensor(0.5338, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1032 < 1065; dropping {'train_loss': tensor(0.1819, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1033 < 1065; dropping {'train_loss': tensor(0.1941, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1034 < 1065; dropping {'train_loss': tensor(0.2274, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1035 < 1065; dropping {'train_loss': tensor(0.2548, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1036 < 1065; dropping {'train_loss': tensor(0.2343, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1037 < 1065; dropping {'train_loss': tensor(0.4196, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1038 < 1065; dropping {'train_loss': tensor(0.3406, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1039 < 1065; dropping {'train_loss': tensor(0.2596, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1040 < 1065; dropping {'train_loss': tensor(0.2409, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1041 < 1065; dropping {'train_loss': tensor(0.2579, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1042 < 1065; dropping {'train_loss': tensor(0.2461, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1043 < 1065; dropping {'train_loss': tensor(0.2972, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1044 < 1065; dropping {'train_loss': tensor(0.2631, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1045 < 1065; dropping {'train_loss': tensor(0.3589, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1046 < 1065; dropping {'train_loss': tensor(0.1117, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1047 < 1065; dropping {'train_loss': tensor(0.2900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1048 < 1065; dropping {'train_loss': tensor(0.2228, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1049 < 1065; dropping {'train_loss': tensor(0.4891, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1050 < 1065; dropping {'train_loss': tensor(0.3268, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1051 < 1065; dropping {'train_loss': tensor(0.2499, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1052 < 1065; dropping {'train_loss': tensor(0.1463, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1053 < 1065; dropping {'train_loss': tensor(0.2806, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1054 < 1065; dropping {'train_loss': tensor(0.3850, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1055 < 1065; dropping {'train_loss': tensor(0.2888, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1056 < 1065; dropping {'train_loss': tensor(0.2911, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1057 < 1065; dropping {'train_loss': tensor(0.1821, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1058 < 1065; dropping {'train_loss': tensor(0.2292, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1059 < 1065; dropping {'train_loss': tensor(0.2211, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1060 < 1065; dropping {'train_loss': tensor(0.3386, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1061 < 1065; dropping {'train_loss': tensor(0.2572, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1062 < 1065; dropping {'train_loss': tensor(0.2557, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1063 < 1065; dropping {'train_loss': tensor(0.3470, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 1064 < 1065; dropping {'train_loss': tensor(0.3083, grad_fn=<NllLossBackward0>)}.
Train Epoch: 4 | Batch Status: 57600/60000             (96% | Loss: 0.254609
wandb: WARNING Step must only increase in log calls.  Step 192 < 1129; dropping {'val_loss': tensor(0.4694, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 193 < 1129; dropping {'val_loss': tensor(0.2725, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 194 < 1129; dropping {'val_loss': tensor(0.2481, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 195 < 1129; dropping {'val_loss': tensor(0.2637, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 196 < 1129; dropping {'val_loss': tensor(0.2935, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 197 < 1129; dropping {'val_loss': tensor(0.3720, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 198 < 1129; dropping {'val_loss': tensor(0.1868, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 199 < 1129; dropping {'val_loss': tensor(0.2661, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 200 < 1129; dropping {'val_loss': tensor(0.1814, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 201 < 1129; dropping {'val_loss': tensor(0.1554, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 202 < 1129; dropping {'val_loss': tensor(0.3918, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 203 < 1129; dropping {'val_loss': tensor(0.2925, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 204 < 1129; dropping {'val_loss': tensor(0.3668, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 205 < 1129; dropping {'val_loss': tensor(0.2950, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 206 < 1129; dropping {'val_loss': tensor(0.2899, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 207 < 1129; dropping {'val_loss': tensor(0.1503, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 208 < 1129; dropping {'val_loss': tensor(0.3309, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 209 < 1129; dropping {'val_loss': tensor(0.1546, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 210 < 1129; dropping {'val_loss': tensor(0.1853, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 211 < 1129; dropping {'val_loss': tensor(0.2614, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 212 < 1129; dropping {'val_loss': tensor(0.4826, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 213 < 1129; dropping {'val_loss': tensor(0.3686, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 214 < 1129; dropping {'val_loss': tensor(0.1825, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 215 < 1129; dropping {'val_loss': tensor(0.2226, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 216 < 1129; dropping {'val_loss': tensor(0.3848, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 217 < 1129; dropping {'val_loss': tensor(0.1366, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 218 < 1129; dropping {'val_loss': tensor(0.1554, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 219 < 1129; dropping {'val_loss': tensor(0.4320, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 220 < 1129; dropping {'val_loss': tensor(0.3297, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 221 < 1129; dropping {'val_loss': tensor(0.3236, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 222 < 1129; dropping {'val_loss': tensor(0.3578, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 223 < 1129; dropping {'val_loss': tensor(0.3400, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 224 < 1129; dropping {'val_loss': tensor(0.3035, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 225 < 1129; dropping {'val_loss': tensor(0.4218, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 226 < 1129; dropping {'val_loss': tensor(0.3253, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 227 < 1129; dropping {'val_loss': tensor(0.2177, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 228 < 1129; dropping {'val_loss': tensor(0.2916, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 229 < 1129; dropping {'val_loss': tensor(0.1305, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 230 < 1129; dropping {'val_loss': tensor(0.2229, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 231 < 1129; dropping {'val_loss': tensor(0.1676, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 232 < 1129; dropping {'val_loss': tensor(0.2987, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 233 < 1129; dropping {'val_loss': tensor(0.2883, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 234 < 1129; dropping {'val_loss': tensor(0.2536, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 235 < 1129; dropping {'val_loss': tensor(0.4396, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 236 < 1129; dropping {'val_loss': tensor(0.1884, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 237 < 1129; dropping {'val_loss': tensor(0.4170, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 238 < 1129; dropping {'val_loss': tensor(0.2962, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 239 < 1129; dropping {'val_loss': tensor(0.2904, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 240 < 1129; dropping {'val_loss': tensor(0.3325, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 241 < 1129; dropping {'val_loss': tensor(0.2000, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 242 < 1129; dropping {'val_loss': tensor(0.2723, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 243 < 1129; dropping {'val_loss': tensor(0.3749, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 244 < 1129; dropping {'val_loss': tensor(0.3760, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 245 < 1129; dropping {'val_loss': tensor(0.3694, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 246 < 1129; dropping {'val_loss': tensor(0.2886, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 247 < 1129; dropping {'val_loss': tensor(0.3742, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 248 < 1129; dropping {'val_loss': tensor(0.4055, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 249 < 1129; dropping {'val_loss': tensor(0.2626, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 250 < 1129; dropping {'val_loss': tensor(0.4684, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 251 < 1129; dropping {'val_loss': tensor(0.3111, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 252 < 1129; dropping {'val_loss': tensor(0.4523, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 253 < 1129; dropping {'val_loss': tensor(0.3230, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 254 < 1129; dropping {'val_loss': tensor(0.2915, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 255 < 1129; dropping {'val_loss': tensor(0.3331, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 256 < 1129; dropping {'val_loss': tensor(0.2199, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 257 < 1129; dropping {'val_loss': tensor(0.1905, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 258 < 1129; dropping {'val_loss': tensor(0.2900, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 259 < 1129; dropping {'val_loss': tensor(0.2907, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 260 < 1129; dropping {'val_loss': tensor(0.2163, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 261 < 1129; dropping {'val_loss': tensor(0.1501, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 262 < 1129; dropping {'val_loss': tensor(0.3349, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 263 < 1129; dropping {'val_loss': tensor(0.3057, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 264 < 1129; dropping {'val_loss': tensor(0.2682, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 265 < 1129; dropping {'val_loss': tensor(0.3312, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 266 < 1129; dropping {'val_loss': tensor(0.3489, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 267 < 1129; dropping {'val_loss': tensor(0.4200, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 268 < 1129; dropping {'val_loss': tensor(0.3419, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 269 < 1129; dropping {'val_loss': tensor(0.1882, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 270 < 1129; dropping {'val_loss': tensor(0.2824, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 271 < 1129; dropping {'val_loss': tensor(0.4747, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 272 < 1129; dropping {'val_loss': tensor(0.4499, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 273 < 1129; dropping {'val_loss': tensor(0.1907, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 274 < 1129; dropping {'val_loss': tensor(0.3695, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 275 < 1129; dropping {'val_loss': tensor(0.2771, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 276 < 1129; dropping {'val_loss': tensor(0.2318, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 277 < 1129; dropping {'val_loss': tensor(0.3264, grad_fn=<NllLossBackward0>)}.
wandb: WARNING Step must only increase in log calls.  Step 278 < 1129; dropping {'val_loss': tensor(0.2920, grad_fn=<NllLossBackward0>)}.
Traceback (most recent call last):
  File "C:/Users/ye200/Aiffel/Torch-Master/Original/run_with_wandb.py", line 77, in <module>
    validation(epoch, cnn, ce_loss, valid_loader)
  File "C:/Users/ye200/Aiffel/Torch-Master/Original/run_with_wandb.py", line 49, in validation
    for batch_index, (x, y) in enumerate(valid_loader):
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\torch\utils\data\dataloader.py", line 521, in __next__
    data = self._next_data()
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\torch\utils\data\dataloader.py", line 561, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\torch\utils\data\_utils\fetch.py", line 49, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\torch\utils\data\_utils\fetch.py", line 49, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\torchvision\datasets\mnist.py", line 131, in __getitem__
    img = Image.fromarray(img.numpy(), mode='L')
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\PIL\Image.py", line 2849, in fromarray
    return frombuffer(mode, size, obj, "raw", rawmode, 0, 1)
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\PIL\Image.py", line 2784, in frombuffer
    im = new(mode, (1, 1))
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\PIL\Image.py", line 2698, in new
    return im._new(core.fill(mode, size, color))
  File "C:\Users\ye200\Anaconda3\envs\env\lib\site-packages\PIL\Image.py", line 563, in _new
    new.mode = im.mode
KeyboardInterrupt