{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "470e1ea9",
   "metadata": {},
   "source": [
    "미니배치, 이터레이션, 에포크 참조  \n",
    "https://wikidocs.net/55580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ef8e6284",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.data import DataLoader # 데이터로더\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "2b57c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensorDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.x_data = [[73, 80, 75],\n",
    "                       [93, 88, 93],\n",
    "                       [89, 91, 90],\n",
    "                       [96, 98, 100],\n",
    "                       [73, 66, 70]]\n",
    "        self.y_data = [[152], [185], [180], [196], [142]]\n",
    "\n",
    "      # 총 데이터의 개수를 리턴\n",
    "    def __len__(self): \n",
    "        return len(self.x_data)\n",
    "\n",
    "      # 인덱스를 입력받아 그에 맵핑되는 입출력 데이터를 파이토치의 Tensor 형태로 리턴\n",
    "    def __getitem__(self, idx): \n",
    "        x = torch.FloatTensor(self.x_data[idx])\n",
    "        y = torch.FloatTensor(self.y_data[idx])\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "634666f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "xy = np.loadtxt('./data/diabetes.csv.gz', delimiter=',', dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "3b8671b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiabetesDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, xy_dataset):\n",
    "        # 커스텀 데이터셋 클래스의 생성자\n",
    "        # 데이터를 불러오고 전처리 한다.\n",
    "        self.x_data = torch.from_numpy(xy_dataset[:, 0:-1])\n",
    "        self.y_data = torch.from_numpy(xy_dataset[:, [-1]])\n",
    "        print(f'X\\'s shape: {self.x_data.shape} | Y\\'s shape: {self.y_data.shape}')\n",
    "\n",
    "    def __len__(self):\n",
    "        # 데이터셋의 길이를 반환하는 메소드\n",
    "        return len(self.x_data)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        # 데이터셋에서 하나의 특정 샘플 (x, y)을 가져오는 메소드\n",
    "        return self.x_data[idx], self.y_data[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "d299e115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X's shape: torch.Size([759, 8]) | Y's shape: torch.Size([759, 1])\n"
     ]
    }
   ],
   "source": [
    "# 구현한 커스텀 데이터셋 클래스의 인스턴스 생성\n",
    "dataset = DiabetesDataset(xy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "9b7c7de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataLoader 클래스를 사용하여 데이터를 불러온 후, 모델에 입력하게 된다.\n",
    "data_loader = DataLoader(dataset, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e93d55",
   "metadata": {},
   "source": [
    "## 퀴즈 (Easy)  \n",
    "1) 당뇨병 데이터셋에 대해서 로지스틱 회귀 모델을 구현한다면 첫번째 레이어의 노드 수는 몇개가 되어야 할까요??   \n",
    "2) data_loader에서 샘플들을 가져온다면 샘플들의 전체 모양은 어떻게 될까요?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc9bc9ec",
   "metadata": {},
   "source": [
    "## 퀴즈 (Normal)  \n",
    "이전의 노트북 파일을 참고해서 LogisticRegressionModel 클래스를 구현하세요.  \n",
    "1) 생성자 :  \n",
    "모델의 은닉층 수는 3층이고 은닉층마다 (8, 6, 4) 개의 뉴런을 가집니다.  \n",
    "마지막 레이어에는 시그모이드 모듈을 이용해 예측값을 계산하도록 만드세요.  \n",
    "2) forward :   \n",
    "최종적으로 확률 값을 예측하도록 레이어를 쌓아서 y를 반환하세요.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e1fefff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.L1 = nn.Linear(8, 6)\n",
    "        self.L2 = nn.Linear(6, 4)\n",
    "        self.L3 = nn.Linear(4, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z1 = self.sigmoid(self.L1(x))\n",
    "        z2 = self.sigmoid(self.L2(z1))\n",
    "        z3 = self.sigmoid(self.L3(z2))\n",
    "        y_pred = self.sigmoid(z3)\n",
    "        return y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8dd26f4",
   "metadata": {},
   "source": [
    "## 퀴즈 (Normal)  \n",
    "1) 위 모델을 학습시키기 위해서는 어떤 손실함수를 선택해야할까요??  \n",
    "2) 위의 로지스틱회귀 클래스 모델을 조금 더 메모리 효율적으로 구현하려면 어떻게 해야할까요?  \n",
    "3) 위의 로지스틱 회귀 모델을 공책에 그려봅시다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "c2e34bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegressionModel()\n",
    "bce_loss = nn.BCELoss(reduction='mean')\n",
    "lr = 0.01\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "0da5f890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:    1/1000 Batch    1/8                     Loss: 0.641854\n",
      "Epoch:    2/1000 Batch    1/8                     Loss: 0.639658\n",
      "Epoch:    3/1000 Batch    1/8                     Loss: 0.636665\n",
      "Epoch:    4/1000 Batch    1/8                     Loss: 0.628623\n",
      "Epoch:    5/1000 Batch    1/8                     Loss: 0.610536\n",
      "Epoch:    6/1000 Batch    1/8                     Loss: 0.584162\n",
      "Epoch:    7/1000 Batch    1/8                     Loss: 0.564793\n",
      "Epoch:    8/1000 Batch    1/8                     Loss: 0.556183\n",
      "Epoch:    9/1000 Batch    1/8                     Loss: 0.553297\n",
      "Epoch:   10/1000 Batch    1/8                     Loss: 0.552558\n",
      "Epoch:   11/1000 Batch    1/8                     Loss: 0.553340\n",
      "Epoch:   12/1000 Batch    1/8                     Loss: 0.555216\n",
      "Epoch:   13/1000 Batch    1/8                     Loss: 0.557112\n",
      "Epoch:   14/1000 Batch    1/8                     Loss: 0.558286\n",
      "Epoch:   15/1000 Batch    1/8                     Loss: 0.558863\n",
      "Epoch:   16/1000 Batch    1/8                     Loss: 0.558913\n",
      "Epoch:   17/1000 Batch    1/8                     Loss: 0.558728\n",
      "Epoch:   18/1000 Batch    1/8                     Loss: 0.558464\n",
      "Epoch:   19/1000 Batch    1/8                     Loss: 0.558228\n",
      "Epoch:   20/1000 Batch    1/8                     Loss: 0.558062\n",
      "Epoch:   21/1000 Batch    1/8                     Loss: 0.557946\n",
      "Epoch:   22/1000 Batch    1/8                     Loss: 0.557867\n",
      "Epoch:   23/1000 Batch    1/8                     Loss: 0.557792\n",
      "Epoch:   24/1000 Batch    1/8                     Loss: 0.557712\n",
      "Epoch:   25/1000 Batch    1/8                     Loss: 0.557620\n",
      "Epoch:   26/1000 Batch    1/8                     Loss: 0.557518\n",
      "Epoch:   27/1000 Batch    1/8                     Loss: 0.557410\n",
      "Epoch:   28/1000 Batch    1/8                     Loss: 0.557300\n",
      "Epoch:   29/1000 Batch    1/8                     Loss: 0.557191\n",
      "Epoch:   30/1000 Batch    1/8                     Loss: 0.557085\n",
      "Epoch:   31/1000 Batch    1/8                     Loss: 0.556984\n",
      "Epoch:   32/1000 Batch    1/8                     Loss: 0.556888\n",
      "Epoch:   33/1000 Batch    1/8                     Loss: 0.556798\n",
      "Epoch:   34/1000 Batch    1/8                     Loss: 0.556714\n",
      "Epoch:   35/1000 Batch    1/8                     Loss: 0.556637\n",
      "Epoch:   36/1000 Batch    1/8                     Loss: 0.556565\n",
      "Epoch:   37/1000 Batch    1/8                     Loss: 0.556500\n",
      "Epoch:   38/1000 Batch    1/8                     Loss: 0.556439\n",
      "Epoch:   39/1000 Batch    1/8                     Loss: 0.556382\n",
      "Epoch:   40/1000 Batch    1/8                     Loss: 0.556329\n",
      "Epoch:   41/1000 Batch    1/8                     Loss: 0.556278\n",
      "Epoch:   42/1000 Batch    1/8                     Loss: 0.556228\n",
      "Epoch:   43/1000 Batch    1/8                     Loss: 0.556180\n",
      "Epoch:   44/1000 Batch    1/8                     Loss: 0.556132\n",
      "Epoch:   45/1000 Batch    1/8                     Loss: 0.556083\n",
      "Epoch:   46/1000 Batch    1/8                     Loss: 0.556033\n",
      "Epoch:   47/1000 Batch    1/8                     Loss: 0.555982\n",
      "Epoch:   48/1000 Batch    1/8                     Loss: 0.555930\n",
      "Epoch:   49/1000 Batch    1/8                     Loss: 0.555876\n",
      "Epoch:   50/1000 Batch    1/8                     Loss: 0.555820\n",
      "Epoch:   51/1000 Batch    1/8                     Loss: 0.555762\n",
      "Epoch:   52/1000 Batch    1/8                     Loss: 0.555703\n",
      "Epoch:   53/1000 Batch    1/8                     Loss: 0.555642\n",
      "Epoch:   54/1000 Batch    1/8                     Loss: 0.555580\n",
      "Epoch:   55/1000 Batch    1/8                     Loss: 0.555517\n",
      "Epoch:   56/1000 Batch    1/8                     Loss: 0.555454\n",
      "Epoch:   57/1000 Batch    1/8                     Loss: 0.555390\n",
      "Epoch:   58/1000 Batch    1/8                     Loss: 0.555326\n",
      "Epoch:   59/1000 Batch    1/8                     Loss: 0.555263\n",
      "Epoch:   60/1000 Batch    1/8                     Loss: 0.555200\n",
      "Epoch:   61/1000 Batch    1/8                     Loss: 0.555139\n",
      "Epoch:   62/1000 Batch    1/8                     Loss: 0.555078\n",
      "Epoch:   63/1000 Batch    1/8                     Loss: 0.555019\n",
      "Epoch:   64/1000 Batch    1/8                     Loss: 0.554961\n",
      "Epoch:   65/1000 Batch    1/8                     Loss: 0.554905\n",
      "Epoch:   66/1000 Batch    1/8                     Loss: 0.554851\n",
      "Epoch:   67/1000 Batch    1/8                     Loss: 0.554798\n",
      "Epoch:   68/1000 Batch    1/8                     Loss: 0.554746\n",
      "Epoch:   69/1000 Batch    1/8                     Loss: 0.554696\n",
      "Epoch:   70/1000 Batch    1/8                     Loss: 0.554648\n",
      "Epoch:   71/1000 Batch    1/8                     Loss: 0.554600\n",
      "Epoch:   72/1000 Batch    1/8                     Loss: 0.554554\n",
      "Epoch:   73/1000 Batch    1/8                     Loss: 0.554509\n",
      "Epoch:   74/1000 Batch    1/8                     Loss: 0.554465\n",
      "Epoch:   75/1000 Batch    1/8                     Loss: 0.554422\n",
      "Epoch:   76/1000 Batch    1/8                     Loss: 0.554379\n",
      "Epoch:   77/1000 Batch    1/8                     Loss: 0.554337\n",
      "Epoch:   78/1000 Batch    1/8                     Loss: 0.554296\n",
      "Epoch:   79/1000 Batch    1/8                     Loss: 0.554255\n",
      "Epoch:   80/1000 Batch    1/8                     Loss: 0.554214\n",
      "Epoch:   81/1000 Batch    1/8                     Loss: 0.554173\n",
      "Epoch:   82/1000 Batch    1/8                     Loss: 0.554133\n",
      "Epoch:   83/1000 Batch    1/8                     Loss: 0.554093\n",
      "Epoch:   84/1000 Batch    1/8                     Loss: 0.554053\n",
      "Epoch:   85/1000 Batch    1/8                     Loss: 0.554013\n",
      "Epoch:   86/1000 Batch    1/8                     Loss: 0.553972\n",
      "Epoch:   87/1000 Batch    1/8                     Loss: 0.553932\n",
      "Epoch:   88/1000 Batch    1/8                     Loss: 0.553892\n",
      "Epoch:   89/1000 Batch    1/8                     Loss: 0.553852\n",
      "Epoch:   90/1000 Batch    1/8                     Loss: 0.553812\n",
      "Epoch:   91/1000 Batch    1/8                     Loss: 0.553772\n",
      "Epoch:   92/1000 Batch    1/8                     Loss: 0.553732\n",
      "Epoch:   93/1000 Batch    1/8                     Loss: 0.553692\n",
      "Epoch:   94/1000 Batch    1/8                     Loss: 0.553651\n",
      "Epoch:   95/1000 Batch    1/8                     Loss: 0.553611\n",
      "Epoch:   96/1000 Batch    1/8                     Loss: 0.553571\n",
      "Epoch:   97/1000 Batch    1/8                     Loss: 0.553530\n",
      "Epoch:   98/1000 Batch    1/8                     Loss: 0.553490\n",
      "Epoch:   99/1000 Batch    1/8                     Loss: 0.553449\n",
      "Epoch:  100/1000 Batch    1/8                     Loss: 0.553409\n",
      "Epoch:  101/1000 Batch    1/8                     Loss: 0.553369\n",
      "Epoch:  102/1000 Batch    1/8                     Loss: 0.553328\n",
      "Epoch:  103/1000 Batch    1/8                     Loss: 0.553288\n",
      "Epoch:  104/1000 Batch    1/8                     Loss: 0.553247\n",
      "Epoch:  105/1000 Batch    1/8                     Loss: 0.553207\n",
      "Epoch:  106/1000 Batch    1/8                     Loss: 0.553166\n",
      "Epoch:  107/1000 Batch    1/8                     Loss: 0.553126\n",
      "Epoch:  108/1000 Batch    1/8                     Loss: 0.553085\n",
      "Epoch:  109/1000 Batch    1/8                     Loss: 0.553045\n",
      "Epoch:  110/1000 Batch    1/8                     Loss: 0.553005\n",
      "Epoch:  111/1000 Batch    1/8                     Loss: 0.552964\n",
      "Epoch:  112/1000 Batch    1/8                     Loss: 0.552924\n",
      "Epoch:  113/1000 Batch    1/8                     Loss: 0.552884\n",
      "Epoch:  114/1000 Batch    1/8                     Loss: 0.552844\n",
      "Epoch:  115/1000 Batch    1/8                     Loss: 0.552804\n",
      "Epoch:  116/1000 Batch    1/8                     Loss: 0.552764\n",
      "Epoch:  117/1000 Batch    1/8                     Loss: 0.552724\n",
      "Epoch:  118/1000 Batch    1/8                     Loss: 0.552684\n",
      "Epoch:  119/1000 Batch    1/8                     Loss: 0.552644\n",
      "Epoch:  120/1000 Batch    1/8                     Loss: 0.552604\n",
      "Epoch:  121/1000 Batch    1/8                     Loss: 0.552565\n",
      "Epoch:  122/1000 Batch    1/8                     Loss: 0.552525\n",
      "Epoch:  123/1000 Batch    1/8                     Loss: 0.552486\n",
      "Epoch:  124/1000 Batch    1/8                     Loss: 0.552446\n",
      "Epoch:  125/1000 Batch    1/8                     Loss: 0.552407\n",
      "Epoch:  126/1000 Batch    1/8                     Loss: 0.552367\n",
      "Epoch:  127/1000 Batch    1/8                     Loss: 0.552328\n",
      "Epoch:  128/1000 Batch    1/8                     Loss: 0.552289\n",
      "Epoch:  129/1000 Batch    1/8                     Loss: 0.552250\n",
      "Epoch:  130/1000 Batch    1/8                     Loss: 0.552211\n",
      "Epoch:  131/1000 Batch    1/8                     Loss: 0.552172\n",
      "Epoch:  132/1000 Batch    1/8                     Loss: 0.552134\n",
      "Epoch:  133/1000 Batch    1/8                     Loss: 0.552095\n",
      "Epoch:  134/1000 Batch    1/8                     Loss: 0.552056\n",
      "Epoch:  135/1000 Batch    1/8                     Loss: 0.552018\n",
      "Epoch:  136/1000 Batch    1/8                     Loss: 0.551980\n",
      "Epoch:  137/1000 Batch    1/8                     Loss: 0.551941\n",
      "Epoch:  138/1000 Batch    1/8                     Loss: 0.551903\n",
      "Epoch:  139/1000 Batch    1/8                     Loss: 0.551865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  140/1000 Batch    1/8                     Loss: 0.551827\n",
      "Epoch:  141/1000 Batch    1/8                     Loss: 0.551789\n",
      "Epoch:  142/1000 Batch    1/8                     Loss: 0.551751\n",
      "Epoch:  143/1000 Batch    1/8                     Loss: 0.551713\n",
      "Epoch:  144/1000 Batch    1/8                     Loss: 0.551676\n",
      "Epoch:  145/1000 Batch    1/8                     Loss: 0.551638\n",
      "Epoch:  146/1000 Batch    1/8                     Loss: 0.551601\n",
      "Epoch:  147/1000 Batch    1/8                     Loss: 0.551563\n",
      "Epoch:  148/1000 Batch    1/8                     Loss: 0.551526\n",
      "Epoch:  149/1000 Batch    1/8                     Loss: 0.551489\n",
      "Epoch:  150/1000 Batch    1/8                     Loss: 0.551452\n",
      "Epoch:  151/1000 Batch    1/8                     Loss: 0.551415\n",
      "Epoch:  152/1000 Batch    1/8                     Loss: 0.551377\n",
      "Epoch:  153/1000 Batch    1/8                     Loss: 0.551340\n",
      "Epoch:  154/1000 Batch    1/8                     Loss: 0.551304\n",
      "Epoch:  155/1000 Batch    1/8                     Loss: 0.551267\n",
      "Epoch:  156/1000 Batch    1/8                     Loss: 0.551230\n",
      "Epoch:  157/1000 Batch    1/8                     Loss: 0.551193\n",
      "Epoch:  158/1000 Batch    1/8                     Loss: 0.551157\n",
      "Epoch:  159/1000 Batch    1/8                     Loss: 0.551120\n",
      "Epoch:  160/1000 Batch    1/8                     Loss: 0.551084\n",
      "Epoch:  161/1000 Batch    1/8                     Loss: 0.551047\n",
      "Epoch:  162/1000 Batch    1/8                     Loss: 0.551011\n",
      "Epoch:  163/1000 Batch    1/8                     Loss: 0.550975\n",
      "Epoch:  164/1000 Batch    1/8                     Loss: 0.550939\n",
      "Epoch:  165/1000 Batch    1/8                     Loss: 0.550902\n",
      "Epoch:  166/1000 Batch    1/8                     Loss: 0.550866\n",
      "Epoch:  167/1000 Batch    1/8                     Loss: 0.550830\n",
      "Epoch:  168/1000 Batch    1/8                     Loss: 0.550794\n",
      "Epoch:  169/1000 Batch    1/8                     Loss: 0.550758\n",
      "Epoch:  170/1000 Batch    1/8                     Loss: 0.550722\n",
      "Epoch:  171/1000 Batch    1/8                     Loss: 0.550686\n",
      "Epoch:  172/1000 Batch    1/8                     Loss: 0.550651\n",
      "Epoch:  173/1000 Batch    1/8                     Loss: 0.550615\n",
      "Epoch:  174/1000 Batch    1/8                     Loss: 0.550579\n",
      "Epoch:  175/1000 Batch    1/8                     Loss: 0.550544\n",
      "Epoch:  176/1000 Batch    1/8                     Loss: 0.550508\n",
      "Epoch:  177/1000 Batch    1/8                     Loss: 0.550473\n",
      "Epoch:  178/1000 Batch    1/8                     Loss: 0.550437\n",
      "Epoch:  179/1000 Batch    1/8                     Loss: 0.550402\n",
      "Epoch:  180/1000 Batch    1/8                     Loss: 0.550367\n",
      "Epoch:  181/1000 Batch    1/8                     Loss: 0.550332\n",
      "Epoch:  182/1000 Batch    1/8                     Loss: 0.550297\n",
      "Epoch:  183/1000 Batch    1/8                     Loss: 0.550262\n",
      "Epoch:  184/1000 Batch    1/8                     Loss: 0.550227\n",
      "Epoch:  185/1000 Batch    1/8                     Loss: 0.550192\n",
      "Epoch:  186/1000 Batch    1/8                     Loss: 0.550157\n",
      "Epoch:  187/1000 Batch    1/8                     Loss: 0.550122\n",
      "Epoch:  188/1000 Batch    1/8                     Loss: 0.550088\n",
      "Epoch:  189/1000 Batch    1/8                     Loss: 0.550053\n",
      "Epoch:  190/1000 Batch    1/8                     Loss: 0.550019\n",
      "Epoch:  191/1000 Batch    1/8                     Loss: 0.549985\n",
      "Epoch:  192/1000 Batch    1/8                     Loss: 0.549950\n",
      "Epoch:  193/1000 Batch    1/8                     Loss: 0.549916\n",
      "Epoch:  194/1000 Batch    1/8                     Loss: 0.549883\n",
      "Epoch:  195/1000 Batch    1/8                     Loss: 0.549849\n",
      "Epoch:  196/1000 Batch    1/8                     Loss: 0.549815\n",
      "Epoch:  197/1000 Batch    1/8                     Loss: 0.549781\n",
      "Epoch:  198/1000 Batch    1/8                     Loss: 0.549748\n",
      "Epoch:  199/1000 Batch    1/8                     Loss: 0.549715\n",
      "Epoch:  200/1000 Batch    1/8                     Loss: 0.549681\n",
      "Epoch:  201/1000 Batch    1/8                     Loss: 0.549648\n",
      "Epoch:  202/1000 Batch    1/8                     Loss: 0.549615\n",
      "Epoch:  203/1000 Batch    1/8                     Loss: 0.549582\n",
      "Epoch:  204/1000 Batch    1/8                     Loss: 0.549550\n",
      "Epoch:  205/1000 Batch    1/8                     Loss: 0.549517\n",
      "Epoch:  206/1000 Batch    1/8                     Loss: 0.549484\n",
      "Epoch:  207/1000 Batch    1/8                     Loss: 0.549452\n",
      "Epoch:  208/1000 Batch    1/8                     Loss: 0.549420\n",
      "Epoch:  209/1000 Batch    1/8                     Loss: 0.549388\n",
      "Epoch:  210/1000 Batch    1/8                     Loss: 0.549356\n",
      "Epoch:  211/1000 Batch    1/8                     Loss: 0.549324\n",
      "Epoch:  212/1000 Batch    1/8                     Loss: 0.549292\n",
      "Epoch:  213/1000 Batch    1/8                     Loss: 0.549261\n",
      "Epoch:  214/1000 Batch    1/8                     Loss: 0.549229\n",
      "Epoch:  215/1000 Batch    1/8                     Loss: 0.549198\n",
      "Epoch:  216/1000 Batch    1/8                     Loss: 0.549167\n",
      "Epoch:  217/1000 Batch    1/8                     Loss: 0.549136\n",
      "Epoch:  218/1000 Batch    1/8                     Loss: 0.549105\n",
      "Epoch:  219/1000 Batch    1/8                     Loss: 0.549074\n",
      "Epoch:  220/1000 Batch    1/8                     Loss: 0.549043\n",
      "Epoch:  221/1000 Batch    1/8                     Loss: 0.549012\n",
      "Epoch:  222/1000 Batch    1/8                     Loss: 0.548982\n",
      "Epoch:  223/1000 Batch    1/8                     Loss: 0.548951\n",
      "Epoch:  224/1000 Batch    1/8                     Loss: 0.548921\n",
      "Epoch:  225/1000 Batch    1/8                     Loss: 0.548890\n",
      "Epoch:  226/1000 Batch    1/8                     Loss: 0.548860\n",
      "Epoch:  227/1000 Batch    1/8                     Loss: 0.548830\n",
      "Epoch:  228/1000 Batch    1/8                     Loss: 0.548800\n",
      "Epoch:  229/1000 Batch    1/8                     Loss: 0.548770\n",
      "Epoch:  230/1000 Batch    1/8                     Loss: 0.548740\n",
      "Epoch:  231/1000 Batch    1/8                     Loss: 0.548710\n",
      "Epoch:  232/1000 Batch    1/8                     Loss: 0.548680\n",
      "Epoch:  233/1000 Batch    1/8                     Loss: 0.548650\n",
      "Epoch:  234/1000 Batch    1/8                     Loss: 0.548620\n",
      "Epoch:  235/1000 Batch    1/8                     Loss: 0.548590\n",
      "Epoch:  236/1000 Batch    1/8                     Loss: 0.548560\n",
      "Epoch:  237/1000 Batch    1/8                     Loss: 0.548530\n",
      "Epoch:  238/1000 Batch    1/8                     Loss: 0.548500\n",
      "Epoch:  239/1000 Batch    1/8                     Loss: 0.548470\n",
      "Epoch:  240/1000 Batch    1/8                     Loss: 0.548440\n",
      "Epoch:  241/1000 Batch    1/8                     Loss: 0.548410\n",
      "Epoch:  242/1000 Batch    1/8                     Loss: 0.548380\n",
      "Epoch:  243/1000 Batch    1/8                     Loss: 0.548350\n",
      "Epoch:  244/1000 Batch    1/8                     Loss: 0.548320\n",
      "Epoch:  245/1000 Batch    1/8                     Loss: 0.548290\n",
      "Epoch:  246/1000 Batch    1/8                     Loss: 0.548260\n",
      "Epoch:  247/1000 Batch    1/8                     Loss: 0.548229\n",
      "Epoch:  248/1000 Batch    1/8                     Loss: 0.548199\n",
      "Epoch:  249/1000 Batch    1/8                     Loss: 0.548168\n",
      "Epoch:  250/1000 Batch    1/8                     Loss: 0.548138\n",
      "Epoch:  251/1000 Batch    1/8                     Loss: 0.548107\n",
      "Epoch:  252/1000 Batch    1/8                     Loss: 0.548076\n",
      "Epoch:  253/1000 Batch    1/8                     Loss: 0.548046\n",
      "Epoch:  254/1000 Batch    1/8                     Loss: 0.548015\n",
      "Epoch:  255/1000 Batch    1/8                     Loss: 0.547983\n",
      "Epoch:  256/1000 Batch    1/8                     Loss: 0.547952\n",
      "Epoch:  257/1000 Batch    1/8                     Loss: 0.547921\n",
      "Epoch:  258/1000 Batch    1/8                     Loss: 0.547889\n",
      "Epoch:  259/1000 Batch    1/8                     Loss: 0.547858\n",
      "Epoch:  260/1000 Batch    1/8                     Loss: 0.547826\n",
      "Epoch:  261/1000 Batch    1/8                     Loss: 0.547794\n",
      "Epoch:  262/1000 Batch    1/8                     Loss: 0.547762\n",
      "Epoch:  263/1000 Batch    1/8                     Loss: 0.547730\n",
      "Epoch:  264/1000 Batch    1/8                     Loss: 0.547697\n",
      "Epoch:  265/1000 Batch    1/8                     Loss: 0.547665\n",
      "Epoch:  266/1000 Batch    1/8                     Loss: 0.547632\n",
      "Epoch:  267/1000 Batch    1/8                     Loss: 0.547599\n",
      "Epoch:  268/1000 Batch    1/8                     Loss: 0.547566\n",
      "Epoch:  269/1000 Batch    1/8                     Loss: 0.547532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  270/1000 Batch    1/8                     Loss: 0.547498\n",
      "Epoch:  271/1000 Batch    1/8                     Loss: 0.547465\n",
      "Epoch:  272/1000 Batch    1/8                     Loss: 0.547431\n",
      "Epoch:  273/1000 Batch    1/8                     Loss: 0.547396\n",
      "Epoch:  274/1000 Batch    1/8                     Loss: 0.547362\n",
      "Epoch:  275/1000 Batch    1/8                     Loss: 0.547327\n",
      "Epoch:  276/1000 Batch    1/8                     Loss: 0.547292\n",
      "Epoch:  277/1000 Batch    1/8                     Loss: 0.547257\n",
      "Epoch:  278/1000 Batch    1/8                     Loss: 0.547221\n",
      "Epoch:  279/1000 Batch    1/8                     Loss: 0.547185\n",
      "Epoch:  280/1000 Batch    1/8                     Loss: 0.547149\n",
      "Epoch:  281/1000 Batch    1/8                     Loss: 0.547113\n",
      "Epoch:  282/1000 Batch    1/8                     Loss: 0.547076\n",
      "Epoch:  283/1000 Batch    1/8                     Loss: 0.547039\n",
      "Epoch:  284/1000 Batch    1/8                     Loss: 0.547001\n",
      "Epoch:  285/1000 Batch    1/8                     Loss: 0.546963\n",
      "Epoch:  286/1000 Batch    1/8                     Loss: 0.546925\n",
      "Epoch:  287/1000 Batch    1/8                     Loss: 0.546886\n",
      "Epoch:  288/1000 Batch    1/8                     Loss: 0.546847\n",
      "Epoch:  289/1000 Batch    1/8                     Loss: 0.546807\n",
      "Epoch:  290/1000 Batch    1/8                     Loss: 0.546766\n",
      "Epoch:  291/1000 Batch    1/8                     Loss: 0.546725\n",
      "Epoch:  292/1000 Batch    1/8                     Loss: 0.546683\n",
      "Epoch:  293/1000 Batch    1/8                     Loss: 0.546641\n",
      "Epoch:  294/1000 Batch    1/8                     Loss: 0.546598\n",
      "Epoch:  295/1000 Batch    1/8                     Loss: 0.546554\n",
      "Epoch:  296/1000 Batch    1/8                     Loss: 0.546509\n",
      "Epoch:  297/1000 Batch    1/8                     Loss: 0.546463\n",
      "Epoch:  298/1000 Batch    1/8                     Loss: 0.546416\n",
      "Epoch:  299/1000 Batch    1/8                     Loss: 0.546367\n",
      "Epoch:  300/1000 Batch    1/8                     Loss: 0.546318\n",
      "Epoch:  301/1000 Batch    1/8                     Loss: 0.546267\n",
      "Epoch:  302/1000 Batch    1/8                     Loss: 0.546215\n",
      "Epoch:  303/1000 Batch    1/8                     Loss: 0.546161\n",
      "Epoch:  304/1000 Batch    1/8                     Loss: 0.546108\n",
      "Epoch:  305/1000 Batch    1/8                     Loss: 0.546056\n",
      "Epoch:  306/1000 Batch    1/8                     Loss: 0.546006\n",
      "Epoch:  307/1000 Batch    1/8                     Loss: 0.545964\n",
      "Epoch:  308/1000 Batch    1/8                     Loss: 0.545934\n",
      "Epoch:  309/1000 Batch    1/8                     Loss: 0.545921\n",
      "Epoch:  310/1000 Batch    1/8                     Loss: 0.545925\n",
      "Epoch:  311/1000 Batch    1/8                     Loss: 0.545943\n",
      "Epoch:  312/1000 Batch    1/8                     Loss: 0.545954\n",
      "Epoch:  313/1000 Batch    1/8                     Loss: 0.545946\n",
      "Epoch:  314/1000 Batch    1/8                     Loss: 0.545936\n",
      "Epoch:  315/1000 Batch    1/8                     Loss: 0.545928\n",
      "Epoch:  316/1000 Batch    1/8                     Loss: 0.545891\n",
      "Epoch:  317/1000 Batch    1/8                     Loss: 0.545831\n",
      "Epoch:  318/1000 Batch    1/8                     Loss: 0.545812\n",
      "Epoch:  319/1000 Batch    1/8                     Loss: 0.545807\n",
      "Epoch:  320/1000 Batch    1/8                     Loss: 0.545713\n",
      "Epoch:  321/1000 Batch    1/8                     Loss: 0.545628\n",
      "Epoch:  322/1000 Batch    1/8                     Loss: 0.545709\n",
      "Epoch:  323/1000 Batch    1/8                     Loss: 0.545701\n",
      "Epoch:  324/1000 Batch    1/8                     Loss: 0.545403\n",
      "Epoch:  325/1000 Batch    1/8                     Loss: 0.545406\n",
      "Epoch:  326/1000 Batch    1/8                     Loss: 0.545918\n",
      "Epoch:  327/1000 Batch    1/8                     Loss: 0.545530\n",
      "Epoch:  328/1000 Batch    1/8                     Loss: 0.544703\n",
      "Epoch:  329/1000 Batch    1/8                     Loss: 0.545850\n",
      "Epoch:  330/1000 Batch    1/8                     Loss: 0.547108\n",
      "Epoch:  331/1000 Batch    1/8                     Loss: 0.544887\n",
      "Epoch:  332/1000 Batch    1/8                     Loss: 0.544739\n",
      "Epoch:  333/1000 Batch    1/8                     Loss: 0.545808\n",
      "Epoch:  334/1000 Batch    1/8                     Loss: 0.546525\n",
      "Epoch:  335/1000 Batch    1/8                     Loss: 0.544609\n",
      "Epoch:  336/1000 Batch    1/8                     Loss: 0.544441\n",
      "Epoch:  337/1000 Batch    1/8                     Loss: 0.546350\n",
      "Epoch:  338/1000 Batch    1/8                     Loss: 0.546043\n",
      "Epoch:  339/1000 Batch    1/8                     Loss: 0.544342\n",
      "Epoch:  340/1000 Batch    1/8                     Loss: 0.545424\n",
      "Epoch:  341/1000 Batch    1/8                     Loss: 0.545404\n",
      "Epoch:  342/1000 Batch    1/8                     Loss: 0.544351\n",
      "Epoch:  343/1000 Batch    1/8                     Loss: 0.544296\n",
      "Epoch:  344/1000 Batch    1/8                     Loss: 0.548025\n",
      "Epoch:  345/1000 Batch    1/8                     Loss: 0.544786\n",
      "Epoch:  346/1000 Batch    1/8                     Loss: 0.544512\n",
      "Epoch:  347/1000 Batch    1/8                     Loss: 0.551492\n",
      "Epoch:  348/1000 Batch    1/8                     Loss: 0.544189\n",
      "Epoch:  349/1000 Batch    1/8                     Loss: 0.544989\n",
      "Epoch:  350/1000 Batch    1/8                     Loss: 0.545175\n",
      "Epoch:  351/1000 Batch    1/8                     Loss: 0.545931\n",
      "Epoch:  352/1000 Batch    1/8                     Loss: 0.544296\n",
      "Epoch:  353/1000 Batch    1/8                     Loss: 0.543982\n",
      "Epoch:  354/1000 Batch    1/8                     Loss: 0.553435\n",
      "Epoch:  355/1000 Batch    1/8                     Loss: 0.544092\n",
      "Epoch:  356/1000 Batch    1/8                     Loss: 0.545502\n",
      "Epoch:  357/1000 Batch    1/8                     Loss: 0.543958\n",
      "Epoch:  358/1000 Batch    1/8                     Loss: 0.545970\n",
      "Epoch:  359/1000 Batch    1/8                     Loss: 0.546403\n",
      "Epoch:  360/1000 Batch    1/8                     Loss: 0.544139\n",
      "Epoch:  361/1000 Batch    1/8                     Loss: 0.544104\n",
      "Epoch:  362/1000 Batch    1/8                     Loss: 0.552044\n",
      "Epoch:  363/1000 Batch    1/8                     Loss: 0.544093\n",
      "Epoch:  364/1000 Batch    1/8                     Loss: 0.545689\n",
      "Epoch:  365/1000 Batch    1/8                     Loss: 0.543879\n",
      "Epoch:  366/1000 Batch    1/8                     Loss: 0.545685\n",
      "Epoch:  367/1000 Batch    1/8                     Loss: 0.546164\n",
      "Epoch:  368/1000 Batch    1/8                     Loss: 0.543923\n",
      "Epoch:  369/1000 Batch    1/8                     Loss: 0.544427\n",
      "Epoch:  370/1000 Batch    1/8                     Loss: 0.553768\n",
      "Epoch:  371/1000 Batch    1/8                     Loss: 0.544337\n",
      "Epoch:  372/1000 Batch    1/8                     Loss: 0.544814\n",
      "Epoch:  373/1000 Batch    1/8                     Loss: 0.544024\n",
      "Epoch:  374/1000 Batch    1/8                     Loss: 0.545503\n",
      "Epoch:  375/1000 Batch    1/8                     Loss: 0.544082\n",
      "Epoch:  376/1000 Batch    1/8                     Loss: 0.543868\n",
      "Epoch:  377/1000 Batch    1/8                     Loss: 0.549054\n",
      "Epoch:  378/1000 Batch    1/8                     Loss: 0.544149\n",
      "Epoch:  379/1000 Batch    1/8                     Loss: 0.545958\n",
      "Epoch:  380/1000 Batch    1/8                     Loss: 0.545453\n",
      "Epoch:  381/1000 Batch    1/8                     Loss: 0.543846\n",
      "Epoch:  382/1000 Batch    1/8                     Loss: 0.543931\n",
      "Epoch:  383/1000 Batch    1/8                     Loss: 0.549924\n",
      "Epoch:  384/1000 Batch    1/8                     Loss: 0.544111\n",
      "Epoch:  385/1000 Batch    1/8                     Loss: 0.548159\n",
      "Epoch:  386/1000 Batch    1/8                     Loss: 0.544018\n",
      "Epoch:  387/1000 Batch    1/8                     Loss: 0.544699\n",
      "Epoch:  388/1000 Batch    1/8                     Loss: 0.546279\n",
      "Epoch:  389/1000 Batch    1/8                     Loss: 0.543873\n",
      "Epoch:  390/1000 Batch    1/8                     Loss: 0.543886\n",
      "Epoch:  391/1000 Batch    1/8                     Loss: 0.551179\n",
      "Epoch:  392/1000 Batch    1/8                     Loss: 0.545267\n",
      "Epoch:  393/1000 Batch    1/8                     Loss: 0.545254\n",
      "Epoch:  394/1000 Batch    1/8                     Loss: 0.543789\n",
      "Epoch:  395/1000 Batch    1/8                     Loss: 0.544694\n",
      "Epoch:  396/1000 Batch    1/8                     Loss: 0.547952\n",
      "Epoch:  397/1000 Batch    1/8                     Loss: 0.543936\n",
      "Epoch:  398/1000 Batch    1/8                     Loss: 0.546144\n",
      "Epoch:  399/1000 Batch    1/8                     Loss: 0.544488\n",
      "Epoch:  400/1000 Batch    1/8                     Loss: 0.543948\n",
      "Epoch:  401/1000 Batch    1/8                     Loss: 0.544357\n",
      "Epoch:  402/1000 Batch    1/8                     Loss: 0.544584\n",
      "Epoch:  403/1000 Batch    1/8                     Loss: 0.545370\n",
      "Epoch:  404/1000 Batch    1/8                     Loss: 0.544015\n",
      "Epoch:  405/1000 Batch    1/8                     Loss: 0.544072\n",
      "Epoch:  406/1000 Batch    1/8                     Loss: 0.544514\n",
      "Epoch:  407/1000 Batch    1/8                     Loss: 0.544333\n",
      "Epoch:  408/1000 Batch    1/8                     Loss: 0.544218\n",
      "Epoch:  409/1000 Batch    1/8                     Loss: 0.544278\n",
      "Epoch:  410/1000 Batch    1/8                     Loss: 0.544511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  411/1000 Batch    1/8                     Loss: 0.545376\n",
      "Epoch:  412/1000 Batch    1/8                     Loss: 0.544028\n",
      "Epoch:  413/1000 Batch    1/8                     Loss: 0.544112\n",
      "Epoch:  414/1000 Batch    1/8                     Loss: 0.544641\n",
      "Epoch:  415/1000 Batch    1/8                     Loss: 0.544343\n",
      "Epoch:  416/1000 Batch    1/8                     Loss: 0.544218\n",
      "Epoch:  417/1000 Batch    1/8                     Loss: 0.544336\n",
      "Epoch:  418/1000 Batch    1/8                     Loss: 0.544505\n",
      "Epoch:  419/1000 Batch    1/8                     Loss: 0.545756\n",
      "Epoch:  420/1000 Batch    1/8                     Loss: 0.543956\n",
      "Epoch:  421/1000 Batch    1/8                     Loss: 0.544309\n",
      "Epoch:  422/1000 Batch    1/8                     Loss: 0.544440\n",
      "Epoch:  423/1000 Batch    1/8                     Loss: 0.546065\n",
      "Epoch:  424/1000 Batch    1/8                     Loss: 0.545409\n",
      "Epoch:  425/1000 Batch    1/8                     Loss: 0.545296\n",
      "Epoch:  426/1000 Batch    1/8                     Loss: 0.548038\n",
      "Epoch:  427/1000 Batch    1/8                     Loss: 0.544176\n",
      "Epoch:  428/1000 Batch    1/8                     Loss: 0.545470\n",
      "Epoch:  429/1000 Batch    1/8                     Loss: 0.544570\n",
      "Epoch:  430/1000 Batch    1/8                     Loss: 0.550339\n",
      "Epoch:  431/1000 Batch    1/8                     Loss: 0.547514\n",
      "Epoch:  432/1000 Batch    1/8                     Loss: 0.544903\n",
      "Epoch:  433/1000 Batch    1/8                     Loss: 0.544394\n",
      "Epoch:  434/1000 Batch    1/8                     Loss: 0.543875\n",
      "Epoch:  435/1000 Batch    1/8                     Loss: 0.544442\n",
      "Epoch:  436/1000 Batch    1/8                     Loss: 0.545689\n",
      "Epoch:  437/1000 Batch    1/8                     Loss: 0.544275\n",
      "Epoch:  438/1000 Batch    1/8                     Loss: 0.544430\n",
      "Epoch:  439/1000 Batch    1/8                     Loss: 0.544625\n",
      "Epoch:  440/1000 Batch    1/8                     Loss: 0.546542\n",
      "Epoch:  441/1000 Batch    1/8                     Loss: 0.544650\n",
      "Epoch:  442/1000 Batch    1/8                     Loss: 0.544729\n",
      "Epoch:  443/1000 Batch    1/8                     Loss: 0.544453\n",
      "Epoch:  444/1000 Batch    1/8                     Loss: 0.545017\n",
      "Epoch:  445/1000 Batch    1/8                     Loss: 0.544267\n",
      "Epoch:  446/1000 Batch    1/8                     Loss: 0.544546\n",
      "Epoch:  447/1000 Batch    1/8                     Loss: 0.546066\n",
      "Epoch:  448/1000 Batch    1/8                     Loss: 0.544363\n",
      "Epoch:  449/1000 Batch    1/8                     Loss: 0.544265\n",
      "Epoch:  450/1000 Batch    1/8                     Loss: 0.544427\n",
      "Epoch:  451/1000 Batch    1/8                     Loss: 0.546212\n",
      "Epoch:  452/1000 Batch    1/8                     Loss: 0.544465\n",
      "Epoch:  453/1000 Batch    1/8                     Loss: 0.544519\n",
      "Epoch:  454/1000 Batch    1/8                     Loss: 0.544145\n",
      "Epoch:  455/1000 Batch    1/8                     Loss: 0.545195\n",
      "Epoch:  456/1000 Batch    1/8                     Loss: 0.544042\n",
      "Epoch:  457/1000 Batch    1/8                     Loss: 0.544708\n",
      "Epoch:  458/1000 Batch    1/8                     Loss: 0.544974\n",
      "Epoch:  459/1000 Batch    1/8                     Loss: 0.547803\n",
      "Epoch:  460/1000 Batch    1/8                     Loss: 0.543942\n",
      "Epoch:  461/1000 Batch    1/8                     Loss: 0.544303\n",
      "Epoch:  462/1000 Batch    1/8                     Loss: 0.544806\n",
      "Epoch:  463/1000 Batch    1/8                     Loss: 0.544392\n",
      "Epoch:  464/1000 Batch    1/8                     Loss: 0.544331\n",
      "Epoch:  465/1000 Batch    1/8                     Loss: 0.544106\n",
      "Epoch:  466/1000 Batch    1/8                     Loss: 0.544106\n",
      "Epoch:  467/1000 Batch    1/8                     Loss: 0.544292\n",
      "Epoch:  468/1000 Batch    1/8                     Loss: 0.545084\n",
      "Epoch:  469/1000 Batch    1/8                     Loss: 0.544290\n",
      "Epoch:  470/1000 Batch    1/8                     Loss: 0.544016\n",
      "Epoch:  471/1000 Batch    1/8                     Loss: 0.544464\n",
      "Epoch:  472/1000 Batch    1/8                     Loss: 0.545324\n",
      "Epoch:  473/1000 Batch    1/8                     Loss: 0.545512\n",
      "Epoch:  474/1000 Batch    1/8                     Loss: 0.543815\n",
      "Epoch:  475/1000 Batch    1/8                     Loss: 0.544873\n",
      "Epoch:  476/1000 Batch    1/8                     Loss: 0.544909\n",
      "Epoch:  477/1000 Batch    1/8                     Loss: 0.549826\n",
      "Epoch:  478/1000 Batch    1/8                     Loss: 0.544900\n",
      "Epoch:  479/1000 Batch    1/8                     Loss: 0.555416\n",
      "Epoch:  480/1000 Batch    1/8                     Loss: 0.544414\n",
      "Epoch:  481/1000 Batch    1/8                     Loss: 0.547332\n",
      "Epoch:  482/1000 Batch    1/8                     Loss: 0.548170\n",
      "Epoch:  483/1000 Batch    1/8                     Loss: 0.544981\n",
      "Epoch:  484/1000 Batch    1/8                     Loss: 0.549059\n",
      "Epoch:  485/1000 Batch    1/8                     Loss: 0.545818\n",
      "Epoch:  486/1000 Batch    1/8                     Loss: 0.546884\n",
      "Epoch:  487/1000 Batch    1/8                     Loss: 0.546036\n",
      "Epoch:  488/1000 Batch    1/8                     Loss: 0.546431\n",
      "Epoch:  489/1000 Batch    1/8                     Loss: 0.544239\n",
      "Epoch:  490/1000 Batch    1/8                     Loss: 0.544385\n",
      "Epoch:  491/1000 Batch    1/8                     Loss: 0.546052\n",
      "Epoch:  492/1000 Batch    1/8                     Loss: 0.544194\n",
      "Epoch:  493/1000 Batch    1/8                     Loss: 0.544186\n",
      "Epoch:  494/1000 Batch    1/8                     Loss: 0.544670\n",
      "Epoch:  495/1000 Batch    1/8                     Loss: 0.544252\n",
      "Epoch:  496/1000 Batch    1/8                     Loss: 0.543987\n",
      "Epoch:  497/1000 Batch    1/8                     Loss: 0.544103\n",
      "Epoch:  498/1000 Batch    1/8                     Loss: 0.544488\n",
      "Epoch:  499/1000 Batch    1/8                     Loss: 0.544142\n",
      "Epoch:  500/1000 Batch    1/8                     Loss: 0.544005\n",
      "Epoch:  501/1000 Batch    1/8                     Loss: 0.544126\n",
      "Epoch:  502/1000 Batch    1/8                     Loss: 0.544459\n",
      "Epoch:  503/1000 Batch    1/8                     Loss: 0.544104\n",
      "Epoch:  504/1000 Batch    1/8                     Loss: 0.543995\n",
      "Epoch:  505/1000 Batch    1/8                     Loss: 0.544112\n",
      "Epoch:  506/1000 Batch    1/8                     Loss: 0.544525\n",
      "Epoch:  507/1000 Batch    1/8                     Loss: 0.544078\n",
      "Epoch:  508/1000 Batch    1/8                     Loss: 0.543978\n",
      "Epoch:  509/1000 Batch    1/8                     Loss: 0.544098\n",
      "Epoch:  510/1000 Batch    1/8                     Loss: 0.544728\n",
      "Epoch:  511/1000 Batch    1/8                     Loss: 0.544100\n",
      "Epoch:  512/1000 Batch    1/8                     Loss: 0.543952\n",
      "Epoch:  513/1000 Batch    1/8                     Loss: 0.544156\n",
      "Epoch:  514/1000 Batch    1/8                     Loss: 0.545084\n",
      "Epoch:  515/1000 Batch    1/8                     Loss: 0.544338\n",
      "Epoch:  516/1000 Batch    1/8                     Loss: 0.543836\n",
      "Epoch:  517/1000 Batch    1/8                     Loss: 0.544480\n",
      "Epoch:  518/1000 Batch    1/8                     Loss: 0.545012\n",
      "Epoch:  519/1000 Batch    1/8                     Loss: 0.545610\n",
      "Epoch:  520/1000 Batch    1/8                     Loss: 0.543621\n",
      "Epoch:  521/1000 Batch    1/8                     Loss: 0.544965\n",
      "Epoch:  522/1000 Batch    1/8                     Loss: 0.545606\n",
      "Epoch:  523/1000 Batch    1/8                     Loss: 0.552801\n",
      "Epoch:  524/1000 Batch    1/8                     Loss: 0.545044\n",
      "Epoch:  525/1000 Batch    1/8                     Loss: 0.552804\n",
      "Epoch:  526/1000 Batch    1/8                     Loss: 0.543370\n",
      "Epoch:  527/1000 Batch    1/8                     Loss: 0.559274\n",
      "Epoch:  528/1000 Batch    1/8                     Loss: 0.555876\n",
      "Epoch:  529/1000 Batch    1/8                     Loss: 0.547957\n",
      "Epoch:  530/1000 Batch    1/8                     Loss: 0.556871\n",
      "Epoch:  531/1000 Batch    1/8                     Loss: 0.548313\n",
      "Epoch:  532/1000 Batch    1/8                     Loss: 0.547266\n",
      "Epoch:  533/1000 Batch    1/8                     Loss: 0.558426\n",
      "Epoch:  534/1000 Batch    1/8                     Loss: 0.556306\n",
      "Epoch:  535/1000 Batch    1/8                     Loss: 0.554986\n",
      "Epoch:  536/1000 Batch    1/8                     Loss: 0.566805\n",
      "Epoch:  537/1000 Batch    1/8                     Loss: 0.554592\n",
      "Epoch:  538/1000 Batch    1/8                     Loss: 0.573958\n",
      "Epoch:  539/1000 Batch    1/8                     Loss: 0.551177\n",
      "Epoch:  540/1000 Batch    1/8                     Loss: 0.553796\n",
      "Epoch:  541/1000 Batch    1/8                     Loss: 0.547573\n",
      "Epoch:  542/1000 Batch    1/8                     Loss: 0.547167\n",
      "Epoch:  543/1000 Batch    1/8                     Loss: 0.543500\n",
      "Epoch:  544/1000 Batch    1/8                     Loss: 0.543614\n",
      "Epoch:  545/1000 Batch    1/8                     Loss: 0.543732\n",
      "Epoch:  546/1000 Batch    1/8                     Loss: 0.543834\n",
      "Epoch:  547/1000 Batch    1/8                     Loss: 0.544023\n",
      "Epoch:  548/1000 Batch    1/8                     Loss: 0.543926\n",
      "Epoch:  549/1000 Batch    1/8                     Loss: 0.543944\n",
      "Epoch:  550/1000 Batch    1/8                     Loss: 0.544027\n",
      "Epoch:  551/1000 Batch    1/8                     Loss: 0.543945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  552/1000 Batch    1/8                     Loss: 0.543940\n",
      "Epoch:  553/1000 Batch    1/8                     Loss: 0.543951\n",
      "Epoch:  554/1000 Batch    1/8                     Loss: 0.543944\n",
      "Epoch:  555/1000 Batch    1/8                     Loss: 0.543954\n",
      "Epoch:  556/1000 Batch    1/8                     Loss: 0.543951\n",
      "Epoch:  557/1000 Batch    1/8                     Loss: 0.543943\n",
      "Epoch:  558/1000 Batch    1/8                     Loss: 0.543948\n",
      "Epoch:  559/1000 Batch    1/8                     Loss: 0.543949\n",
      "Epoch:  560/1000 Batch    1/8                     Loss: 0.543945\n",
      "Epoch:  561/1000 Batch    1/8                     Loss: 0.543944\n",
      "Epoch:  562/1000 Batch    1/8                     Loss: 0.543944\n",
      "Epoch:  563/1000 Batch    1/8                     Loss: 0.543942\n",
      "Epoch:  564/1000 Batch    1/8                     Loss: 0.543940\n",
      "Epoch:  565/1000 Batch    1/8                     Loss: 0.543938\n",
      "Epoch:  566/1000 Batch    1/8                     Loss: 0.543936\n",
      "Epoch:  567/1000 Batch    1/8                     Loss: 0.543933\n",
      "Epoch:  568/1000 Batch    1/8                     Loss: 0.543930\n",
      "Epoch:  569/1000 Batch    1/8                     Loss: 0.543928\n",
      "Epoch:  570/1000 Batch    1/8                     Loss: 0.543924\n",
      "Epoch:  571/1000 Batch    1/8                     Loss: 0.543921\n",
      "Epoch:  572/1000 Batch    1/8                     Loss: 0.543918\n",
      "Epoch:  573/1000 Batch    1/8                     Loss: 0.543915\n",
      "Epoch:  574/1000 Batch    1/8                     Loss: 0.543911\n",
      "Epoch:  575/1000 Batch    1/8                     Loss: 0.543907\n",
      "Epoch:  576/1000 Batch    1/8                     Loss: 0.543904\n",
      "Epoch:  577/1000 Batch    1/8                     Loss: 0.543900\n",
      "Epoch:  578/1000 Batch    1/8                     Loss: 0.543895\n",
      "Epoch:  579/1000 Batch    1/8                     Loss: 0.543892\n",
      "Epoch:  580/1000 Batch    1/8                     Loss: 0.543889\n",
      "Epoch:  581/1000 Batch    1/8                     Loss: 0.543884\n",
      "Epoch:  582/1000 Batch    1/8                     Loss: 0.543878\n",
      "Epoch:  583/1000 Batch    1/8                     Loss: 0.543876\n",
      "Epoch:  584/1000 Batch    1/8                     Loss: 0.543874\n",
      "Epoch:  585/1000 Batch    1/8                     Loss: 0.543865\n",
      "Epoch:  586/1000 Batch    1/8                     Loss: 0.543860\n",
      "Epoch:  587/1000 Batch    1/8                     Loss: 0.543863\n",
      "Epoch:  588/1000 Batch    1/8                     Loss: 0.543857\n",
      "Epoch:  589/1000 Batch    1/8                     Loss: 0.543841\n",
      "Epoch:  590/1000 Batch    1/8                     Loss: 0.543843\n",
      "Epoch:  591/1000 Batch    1/8                     Loss: 0.543857\n",
      "Epoch:  592/1000 Batch    1/8                     Loss: 0.543834\n",
      "Epoch:  593/1000 Batch    1/8                     Loss: 0.543810\n",
      "Epoch:  594/1000 Batch    1/8                     Loss: 0.543841\n",
      "Epoch:  595/1000 Batch    1/8                     Loss: 0.543885\n",
      "Epoch:  596/1000 Batch    1/8                     Loss: 0.543771\n",
      "Epoch:  597/1000 Batch    1/8                     Loss: 0.543823\n",
      "Epoch:  598/1000 Batch    1/8                     Loss: 0.543898\n",
      "Epoch:  599/1000 Batch    1/8                     Loss: 0.544119\n",
      "Epoch:  600/1000 Batch    1/8                     Loss: 0.543634\n",
      "Epoch:  601/1000 Batch    1/8                     Loss: 0.544021\n",
      "Epoch:  602/1000 Batch    1/8                     Loss: 0.543963\n",
      "Epoch:  603/1000 Batch    1/8                     Loss: 0.544833\n",
      "Epoch:  604/1000 Batch    1/8                     Loss: 0.543511\n",
      "Epoch:  605/1000 Batch    1/8                     Loss: 0.543966\n",
      "Epoch:  606/1000 Batch    1/8                     Loss: 0.543612\n",
      "Epoch:  607/1000 Batch    1/8                     Loss: 0.543851\n",
      "Epoch:  608/1000 Batch    1/8                     Loss: 0.544250\n",
      "Epoch:  609/1000 Batch    1/8                     Loss: 0.543519\n",
      "Epoch:  610/1000 Batch    1/8                     Loss: 0.544203\n",
      "Epoch:  611/1000 Batch    1/8                     Loss: 0.543782\n",
      "Epoch:  612/1000 Batch    1/8                     Loss: 0.545696\n",
      "Epoch:  613/1000 Batch    1/8                     Loss: 0.543427\n",
      "Epoch:  614/1000 Batch    1/8                     Loss: 0.544141\n",
      "Epoch:  615/1000 Batch    1/8                     Loss: 0.544338\n",
      "Epoch:  616/1000 Batch    1/8                     Loss: 0.545749\n",
      "Epoch:  617/1000 Batch    1/8                     Loss: 0.543922\n",
      "Epoch:  618/1000 Batch    1/8                     Loss: 0.544931\n",
      "Epoch:  619/1000 Batch    1/8                     Loss: 0.555929\n",
      "Epoch:  620/1000 Batch    1/8                     Loss: 0.552768\n",
      "Epoch:  621/1000 Batch    1/8                     Loss: 0.562069\n",
      "Epoch:  622/1000 Batch    1/8                     Loss: 0.566746\n",
      "Epoch:  623/1000 Batch    1/8                     Loss: 0.546676\n",
      "Epoch:  624/1000 Batch    1/8                     Loss: 0.543728\n",
      "Epoch:  625/1000 Batch    1/8                     Loss: 0.548772\n",
      "Epoch:  626/1000 Batch    1/8                     Loss: 0.543793\n",
      "Epoch:  627/1000 Batch    1/8                     Loss: 0.550525\n",
      "Epoch:  628/1000 Batch    1/8                     Loss: 0.546842\n",
      "Epoch:  629/1000 Batch    1/8                     Loss: 0.558212\n",
      "Epoch:  630/1000 Batch    1/8                     Loss: 0.546207\n",
      "Epoch:  631/1000 Batch    1/8                     Loss: 0.542924\n",
      "Epoch:  632/1000 Batch    1/8                     Loss: 0.557728\n",
      "Epoch:  633/1000 Batch    1/8                     Loss: 0.545422\n",
      "Epoch:  634/1000 Batch    1/8                     Loss: 0.542545\n",
      "Epoch:  635/1000 Batch    1/8                     Loss: 0.553552\n",
      "Epoch:  636/1000 Batch    1/8                     Loss: 0.545954\n",
      "Epoch:  637/1000 Batch    1/8                     Loss: 0.543264\n",
      "Epoch:  638/1000 Batch    1/8                     Loss: 0.544218\n",
      "Epoch:  639/1000 Batch    1/8                     Loss: 0.546957\n",
      "Epoch:  640/1000 Batch    1/8                     Loss: 0.555598\n",
      "Epoch:  641/1000 Batch    1/8                     Loss: 0.549245\n",
      "Epoch:  642/1000 Batch    1/8                     Loss: 0.553330\n",
      "Epoch:  643/1000 Batch    1/8                     Loss: 0.550985\n",
      "Epoch:  644/1000 Batch    1/8                     Loss: 0.554712\n",
      "Epoch:  645/1000 Batch    1/8                     Loss: 0.547166\n",
      "Epoch:  646/1000 Batch    1/8                     Loss: 0.547009\n",
      "Epoch:  647/1000 Batch    1/8                     Loss: 0.546999\n",
      "Epoch:  648/1000 Batch    1/8                     Loss: 0.546968\n",
      "Epoch:  649/1000 Batch    1/8                     Loss: 0.546957\n",
      "Epoch:  650/1000 Batch    1/8                     Loss: 0.547020\n",
      "Epoch:  651/1000 Batch    1/8                     Loss: 0.546977\n",
      "Epoch:  652/1000 Batch    1/8                     Loss: 0.547025\n",
      "Epoch:  653/1000 Batch    1/8                     Loss: 0.547029\n",
      "Epoch:  654/1000 Batch    1/8                     Loss: 0.547058\n",
      "Epoch:  655/1000 Batch    1/8                     Loss: 0.547027\n",
      "Epoch:  656/1000 Batch    1/8                     Loss: 0.547108\n",
      "Epoch:  657/1000 Batch    1/8                     Loss: 0.547042\n",
      "Epoch:  658/1000 Batch    1/8                     Loss: 0.547208\n",
      "Epoch:  659/1000 Batch    1/8                     Loss: 0.547081\n",
      "Epoch:  660/1000 Batch    1/8                     Loss: 0.547077\n",
      "Epoch:  661/1000 Batch    1/8                     Loss: 0.548062\n",
      "Epoch:  662/1000 Batch    1/8                     Loss: 0.547056\n",
      "Epoch:  663/1000 Batch    1/8                     Loss: 0.547285\n",
      "Epoch:  664/1000 Batch    1/8                     Loss: 0.549449\n",
      "Epoch:  665/1000 Batch    1/8                     Loss: 0.557364\n",
      "Epoch:  666/1000 Batch    1/8                     Loss: 0.554775\n",
      "Epoch:  667/1000 Batch    1/8                     Loss: 0.547138\n",
      "Epoch:  668/1000 Batch    1/8                     Loss: 0.547217\n",
      "Epoch:  669/1000 Batch    1/8                     Loss: 0.557734\n",
      "Epoch:  670/1000 Batch    1/8                     Loss: 0.567404\n",
      "Epoch:  671/1000 Batch    1/8                     Loss: 0.546099\n",
      "Epoch:  672/1000 Batch    1/8                     Loss: 0.574723\n",
      "Epoch:  673/1000 Batch    1/8                     Loss: 0.569973\n",
      "Epoch:  674/1000 Batch    1/8                     Loss: 0.559345\n",
      "Epoch:  675/1000 Batch    1/8                     Loss: 0.543464\n",
      "Epoch:  676/1000 Batch    1/8                     Loss: 0.551783\n",
      "Epoch:  677/1000 Batch    1/8                     Loss: 0.560041\n",
      "Epoch:  678/1000 Batch    1/8                     Loss: 0.546686\n",
      "Epoch:  679/1000 Batch    1/8                     Loss: 0.550485\n",
      "Epoch:  680/1000 Batch    1/8                     Loss: 0.554119\n",
      "Epoch:  681/1000 Batch    1/8                     Loss: 0.547233\n",
      "Epoch:  682/1000 Batch    1/8                     Loss: 0.545097\n",
      "Epoch:  683/1000 Batch    1/8                     Loss: 0.545522\n",
      "Epoch:  684/1000 Batch    1/8                     Loss: 0.546584\n",
      "Epoch:  685/1000 Batch    1/8                     Loss: 0.545417\n",
      "Epoch:  686/1000 Batch    1/8                     Loss: 0.550793\n",
      "Epoch:  687/1000 Batch    1/8                     Loss: 0.548020\n",
      "Epoch:  688/1000 Batch    1/8                     Loss: 0.558849\n",
      "Epoch:  689/1000 Batch    1/8                     Loss: 0.556865\n",
      "Epoch:  690/1000 Batch    1/8                     Loss: 0.545848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  691/1000 Batch    1/8                     Loss: 0.546993\n",
      "Epoch:  692/1000 Batch    1/8                     Loss: 0.547009\n",
      "Epoch:  693/1000 Batch    1/8                     Loss: 0.547135\n",
      "Epoch:  694/1000 Batch    1/8                     Loss: 0.548386\n",
      "Epoch:  695/1000 Batch    1/8                     Loss: 0.551514\n",
      "Epoch:  696/1000 Batch    1/8                     Loss: 0.547570\n",
      "Epoch:  697/1000 Batch    1/8                     Loss: 0.547649\n",
      "Epoch:  698/1000 Batch    1/8                     Loss: 0.544760\n",
      "Epoch:  699/1000 Batch    1/8                     Loss: 0.544524\n",
      "Epoch:  700/1000 Batch    1/8                     Loss: 0.545776\n",
      "Epoch:  701/1000 Batch    1/8                     Loss: 0.543593\n",
      "Epoch:  702/1000 Batch    1/8                     Loss: 0.543755\n",
      "Epoch:  703/1000 Batch    1/8                     Loss: 0.543960\n",
      "Epoch:  704/1000 Batch    1/8                     Loss: 0.544416\n",
      "Epoch:  705/1000 Batch    1/8                     Loss: 0.543736\n",
      "Epoch:  706/1000 Batch    1/8                     Loss: 0.543773\n",
      "Epoch:  707/1000 Batch    1/8                     Loss: 0.543879\n",
      "Epoch:  708/1000 Batch    1/8                     Loss: 0.543781\n",
      "Epoch:  709/1000 Batch    1/8                     Loss: 0.543764\n",
      "Epoch:  710/1000 Batch    1/8                     Loss: 0.543801\n",
      "Epoch:  711/1000 Batch    1/8                     Loss: 0.543781\n",
      "Epoch:  712/1000 Batch    1/8                     Loss: 0.543752\n",
      "Epoch:  713/1000 Batch    1/8                     Loss: 0.543738\n",
      "Epoch:  714/1000 Batch    1/8                     Loss: 0.543730\n",
      "Epoch:  715/1000 Batch    1/8                     Loss: 0.543722\n",
      "Epoch:  716/1000 Batch    1/8                     Loss: 0.543713\n",
      "Epoch:  717/1000 Batch    1/8                     Loss: 0.543711\n",
      "Epoch:  718/1000 Batch    1/8                     Loss: 0.543713\n",
      "Epoch:  719/1000 Batch    1/8                     Loss: 0.543729\n",
      "Epoch:  720/1000 Batch    1/8                     Loss: 0.543784\n",
      "Epoch:  721/1000 Batch    1/8                     Loss: 0.543994\n",
      "Epoch:  722/1000 Batch    1/8                     Loss: 0.544405\n",
      "Epoch:  723/1000 Batch    1/8                     Loss: 0.543893\n",
      "Epoch:  724/1000 Batch    1/8                     Loss: 0.545541\n",
      "Epoch:  725/1000 Batch    1/8                     Loss: 0.544077\n",
      "Epoch:  726/1000 Batch    1/8                     Loss: 0.547168\n",
      "Epoch:  727/1000 Batch    1/8                     Loss: 0.546863\n",
      "Epoch:  728/1000 Batch    1/8                     Loss: 0.545412\n",
      "Epoch:  729/1000 Batch    1/8                     Loss: 0.548452\n",
      "Epoch:  730/1000 Batch    1/8                     Loss: 0.547859\n",
      "Epoch:  731/1000 Batch    1/8                     Loss: 0.546712\n",
      "Epoch:  732/1000 Batch    1/8                     Loss: 0.546413\n",
      "Epoch:  733/1000 Batch    1/8                     Loss: 0.546304\n",
      "Epoch:  734/1000 Batch    1/8                     Loss: 0.545624\n",
      "Epoch:  735/1000 Batch    1/8                     Loss: 0.545203\n",
      "Epoch:  736/1000 Batch    1/8                     Loss: 0.545956\n",
      "Epoch:  737/1000 Batch    1/8                     Loss: 0.543934\n",
      "Epoch:  738/1000 Batch    1/8                     Loss: 0.544193\n",
      "Epoch:  739/1000 Batch    1/8                     Loss: 0.543529\n",
      "Epoch:  740/1000 Batch    1/8                     Loss: 0.543704\n",
      "Epoch:  741/1000 Batch    1/8                     Loss: 0.543504\n",
      "Epoch:  742/1000 Batch    1/8                     Loss: 0.543627\n",
      "Epoch:  743/1000 Batch    1/8                     Loss: 0.543575\n",
      "Epoch:  744/1000 Batch    1/8                     Loss: 0.543541\n",
      "Epoch:  745/1000 Batch    1/8                     Loss: 0.543491\n",
      "Epoch:  746/1000 Batch    1/8                     Loss: 0.543509\n",
      "Epoch:  747/1000 Batch    1/8                     Loss: 0.543483\n",
      "Epoch:  748/1000 Batch    1/8                     Loss: 0.543494\n",
      "Epoch:  749/1000 Batch    1/8                     Loss: 0.543474\n",
      "Epoch:  750/1000 Batch    1/8                     Loss: 0.543482\n",
      "Epoch:  751/1000 Batch    1/8                     Loss: 0.543460\n",
      "Epoch:  752/1000 Batch    1/8                     Loss: 0.543475\n",
      "Epoch:  753/1000 Batch    1/8                     Loss: 0.543451\n",
      "Epoch:  754/1000 Batch    1/8                     Loss: 0.543469\n",
      "Epoch:  755/1000 Batch    1/8                     Loss: 0.543444\n",
      "Epoch:  756/1000 Batch    1/8                     Loss: 0.543466\n",
      "Epoch:  757/1000 Batch    1/8                     Loss: 0.543437\n",
      "Epoch:  758/1000 Batch    1/8                     Loss: 0.543465\n",
      "Epoch:  759/1000 Batch    1/8                     Loss: 0.543431\n",
      "Epoch:  760/1000 Batch    1/8                     Loss: 0.543466\n",
      "Epoch:  761/1000 Batch    1/8                     Loss: 0.543427\n",
      "Epoch:  762/1000 Batch    1/8                     Loss: 0.543471\n",
      "Epoch:  763/1000 Batch    1/8                     Loss: 0.543426\n",
      "Epoch:  764/1000 Batch    1/8                     Loss: 0.543481\n",
      "Epoch:  765/1000 Batch    1/8                     Loss: 0.543426\n",
      "Epoch:  766/1000 Batch    1/8                     Loss: 0.543497\n",
      "Epoch:  767/1000 Batch    1/8                     Loss: 0.543431\n",
      "Epoch:  768/1000 Batch    1/8                     Loss: 0.543523\n",
      "Epoch:  769/1000 Batch    1/8                     Loss: 0.543442\n",
      "Epoch:  770/1000 Batch    1/8                     Loss: 0.543565\n",
      "Epoch:  771/1000 Batch    1/8                     Loss: 0.543462\n",
      "Epoch:  772/1000 Batch    1/8                     Loss: 0.543632\n",
      "Epoch:  773/1000 Batch    1/8                     Loss: 0.543495\n",
      "Epoch:  774/1000 Batch    1/8                     Loss: 0.543731\n",
      "Epoch:  775/1000 Batch    1/8                     Loss: 0.543540\n",
      "Epoch:  776/1000 Batch    1/8                     Loss: 0.543854\n",
      "Epoch:  777/1000 Batch    1/8                     Loss: 0.543579\n",
      "Epoch:  778/1000 Batch    1/8                     Loss: 0.543960\n",
      "Epoch:  779/1000 Batch    1/8                     Loss: 0.543601\n",
      "Epoch:  780/1000 Batch    1/8                     Loss: 0.544033\n",
      "Epoch:  781/1000 Batch    1/8                     Loss: 0.543615\n",
      "Epoch:  782/1000 Batch    1/8                     Loss: 0.544092\n",
      "Epoch:  783/1000 Batch    1/8                     Loss: 0.543618\n",
      "Epoch:  784/1000 Batch    1/8                     Loss: 0.544164\n",
      "Epoch:  785/1000 Batch    1/8                     Loss: 0.543634\n",
      "Epoch:  786/1000 Batch    1/8                     Loss: 0.544221\n",
      "Epoch:  787/1000 Batch    1/8                     Loss: 0.543623\n",
      "Epoch:  788/1000 Batch    1/8                     Loss: 0.544321\n",
      "Epoch:  789/1000 Batch    1/8                     Loss: 0.543660\n",
      "Epoch:  790/1000 Batch    1/8                     Loss: 0.544338\n",
      "Epoch:  791/1000 Batch    1/8                     Loss: 0.543617\n",
      "Epoch:  792/1000 Batch    1/8                     Loss: 0.544488\n",
      "Epoch:  793/1000 Batch    1/8                     Loss: 0.543627\n",
      "Epoch:  794/1000 Batch    1/8                     Loss: 0.544402\n",
      "Epoch:  795/1000 Batch    1/8                     Loss: 0.543840\n",
      "Epoch:  796/1000 Batch    1/8                     Loss: 0.543961\n",
      "Epoch:  797/1000 Batch    1/8                     Loss: 0.543257\n",
      "Epoch:  798/1000 Batch    1/8                     Loss: 0.543512\n",
      "Epoch:  799/1000 Batch    1/8                     Loss: 0.543460\n",
      "Epoch:  800/1000 Batch    1/8                     Loss: 0.545468\n",
      "Epoch:  801/1000 Batch    1/8                     Loss: 0.543292\n",
      "Epoch:  802/1000 Batch    1/8                     Loss: 0.543313\n",
      "Epoch:  803/1000 Batch    1/8                     Loss: 0.543316\n",
      "Epoch:  804/1000 Batch    1/8                     Loss: 0.545141\n",
      "Epoch:  805/1000 Batch    1/8                     Loss: 0.545244\n",
      "Epoch:  806/1000 Batch    1/8                     Loss: 0.544187\n",
      "Epoch:  807/1000 Batch    1/8                     Loss: 0.543235\n",
      "Epoch:  808/1000 Batch    1/8                     Loss: 0.545599\n",
      "Epoch:  809/1000 Batch    1/8                     Loss: 0.543512\n",
      "Epoch:  810/1000 Batch    1/8                     Loss: 0.543668\n",
      "Epoch:  811/1000 Batch    1/8                     Loss: 0.545857\n",
      "Epoch:  812/1000 Batch    1/8                     Loss: 0.544804\n",
      "Epoch:  813/1000 Batch    1/8                     Loss: 0.544096\n",
      "Epoch:  814/1000 Batch    1/8                     Loss: 0.543609\n",
      "Epoch:  815/1000 Batch    1/8                     Loss: 0.543274\n",
      "Epoch:  816/1000 Batch    1/8                     Loss: 0.543268\n",
      "Epoch:  817/1000 Batch    1/8                     Loss: 0.543251\n",
      "Epoch:  818/1000 Batch    1/8                     Loss: 0.543254\n",
      "Epoch:  819/1000 Batch    1/8                     Loss: 0.543263\n",
      "Epoch:  820/1000 Batch    1/8                     Loss: 0.543257\n",
      "Epoch:  821/1000 Batch    1/8                     Loss: 0.543258\n",
      "Epoch:  822/1000 Batch    1/8                     Loss: 0.543258\n",
      "Epoch:  823/1000 Batch    1/8                     Loss: 0.543253\n",
      "Epoch:  824/1000 Batch    1/8                     Loss: 0.543252\n",
      "Epoch:  825/1000 Batch    1/8                     Loss: 0.543250\n",
      "Epoch:  826/1000 Batch    1/8                     Loss: 0.543249\n",
      "Epoch:  827/1000 Batch    1/8                     Loss: 0.543248\n",
      "Epoch:  828/1000 Batch    1/8                     Loss: 0.543247\n",
      "Epoch:  829/1000 Batch    1/8                     Loss: 0.543246\n",
      "Epoch:  830/1000 Batch    1/8                     Loss: 0.543246\n",
      "Epoch:  831/1000 Batch    1/8                     Loss: 0.543245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  832/1000 Batch    1/8                     Loss: 0.543245\n",
      "Epoch:  833/1000 Batch    1/8                     Loss: 0.543244\n",
      "Epoch:  834/1000 Batch    1/8                     Loss: 0.543244\n",
      "Epoch:  835/1000 Batch    1/8                     Loss: 0.543244\n",
      "Epoch:  836/1000 Batch    1/8                     Loss: 0.543243\n",
      "Epoch:  837/1000 Batch    1/8                     Loss: 0.543243\n",
      "Epoch:  838/1000 Batch    1/8                     Loss: 0.543243\n",
      "Epoch:  839/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  840/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  841/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  842/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  843/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  844/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  845/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  846/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  847/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  848/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  849/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  850/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  851/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  852/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  853/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  854/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  855/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  856/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  857/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  858/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  859/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  860/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  861/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  862/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  863/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  864/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  865/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  866/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  867/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  868/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  869/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  870/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  871/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  872/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  873/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  874/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  875/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  876/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  877/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  878/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  879/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  880/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  881/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  882/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  883/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  884/1000 Batch    1/8                     Loss: 0.543239\n",
      "Epoch:  885/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  886/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  887/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  888/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  889/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  890/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  891/1000 Batch    1/8                     Loss: 0.543240\n",
      "Epoch:  892/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  893/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  894/1000 Batch    1/8                     Loss: 0.543241\n",
      "Epoch:  895/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  896/1000 Batch    1/8                     Loss: 0.543242\n",
      "Epoch:  897/1000 Batch    1/8                     Loss: 0.543243\n",
      "Epoch:  898/1000 Batch    1/8                     Loss: 0.543243\n",
      "Epoch:  899/1000 Batch    1/8                     Loss: 0.543244\n",
      "Epoch:  900/1000 Batch    1/8                     Loss: 0.543245\n",
      "Epoch:  901/1000 Batch    1/8                     Loss: 0.543246\n",
      "Epoch:  902/1000 Batch    1/8                     Loss: 0.543247\n",
      "Epoch:  903/1000 Batch    1/8                     Loss: 0.543248\n",
      "Epoch:  904/1000 Batch    1/8                     Loss: 0.543250\n",
      "Epoch:  905/1000 Batch    1/8                     Loss: 0.543252\n",
      "Epoch:  906/1000 Batch    1/8                     Loss: 0.543254\n",
      "Epoch:  907/1000 Batch    1/8                     Loss: 0.543257\n",
      "Epoch:  908/1000 Batch    1/8                     Loss: 0.543261\n",
      "Epoch:  909/1000 Batch    1/8                     Loss: 0.543265\n",
      "Epoch:  910/1000 Batch    1/8                     Loss: 0.543269\n",
      "Epoch:  911/1000 Batch    1/8                     Loss: 0.543274\n",
      "Epoch:  912/1000 Batch    1/8                     Loss: 0.543278\n",
      "Epoch:  913/1000 Batch    1/8                     Loss: 0.543280\n",
      "Epoch:  914/1000 Batch    1/8                     Loss: 0.543282\n",
      "Epoch:  915/1000 Batch    1/8                     Loss: 0.543283\n",
      "Epoch:  916/1000 Batch    1/8                     Loss: 0.543284\n",
      "Epoch:  917/1000 Batch    1/8                     Loss: 0.543284\n",
      "Epoch:  918/1000 Batch    1/8                     Loss: 0.543284\n",
      "Epoch:  919/1000 Batch    1/8                     Loss: 0.543284\n",
      "Epoch:  920/1000 Batch    1/8                     Loss: 0.543285\n",
      "Epoch:  921/1000 Batch    1/8                     Loss: 0.543283\n",
      "Epoch:  922/1000 Batch    1/8                     Loss: 0.543285\n",
      "Epoch:  923/1000 Batch    1/8                     Loss: 0.543281\n",
      "Epoch:  924/1000 Batch    1/8                     Loss: 0.543290\n",
      "Epoch:  925/1000 Batch    1/8                     Loss: 0.543274\n",
      "Epoch:  926/1000 Batch    1/8                     Loss: 0.543316\n",
      "Epoch:  927/1000 Batch    1/8                     Loss: 0.543265\n",
      "Epoch:  928/1000 Batch    1/8                     Loss: 0.543379\n",
      "Epoch:  929/1000 Batch    1/8                     Loss: 0.543306\n",
      "Epoch:  930/1000 Batch    1/8                     Loss: 0.543290\n",
      "Epoch:  931/1000 Batch    1/8                     Loss: 0.543442\n",
      "Epoch:  932/1000 Batch    1/8                     Loss: 0.543217\n",
      "Epoch:  933/1000 Batch    1/8                     Loss: 0.543243\n",
      "Epoch:  934/1000 Batch    1/8                     Loss: 0.543216\n",
      "Epoch:  935/1000 Batch    1/8                     Loss: 0.543312\n",
      "Epoch:  936/1000 Batch    1/8                     Loss: 0.544563\n",
      "Epoch:  937/1000 Batch    1/8                     Loss: 0.543317\n",
      "Epoch:  938/1000 Batch    1/8                     Loss: 0.548069\n",
      "Epoch:  939/1000 Batch    1/8                     Loss: 0.544008\n",
      "Epoch:  940/1000 Batch    1/8                     Loss: 0.565879\n",
      "Epoch:  941/1000 Batch    1/8                     Loss: 0.543902\n",
      "Epoch:  942/1000 Batch    1/8                     Loss: 0.565418\n",
      "Epoch:  943/1000 Batch    1/8                     Loss: 0.563113\n",
      "Epoch:  944/1000 Batch    1/8                     Loss: 0.568570\n",
      "Epoch:  945/1000 Batch    1/8                     Loss: 0.567063\n",
      "Epoch:  946/1000 Batch    1/8                     Loss: 0.561920\n",
      "Epoch:  947/1000 Batch    1/8                     Loss: 0.561784\n",
      "Epoch:  948/1000 Batch    1/8                     Loss: 0.561954\n",
      "Epoch:  949/1000 Batch    1/8                     Loss: 0.549947\n",
      "Epoch:  950/1000 Batch    1/8                     Loss: 0.572136\n",
      "Epoch:  951/1000 Batch    1/8                     Loss: 0.596086\n",
      "Epoch:  952/1000 Batch    1/8                     Loss: 0.585232\n",
      "Epoch:  953/1000 Batch    1/8                     Loss: 0.583908\n",
      "Epoch:  954/1000 Batch    1/8                     Loss: 0.573347\n",
      "Epoch:  955/1000 Batch    1/8                     Loss: 0.551238\n",
      "Epoch:  956/1000 Batch    1/8                     Loss: 0.547422\n",
      "Epoch:  957/1000 Batch    1/8                     Loss: 0.552571\n",
      "Epoch:  958/1000 Batch    1/8                     Loss: 0.558397\n",
      "Epoch:  959/1000 Batch    1/8                     Loss: 0.550518\n",
      "Epoch:  960/1000 Batch    1/8                     Loss: 0.548011\n",
      "Epoch:  961/1000 Batch    1/8                     Loss: 0.553370\n",
      "Epoch:  962/1000 Batch    1/8                     Loss: 0.545864\n",
      "Epoch:  963/1000 Batch    1/8                     Loss: 0.543409\n",
      "Epoch:  964/1000 Batch    1/8                     Loss: 0.546991\n",
      "Epoch:  965/1000 Batch    1/8                     Loss: 0.544453\n",
      "Epoch:  966/1000 Batch    1/8                     Loss: 0.557026\n",
      "Epoch:  967/1000 Batch    1/8                     Loss: 0.557496\n",
      "Epoch:  968/1000 Batch    1/8                     Loss: 0.545379\n",
      "Epoch:  969/1000 Batch    1/8                     Loss: 0.571182\n",
      "Epoch:  970/1000 Batch    1/8                     Loss: 0.554778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  971/1000 Batch    1/8                     Loss: 0.545056\n",
      "Epoch:  972/1000 Batch    1/8                     Loss: 0.554024\n",
      "Epoch:  973/1000 Batch    1/8                     Loss: 0.555855\n",
      "Epoch:  974/1000 Batch    1/8                     Loss: 0.548046\n",
      "Epoch:  975/1000 Batch    1/8                     Loss: 0.548077\n",
      "Epoch:  976/1000 Batch    1/8                     Loss: 0.553565\n",
      "Epoch:  977/1000 Batch    1/8                     Loss: 0.558369\n",
      "Epoch:  978/1000 Batch    1/8                     Loss: 0.549479\n",
      "Epoch:  979/1000 Batch    1/8                     Loss: 0.548892\n",
      "Epoch:  980/1000 Batch    1/8                     Loss: 0.564105\n",
      "Epoch:  981/1000 Batch    1/8                     Loss: 0.555451\n",
      "Epoch:  982/1000 Batch    1/8                     Loss: 0.547035\n",
      "Epoch:  983/1000 Batch    1/8                     Loss: 0.547451\n",
      "Epoch:  984/1000 Batch    1/8                     Loss: 0.548275\n",
      "Epoch:  985/1000 Batch    1/8                     Loss: 0.547035\n",
      "Epoch:  986/1000 Batch    1/8                     Loss: 0.554970\n",
      "Epoch:  987/1000 Batch    1/8                     Loss: 0.546068\n",
      "Epoch:  988/1000 Batch    1/8                     Loss: 0.546942\n",
      "Epoch:  989/1000 Batch    1/8                     Loss: 0.543219\n",
      "Epoch:  990/1000 Batch    1/8                     Loss: 0.547150\n",
      "Epoch:  991/1000 Batch    1/8                     Loss: 0.550195\n",
      "Epoch:  992/1000 Batch    1/8                     Loss: 0.547013\n",
      "Epoch:  993/1000 Batch    1/8                     Loss: 0.548618\n",
      "Epoch:  994/1000 Batch    1/8                     Loss: 0.547010\n",
      "Epoch:  995/1000 Batch    1/8                     Loss: 0.547300\n",
      "Epoch:  996/1000 Batch    1/8                     Loss: 0.547008\n",
      "Epoch:  997/1000 Batch    1/8                     Loss: 0.547000\n",
      "Epoch:  998/1000 Batch    1/8                     Loss: 0.547004\n",
      "Epoch:  999/1000 Batch    1/8                     Loss: 0.547012\n",
      "Epoch: 1000/1000 Batch    1/8                     Loss: 0.547316\n"
     ]
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    for batch_idx, samples in enumerate(data_loader):\n",
    "        x_train, y_train = samples\n",
    "        y_pred = model(x_train)\n",
    "        loss = bce_loss(y_pred, y_train)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f'Epoch: {epoch+1:4d}/{epochs} Batch {batch_idx+1:4d}/{len(data_loader)} \\\n",
    "                Loss: {loss.item():4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090ae091",
   "metadata": {},
   "source": [
    "## 퀴즈 (Easy)  \n",
    "위 학습 반복문에서 enumerate를 사용했습니다. 그 이유가 무엇일까요?  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
